{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s6ZJiVAtEgsy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLdHG6zSEgs0"
      },
      "source": [
        "# Training the model for 3-Class Diabetes Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JigRuSA-FRzZ",
        "outputId": "87255373-3566-4b31-ac8d-488382fb1296"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "einuhanxEgs2"
      },
      "source": [
        "### Reading the processed data from training and testing files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PB0jbiQGEgs2"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv(\"/content/drive/MyDrive/AML_Final_Project/Dataset/train_012.csv\")\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/AML_Final_Project/Dataset/test_012.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "puUnapbqEgs2",
        "outputId": "d87d0046-8588-4bdc-a793-a0f408c7db0b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7dbefd48-75e3-418c-99d2-4f917ea8efbd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BMI</th>\n",
              "      <th>GenHlth</th>\n",
              "      <th>MentHlth</th>\n",
              "      <th>PhysHlth</th>\n",
              "      <th>DiffWalk</th>\n",
              "      <th>Age</th>\n",
              "      <th>Education</th>\n",
              "      <th>Income</th>\n",
              "      <th>HighBP_0</th>\n",
              "      <th>HighBP_1</th>\n",
              "      <th>...</th>\n",
              "      <th>Veggies_1</th>\n",
              "      <th>HvyAlcoholConsump_0</th>\n",
              "      <th>HvyAlcoholConsump_1</th>\n",
              "      <th>AnyHealthcare_0</th>\n",
              "      <th>AnyHealthcare_1</th>\n",
              "      <th>NoDocbcCost_0</th>\n",
              "      <th>NoDocbcCost_1</th>\n",
              "      <th>Sex_0</th>\n",
              "      <th>Sex_1</th>\n",
              "      <th>Diabetes_012</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.512552</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.301115</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.998837</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.210274</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.059135</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 35 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7dbefd48-75e3-418c-99d2-4f917ea8efbd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7dbefd48-75e3-418c-99d2-4f917ea8efbd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7dbefd48-75e3-418c-99d2-4f917ea8efbd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b7be713f-a11d-4f26-b09b-553b9d0e3512\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b7be713f-a11d-4f26-b09b-553b9d0e3512')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b7be713f-a11d-4f26-b09b-553b9d0e3512 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        BMI  GenHlth  MentHlth  PhysHlth  DiffWalk       Age  Education  \\\n",
              "0 -0.512552     0.25       0.0  0.000000       0.0  0.750000        0.6   \n",
              "1  1.301115     0.00       0.0  0.000000       0.0  0.000000        0.8   \n",
              "2  0.998837     0.25       0.0  0.000000       0.0  0.833333        0.8   \n",
              "3 -0.210274     0.25       0.0  0.166667       0.0  0.166667        0.6   \n",
              "4 -0.059135     0.50       0.1  0.000000       0.0  0.666667        0.6   \n",
              "\n",
              "     Income  HighBP_0  HighBP_1  ...  Veggies_1  HvyAlcoholConsump_0  \\\n",
              "0  0.428571       0.0       1.0  ...        1.0                  1.0   \n",
              "1  0.571429       1.0       0.0  ...        1.0                  1.0   \n",
              "2  0.285714       0.0       1.0  ...        0.0                  1.0   \n",
              "3  0.714286       1.0       0.0  ...        0.0                  1.0   \n",
              "4  0.428571       1.0       0.0  ...        0.0                  1.0   \n",
              "\n",
              "   HvyAlcoholConsump_1  AnyHealthcare_0  AnyHealthcare_1  NoDocbcCost_0  \\\n",
              "0                  0.0              0.0              1.0            1.0   \n",
              "1                  0.0              0.0              1.0            1.0   \n",
              "2                  0.0              0.0              1.0            1.0   \n",
              "3                  0.0              0.0              1.0            1.0   \n",
              "4                  0.0              0.0              1.0            0.0   \n",
              "\n",
              "   NoDocbcCost_1  Sex_0  Sex_1  Diabetes_012  \n",
              "0            0.0    0.0    1.0           0.0  \n",
              "1            0.0    1.0    0.0           0.0  \n",
              "2            0.0    1.0    0.0           0.0  \n",
              "3            0.0    0.0    1.0           0.0  \n",
              "4            1.0    1.0    0.0           0.0  \n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADgjq4QlEgs3"
      },
      "source": [
        "### Extracting the input and output features from the train and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HapCibGMEgs4"
      },
      "outputs": [],
      "source": [
        "X_train = train_data.drop(['Diabetes_012'], axis=1)\n",
        "y_train = train_data['Diabetes_012']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uo2ZZ3bgEgs4"
      },
      "outputs": [],
      "source": [
        "X_test = test_data.drop(['Diabetes_012'], axis=1)\n",
        "y_test = test_data['Diabetes_012']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0Xvyy9oEgs5"
      },
      "source": [
        "### Specifying the GridSearch implementation of MLP using 5-fold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5dIRjibEgs5"
      },
      "outputs": [],
      "source": [
        "mlp_classifer = MLPClassifier()\n",
        "mlp_param_grid ={\"hidden_layer_sizes\": [(64, 64), (32, 32)],\n",
        "                \"activation\": ['relu', 'tanh'],\n",
        "                \"alpha\" : [0.01, 0.001],\n",
        "                 \"solver\": ['adam'],\n",
        "                \"random_state\": [42],\n",
        "                \"verbose\" : [True],\n",
        "                 \"max_iter\" : [30]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HiAHVjlNEgs5",
        "outputId": "e101ddda-01fb-4976-bc35-541657a2bb75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Iteration 1, loss = 0.41215235\n",
            "Iteration 2, loss = 0.39778774\n",
            "Iteration 3, loss = 0.39618769\n",
            "Iteration 4, loss = 0.39535697\n",
            "Iteration 5, loss = 0.39487084\n",
            "Iteration 6, loss = 0.39458187\n",
            "Iteration 7, loss = 0.39417605\n",
            "Iteration 8, loss = 0.39393893\n",
            "Iteration 9, loss = 0.39345163\n",
            "Iteration 10, loss = 0.39349011\n",
            "Iteration 11, loss = 0.39322113\n",
            "Iteration 12, loss = 0.39319440\n",
            "Iteration 13, loss = 0.39295578\n",
            "Iteration 14, loss = 0.39285003\n",
            "Iteration 15, loss = 0.39281676\n",
            "Iteration 16, loss = 0.39271431\n",
            "Iteration 17, loss = 0.39250340\n",
            "Iteration 18, loss = 0.39260475\n",
            "Iteration 19, loss = 0.39210460\n",
            "Iteration 20, loss = 0.39197799\n",
            "Iteration 21, loss = 0.39203662\n",
            "Iteration 22, loss = 0.39194058\n",
            "Iteration 23, loss = 0.39170519\n",
            "Iteration 24, loss = 0.39181925\n",
            "Iteration 25, loss = 0.39155634\n",
            "Iteration 26, loss = 0.39148500\n",
            "Iteration 27, loss = 0.39123007\n",
            "Iteration 28, loss = 0.39114526\n",
            "Iteration 29, loss = 0.39106276\n",
            "Iteration 30, loss = 0.39108608\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.812 total time= 1.5min\n",
            "Iteration 1, loss = 0.41205717\n",
            "Iteration 2, loss = 0.39823471\n",
            "Iteration 3, loss = 0.39660844\n",
            "Iteration 4, loss = 0.39604176\n",
            "Iteration 5, loss = 0.39534089\n",
            "Iteration 6, loss = 0.39527680\n",
            "Iteration 7, loss = 0.39470138\n",
            "Iteration 8, loss = 0.39441273\n",
            "Iteration 9, loss = 0.39419875\n",
            "Iteration 10, loss = 0.39426784\n",
            "Iteration 11, loss = 0.39379994\n",
            "Iteration 12, loss = 0.39391016\n",
            "Iteration 13, loss = 0.39351592\n",
            "Iteration 14, loss = 0.39327839\n",
            "Iteration 15, loss = 0.39336567\n",
            "Iteration 16, loss = 0.39328792\n",
            "Iteration 17, loss = 0.39294381\n",
            "Iteration 18, loss = 0.39310923\n",
            "Iteration 19, loss = 0.39272656\n",
            "Iteration 20, loss = 0.39265270\n",
            "Iteration 21, loss = 0.39260766\n",
            "Iteration 22, loss = 0.39252217\n",
            "Iteration 23, loss = 0.39236982\n",
            "Iteration 24, loss = 0.39227241\n",
            "Iteration 25, loss = 0.39220599\n",
            "Iteration 26, loss = 0.39201036\n",
            "Iteration 27, loss = 0.39199441\n",
            "Iteration 28, loss = 0.39181791\n",
            "Iteration 29, loss = 0.39181218\n",
            "Iteration 30, loss = 0.39191889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.817 total time= 1.4min\n",
            "Iteration 1, loss = 0.41252851\n",
            "Iteration 2, loss = 0.39817426\n",
            "Iteration 3, loss = 0.39670241\n",
            "Iteration 4, loss = 0.39597669\n",
            "Iteration 5, loss = 0.39547193\n",
            "Iteration 6, loss = 0.39522500\n",
            "Iteration 7, loss = 0.39458329\n",
            "Iteration 8, loss = 0.39433887\n",
            "Iteration 9, loss = 0.39410630\n",
            "Iteration 10, loss = 0.39388652\n",
            "Iteration 11, loss = 0.39358317\n",
            "Iteration 12, loss = 0.39364331\n",
            "Iteration 13, loss = 0.39325861\n",
            "Iteration 14, loss = 0.39322042\n",
            "Iteration 15, loss = 0.39306447\n",
            "Iteration 16, loss = 0.39307784\n",
            "Iteration 17, loss = 0.39278114\n",
            "Iteration 18, loss = 0.39288127\n",
            "Iteration 19, loss = 0.39244086\n",
            "Iteration 20, loss = 0.39224091\n",
            "Iteration 21, loss = 0.39237155\n",
            "Iteration 22, loss = 0.39216209\n",
            "Iteration 23, loss = 0.39190210\n",
            "Iteration 24, loss = 0.39197293\n",
            "Iteration 25, loss = 0.39197364\n",
            "Iteration 26, loss = 0.39181115\n",
            "Iteration 27, loss = 0.39184703\n",
            "Iteration 28, loss = 0.39145998\n",
            "Iteration 29, loss = 0.39160717\n",
            "Iteration 30, loss = 0.39157529\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.816 total time= 1.5min\n",
            "Iteration 1, loss = 0.41267216\n",
            "Iteration 2, loss = 0.39839539\n",
            "Iteration 3, loss = 0.39741309\n",
            "Iteration 4, loss = 0.39642334\n",
            "Iteration 5, loss = 0.39586462\n",
            "Iteration 6, loss = 0.39551491\n",
            "Iteration 7, loss = 0.39501951\n",
            "Iteration 8, loss = 0.39478195\n",
            "Iteration 9, loss = 0.39463781\n",
            "Iteration 10, loss = 0.39411372\n",
            "Iteration 11, loss = 0.39389630\n",
            "Iteration 12, loss = 0.39373905\n",
            "Iteration 13, loss = 0.39346872\n",
            "Iteration 14, loss = 0.39372553\n",
            "Iteration 15, loss = 0.39347499\n",
            "Iteration 16, loss = 0.39339824\n",
            "Iteration 17, loss = 0.39301104\n",
            "Iteration 18, loss = 0.39326266\n",
            "Iteration 19, loss = 0.39288328\n",
            "Iteration 20, loss = 0.39287852\n",
            "Iteration 21, loss = 0.39273590\n",
            "Iteration 22, loss = 0.39270717\n",
            "Iteration 23, loss = 0.39251249\n",
            "Iteration 24, loss = 0.39254478\n",
            "Iteration 25, loss = 0.39249917\n",
            "Iteration 26, loss = 0.39248662\n",
            "Iteration 27, loss = 0.39248981\n",
            "Iteration 28, loss = 0.39238231\n",
            "Iteration 29, loss = 0.39208646\n",
            "Iteration 30, loss = 0.39213983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.812 total time= 1.5min\n",
            "Iteration 1, loss = 0.41240806\n",
            "Iteration 2, loss = 0.39805465\n",
            "Iteration 3, loss = 0.39693051\n",
            "Iteration 4, loss = 0.39624233\n",
            "Iteration 5, loss = 0.39557903\n",
            "Iteration 6, loss = 0.39478741\n",
            "Iteration 7, loss = 0.39498353\n",
            "Iteration 8, loss = 0.39421234\n",
            "Iteration 9, loss = 0.39443073\n",
            "Iteration 10, loss = 0.39370157\n",
            "Iteration 11, loss = 0.39351185\n",
            "Iteration 12, loss = 0.39344205\n",
            "Iteration 13, loss = 0.39325192\n",
            "Iteration 14, loss = 0.39294189\n",
            "Iteration 15, loss = 0.39304267\n",
            "Iteration 16, loss = 0.39293459\n",
            "Iteration 17, loss = 0.39261496\n",
            "Iteration 18, loss = 0.39265504\n",
            "Iteration 19, loss = 0.39258993\n",
            "Iteration 20, loss = 0.39233244\n",
            "Iteration 21, loss = 0.39216180\n",
            "Iteration 22, loss = 0.39215198\n",
            "Iteration 23, loss = 0.39212569\n",
            "Iteration 24, loss = 0.39176085\n",
            "Iteration 25, loss = 0.39184032\n",
            "Iteration 26, loss = 0.39193700\n",
            "Iteration 27, loss = 0.39183737\n",
            "Iteration 28, loss = 0.39154953\n",
            "Iteration 29, loss = 0.39153878\n",
            "Iteration 30, loss = 0.39117524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.810 total time= 1.5min\n",
            "Iteration 1, loss = 0.42157668\n",
            "Iteration 2, loss = 0.39816506\n",
            "Iteration 3, loss = 0.39649305\n",
            "Iteration 4, loss = 0.39538959\n",
            "Iteration 5, loss = 0.39520459\n",
            "Iteration 6, loss = 0.39453142\n",
            "Iteration 7, loss = 0.39429347\n",
            "Iteration 8, loss = 0.39407722\n",
            "Iteration 9, loss = 0.39379961\n",
            "Iteration 10, loss = 0.39382632\n",
            "Iteration 11, loss = 0.39342140\n",
            "Iteration 12, loss = 0.39335638\n",
            "Iteration 13, loss = 0.39316322\n",
            "Iteration 14, loss = 0.39310465\n",
            "Iteration 15, loss = 0.39319850\n",
            "Iteration 16, loss = 0.39283035\n",
            "Iteration 17, loss = 0.39278184\n",
            "Iteration 18, loss = 0.39270822\n",
            "Iteration 19, loss = 0.39246352\n",
            "Iteration 20, loss = 0.39227624\n",
            "Iteration 21, loss = 0.39259179\n",
            "Iteration 22, loss = 0.39253332\n",
            "Iteration 23, loss = 0.39228110\n",
            "Iteration 24, loss = 0.39222552\n",
            "Iteration 25, loss = 0.39226525\n",
            "Iteration 26, loss = 0.39219665\n",
            "Iteration 27, loss = 0.39220031\n",
            "Iteration 28, loss = 0.39224293\n",
            "Iteration 29, loss = 0.39175396\n",
            "Iteration 30, loss = 0.39207469\n",
            "[CV 1/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.815 total time=  33.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.42133342\n",
            "Iteration 2, loss = 0.39831229\n",
            "Iteration 3, loss = 0.39660248\n",
            "Iteration 4, loss = 0.39567796\n",
            "Iteration 5, loss = 0.39555980\n",
            "Iteration 6, loss = 0.39482532\n",
            "Iteration 7, loss = 0.39473366\n",
            "Iteration 8, loss = 0.39432047\n",
            "Iteration 9, loss = 0.39421608\n",
            "Iteration 10, loss = 0.39436478\n",
            "Iteration 11, loss = 0.39394294\n",
            "Iteration 12, loss = 0.39380078\n",
            "Iteration 13, loss = 0.39355556\n",
            "Iteration 14, loss = 0.39361885\n",
            "Iteration 15, loss = 0.39363949\n",
            "Iteration 16, loss = 0.39342767\n",
            "Iteration 17, loss = 0.39322646\n",
            "Iteration 18, loss = 0.39323831\n",
            "Iteration 19, loss = 0.39300161\n",
            "Iteration 20, loss = 0.39296120\n",
            "Iteration 21, loss = 0.39327766\n",
            "Iteration 22, loss = 0.39307174\n",
            "Iteration 23, loss = 0.39288692\n",
            "Iteration 24, loss = 0.39288451\n",
            "Iteration 25, loss = 0.39290515\n",
            "Iteration 26, loss = 0.39277494\n",
            "Iteration 27, loss = 0.39271277\n",
            "Iteration 28, loss = 0.39263076\n",
            "Iteration 29, loss = 0.39247931\n",
            "Iteration 30, loss = 0.39258242\n",
            "[CV 2/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.813 total time=  36.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.42157173\n",
            "Iteration 2, loss = 0.39827025\n",
            "Iteration 3, loss = 0.39647900\n",
            "Iteration 4, loss = 0.39575095\n",
            "Iteration 5, loss = 0.39530361\n",
            "Iteration 6, loss = 0.39490621\n",
            "Iteration 7, loss = 0.39455685\n",
            "Iteration 8, loss = 0.39423634\n",
            "Iteration 9, loss = 0.39420943\n",
            "Iteration 10, loss = 0.39402253\n",
            "Iteration 11, loss = 0.39388901\n",
            "Iteration 12, loss = 0.39382459\n",
            "Iteration 13, loss = 0.39352579\n",
            "Iteration 14, loss = 0.39364868\n",
            "Iteration 15, loss = 0.39334444\n",
            "Iteration 16, loss = 0.39340879\n",
            "Iteration 17, loss = 0.39301094\n",
            "Iteration 18, loss = 0.39311841\n",
            "Iteration 19, loss = 0.39314282\n",
            "Iteration 20, loss = 0.39291979\n",
            "Iteration 21, loss = 0.39318863\n",
            "Iteration 22, loss = 0.39290586\n",
            "Iteration 23, loss = 0.39266116\n",
            "Iteration 24, loss = 0.39275905\n",
            "Iteration 25, loss = 0.39256231\n",
            "Iteration 26, loss = 0.39282681\n",
            "Iteration 27, loss = 0.39275346\n",
            "Iteration 28, loss = 0.39253851\n",
            "Iteration 29, loss = 0.39245163\n",
            "Iteration 30, loss = 0.39238601\n",
            "[CV 3/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.814 total time=  33.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.42193471\n",
            "Iteration 2, loss = 0.39847610\n",
            "Iteration 3, loss = 0.39702168\n",
            "Iteration 4, loss = 0.39623367\n",
            "Iteration 5, loss = 0.39576998\n",
            "Iteration 6, loss = 0.39535862\n",
            "Iteration 7, loss = 0.39486739\n",
            "Iteration 8, loss = 0.39452884\n",
            "Iteration 9, loss = 0.39447191\n",
            "Iteration 10, loss = 0.39436139\n",
            "Iteration 11, loss = 0.39419995\n",
            "Iteration 12, loss = 0.39414556\n",
            "Iteration 13, loss = 0.39377131\n",
            "Iteration 14, loss = 0.39390115\n",
            "Iteration 15, loss = 0.39365560\n",
            "Iteration 16, loss = 0.39349808\n",
            "Iteration 17, loss = 0.39344028\n",
            "Iteration 18, loss = 0.39355864\n",
            "Iteration 19, loss = 0.39342924\n",
            "Iteration 20, loss = 0.39340945\n",
            "Iteration 21, loss = 0.39342799\n",
            "Iteration 22, loss = 0.39316157\n",
            "Iteration 23, loss = 0.39291005\n",
            "Iteration 24, loss = 0.39305147\n",
            "Iteration 25, loss = 0.39307076\n",
            "Iteration 26, loss = 0.39314852\n",
            "Iteration 27, loss = 0.39297165\n",
            "Iteration 28, loss = 0.39278399\n",
            "Iteration 29, loss = 0.39282062\n",
            "Iteration 30, loss = 0.39256988\n",
            "[CV 4/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.812 total time=  34.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.42101610\n",
            "Iteration 2, loss = 0.39873191\n",
            "Iteration 3, loss = 0.39703132\n",
            "Iteration 4, loss = 0.39627828\n",
            "Iteration 5, loss = 0.39550149\n",
            "Iteration 6, loss = 0.39526972\n",
            "Iteration 7, loss = 0.39483898\n",
            "Iteration 8, loss = 0.39449751\n",
            "Iteration 9, loss = 0.39433320\n",
            "Iteration 10, loss = 0.39419144\n",
            "Iteration 11, loss = 0.39402516\n",
            "Iteration 12, loss = 0.39386545\n",
            "Iteration 13, loss = 0.39389949\n",
            "Iteration 14, loss = 0.39364384\n",
            "Iteration 15, loss = 0.39342469\n",
            "Iteration 16, loss = 0.39337087\n",
            "Iteration 17, loss = 0.39335658\n",
            "Iteration 18, loss = 0.39321120\n",
            "Iteration 19, loss = 0.39304794\n",
            "Iteration 20, loss = 0.39315771\n",
            "Iteration 21, loss = 0.39296076\n",
            "Iteration 22, loss = 0.39276718\n",
            "Iteration 23, loss = 0.39271984\n",
            "Iteration 24, loss = 0.39279065\n",
            "Iteration 25, loss = 0.39286350\n",
            "Iteration 26, loss = 0.39245929\n",
            "Iteration 27, loss = 0.39245031\n",
            "Iteration 28, loss = 0.39248441\n",
            "Iteration 29, loss = 0.39233855\n",
            "Iteration 30, loss = 0.39233816\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.807 total time=  36.1s\n",
            "Iteration 1, loss = 0.40975776\n",
            "Iteration 2, loss = 0.39563555\n",
            "Iteration 3, loss = 0.39417381\n",
            "Iteration 4, loss = 0.39347747\n",
            "Iteration 5, loss = 0.39308374\n",
            "Iteration 6, loss = 0.39278484\n",
            "Iteration 7, loss = 0.39241613\n",
            "Iteration 8, loss = 0.39221013\n",
            "Iteration 9, loss = 0.39169883\n",
            "Iteration 10, loss = 0.39164282\n",
            "Iteration 11, loss = 0.39127062\n",
            "Iteration 12, loss = 0.39108424\n",
            "Iteration 13, loss = 0.39086657\n",
            "Iteration 14, loss = 0.39057868\n",
            "Iteration 15, loss = 0.39043715\n",
            "Iteration 16, loss = 0.39027227\n",
            "Iteration 17, loss = 0.38992760\n",
            "Iteration 18, loss = 0.38990974\n",
            "Iteration 19, loss = 0.38927702\n",
            "Iteration 20, loss = 0.38907609\n",
            "Iteration 21, loss = 0.38897041\n",
            "Iteration 22, loss = 0.38875669\n",
            "Iteration 23, loss = 0.38845182\n",
            "Iteration 24, loss = 0.38827287\n",
            "Iteration 25, loss = 0.38793466\n",
            "Iteration 26, loss = 0.38764473\n",
            "Iteration 27, loss = 0.38733781\n",
            "Iteration 28, loss = 0.38698058\n",
            "Iteration 29, loss = 0.38692444\n",
            "Iteration 30, loss = 0.38679838\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.812 total time= 1.4min\n",
            "Iteration 1, loss = 0.40967098\n",
            "Iteration 2, loss = 0.39618311\n",
            "Iteration 3, loss = 0.39466196\n",
            "Iteration 4, loss = 0.39419834\n",
            "Iteration 5, loss = 0.39354292\n",
            "Iteration 6, loss = 0.39349984\n",
            "Iteration 7, loss = 0.39294238\n",
            "Iteration 8, loss = 0.39262408\n",
            "Iteration 9, loss = 0.39242656\n",
            "Iteration 10, loss = 0.39238220\n",
            "Iteration 11, loss = 0.39181076\n",
            "Iteration 12, loss = 0.39186784\n",
            "Iteration 13, loss = 0.39147341\n",
            "Iteration 14, loss = 0.39102675\n",
            "Iteration 15, loss = 0.39105767\n",
            "Iteration 16, loss = 0.39085580\n",
            "Iteration 17, loss = 0.39042199\n",
            "Iteration 18, loss = 0.39047546\n",
            "Iteration 19, loss = 0.39003591\n",
            "Iteration 20, loss = 0.38986398\n",
            "Iteration 21, loss = 0.38965066\n",
            "Iteration 22, loss = 0.38928802\n",
            "Iteration 23, loss = 0.38903210\n",
            "Iteration 24, loss = 0.38884413\n",
            "Iteration 25, loss = 0.38866638\n",
            "Iteration 26, loss = 0.38838459\n",
            "Iteration 27, loss = 0.38798499\n",
            "Iteration 28, loss = 0.38780099\n",
            "Iteration 29, loss = 0.38768230\n",
            "Iteration 30, loss = 0.38747502\n",
            "[CV 2/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.816 total time= 1.4min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.41020761\n",
            "Iteration 2, loss = 0.39616465\n",
            "Iteration 3, loss = 0.39473347\n",
            "Iteration 4, loss = 0.39413401\n",
            "Iteration 5, loss = 0.39357110\n",
            "Iteration 6, loss = 0.39344033\n",
            "Iteration 7, loss = 0.39273106\n",
            "Iteration 8, loss = 0.39246572\n",
            "Iteration 9, loss = 0.39226881\n",
            "Iteration 10, loss = 0.39200183\n",
            "Iteration 11, loss = 0.39164338\n",
            "Iteration 12, loss = 0.39163952\n",
            "Iteration 13, loss = 0.39113731\n",
            "Iteration 14, loss = 0.39096623\n",
            "Iteration 15, loss = 0.39074208\n",
            "Iteration 16, loss = 0.39059461\n",
            "Iteration 17, loss = 0.39028231\n",
            "Iteration 18, loss = 0.39021304\n",
            "Iteration 19, loss = 0.38957728\n",
            "Iteration 20, loss = 0.38937526\n",
            "Iteration 21, loss = 0.38933097\n",
            "Iteration 22, loss = 0.38896426\n",
            "Iteration 23, loss = 0.38849224\n",
            "Iteration 24, loss = 0.38846031\n",
            "Iteration 25, loss = 0.38822688\n",
            "Iteration 26, loss = 0.38795526\n",
            "Iteration 27, loss = 0.38785221\n",
            "Iteration 28, loss = 0.38729664\n",
            "Iteration 29, loss = 0.38725502\n",
            "Iteration 30, loss = 0.38701225\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.815 total time= 1.3min\n",
            "Iteration 1, loss = 0.41026949\n",
            "Iteration 2, loss = 0.39627789\n",
            "Iteration 3, loss = 0.39550755\n",
            "Iteration 4, loss = 0.39454500\n",
            "Iteration 5, loss = 0.39403564\n",
            "Iteration 6, loss = 0.39370189\n",
            "Iteration 7, loss = 0.39316632\n",
            "Iteration 8, loss = 0.39288865\n",
            "Iteration 9, loss = 0.39273659\n",
            "Iteration 10, loss = 0.39209759\n",
            "Iteration 11, loss = 0.39186153\n",
            "Iteration 12, loss = 0.39166638\n",
            "Iteration 13, loss = 0.39122814\n",
            "Iteration 14, loss = 0.39142058\n",
            "Iteration 15, loss = 0.39103722\n",
            "Iteration 16, loss = 0.39087118\n",
            "Iteration 17, loss = 0.39036342\n",
            "Iteration 18, loss = 0.39043035\n",
            "Iteration 19, loss = 0.38983547\n",
            "Iteration 20, loss = 0.38971484\n",
            "Iteration 21, loss = 0.38940489\n",
            "Iteration 22, loss = 0.38919625\n",
            "Iteration 23, loss = 0.38871622\n",
            "Iteration 24, loss = 0.38867485\n",
            "Iteration 25, loss = 0.38835435\n",
            "Iteration 26, loss = 0.38815241\n",
            "Iteration 27, loss = 0.38794268\n",
            "Iteration 28, loss = 0.38779732\n",
            "Iteration 29, loss = 0.38732625\n",
            "Iteration 30, loss = 0.38704380\n",
            "[CV 4/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.814 total time= 1.4min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.41003082\n",
            "Iteration 2, loss = 0.39604110\n",
            "Iteration 3, loss = 0.39508625\n",
            "Iteration 4, loss = 0.39450091\n",
            "Iteration 5, loss = 0.39386695\n",
            "Iteration 6, loss = 0.39312558\n",
            "Iteration 7, loss = 0.39320008\n",
            "Iteration 8, loss = 0.39244856\n",
            "Iteration 9, loss = 0.39252904\n",
            "Iteration 10, loss = 0.39167328\n",
            "Iteration 11, loss = 0.39153066\n",
            "Iteration 12, loss = 0.39127030\n",
            "Iteration 13, loss = 0.39095161\n",
            "Iteration 14, loss = 0.39046390\n",
            "Iteration 15, loss = 0.39055691\n",
            "Iteration 16, loss = 0.39013215\n",
            "Iteration 17, loss = 0.38987905\n",
            "Iteration 18, loss = 0.38974163\n",
            "Iteration 19, loss = 0.38959241\n",
            "Iteration 20, loss = 0.38900715\n",
            "Iteration 21, loss = 0.38880980\n",
            "Iteration 22, loss = 0.38857057\n",
            "Iteration 23, loss = 0.38846818\n",
            "Iteration 24, loss = 0.38797013\n",
            "Iteration 25, loss = 0.38793414\n",
            "Iteration 26, loss = 0.38774713\n",
            "Iteration 27, loss = 0.38761534\n",
            "Iteration 28, loss = 0.38718633\n",
            "Iteration 29, loss = 0.38703233\n",
            "Iteration 30, loss = 0.38656375\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.810 total time= 1.4min\n",
            "Iteration 1, loss = 0.42007843\n",
            "Iteration 2, loss = 0.39673511\n",
            "Iteration 3, loss = 0.39512400\n",
            "Iteration 4, loss = 0.39408945\n",
            "Iteration 5, loss = 0.39391409\n",
            "Iteration 6, loss = 0.39317668\n",
            "Iteration 7, loss = 0.39291447\n",
            "Iteration 8, loss = 0.39272992\n",
            "Iteration 9, loss = 0.39242027\n",
            "Iteration 10, loss = 0.39238886\n",
            "Iteration 11, loss = 0.39196287\n",
            "Iteration 12, loss = 0.39187497\n",
            "Iteration 13, loss = 0.39169805\n",
            "Iteration 14, loss = 0.39158519\n",
            "Iteration 15, loss = 0.39162077\n",
            "Iteration 16, loss = 0.39118666\n",
            "Iteration 17, loss = 0.39127269\n",
            "Iteration 18, loss = 0.39108734\n",
            "Iteration 19, loss = 0.39088743\n",
            "Iteration 20, loss = 0.39059839\n",
            "Iteration 21, loss = 0.39094968\n",
            "Iteration 22, loss = 0.39084915\n",
            "Iteration 23, loss = 0.39049596\n",
            "Iteration 24, loss = 0.39047819\n",
            "Iteration 25, loss = 0.39043252\n",
            "Iteration 26, loss = 0.39035140\n",
            "Iteration 27, loss = 0.39025519\n",
            "Iteration 28, loss = 0.39036160\n",
            "Iteration 29, loss = 0.38986276\n",
            "Iteration 30, loss = 0.39004622\n",
            "[CV 1/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.815 total time=  32.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.41982139\n",
            "Iteration 2, loss = 0.39692294\n",
            "Iteration 3, loss = 0.39526648\n",
            "Iteration 4, loss = 0.39430716\n",
            "Iteration 5, loss = 0.39427634\n",
            "Iteration 6, loss = 0.39352757\n",
            "Iteration 7, loss = 0.39334352\n",
            "Iteration 8, loss = 0.39296876\n",
            "Iteration 9, loss = 0.39280016\n",
            "Iteration 10, loss = 0.39288073\n",
            "Iteration 11, loss = 0.39241078\n",
            "Iteration 12, loss = 0.39225236\n",
            "Iteration 13, loss = 0.39200554\n",
            "Iteration 14, loss = 0.39207903\n",
            "Iteration 15, loss = 0.39201254\n",
            "Iteration 16, loss = 0.39172122\n",
            "Iteration 17, loss = 0.39161788\n",
            "Iteration 18, loss = 0.39151952\n",
            "Iteration 19, loss = 0.39127833\n",
            "Iteration 20, loss = 0.39114516\n",
            "Iteration 21, loss = 0.39140140\n",
            "Iteration 22, loss = 0.39114046\n",
            "Iteration 23, loss = 0.39093967\n",
            "Iteration 24, loss = 0.39094168\n",
            "Iteration 25, loss = 0.39096006\n",
            "Iteration 26, loss = 0.39079779\n",
            "Iteration 27, loss = 0.39071343\n",
            "Iteration 28, loss = 0.39059935\n",
            "Iteration 29, loss = 0.39037859\n",
            "Iteration 30, loss = 0.39050065\n",
            "[CV 2/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.813 total time=  32.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.42010214\n",
            "Iteration 2, loss = 0.39689836\n",
            "Iteration 3, loss = 0.39520142\n",
            "Iteration 4, loss = 0.39443200\n",
            "Iteration 5, loss = 0.39407604\n",
            "Iteration 6, loss = 0.39364211\n",
            "Iteration 7, loss = 0.39331952\n",
            "Iteration 8, loss = 0.39305761\n",
            "Iteration 9, loss = 0.39295979\n",
            "Iteration 10, loss = 0.39277935\n",
            "Iteration 11, loss = 0.39253788\n",
            "Iteration 12, loss = 0.39244266\n",
            "Iteration 13, loss = 0.39209669\n",
            "Iteration 14, loss = 0.39214955\n",
            "Iteration 15, loss = 0.39186542\n",
            "Iteration 16, loss = 0.39185003\n",
            "Iteration 17, loss = 0.39145607\n",
            "Iteration 18, loss = 0.39141746\n",
            "Iteration 19, loss = 0.39142379\n",
            "Iteration 20, loss = 0.39118194\n",
            "Iteration 21, loss = 0.39141409\n",
            "Iteration 22, loss = 0.39113638\n",
            "Iteration 23, loss = 0.39085976\n",
            "Iteration 24, loss = 0.39098818\n",
            "Iteration 25, loss = 0.39073568\n",
            "Iteration 26, loss = 0.39090048\n",
            "Iteration 27, loss = 0.39078179\n",
            "Iteration 28, loss = 0.39049771\n",
            "Iteration 29, loss = 0.39040962\n",
            "Iteration 30, loss = 0.39022158\n",
            "[CV 3/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.813 total time=  32.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.42048741\n",
            "Iteration 2, loss = 0.39711614\n",
            "Iteration 3, loss = 0.39559824\n",
            "Iteration 4, loss = 0.39481560\n",
            "Iteration 5, loss = 0.39436528\n",
            "Iteration 6, loss = 0.39398030\n",
            "Iteration 7, loss = 0.39349259\n",
            "Iteration 8, loss = 0.39311814\n",
            "Iteration 9, loss = 0.39301365\n",
            "Iteration 10, loss = 0.39289506\n",
            "Iteration 11, loss = 0.39264808\n",
            "Iteration 12, loss = 0.39259838\n",
            "Iteration 13, loss = 0.39223945\n",
            "Iteration 14, loss = 0.39225031\n",
            "Iteration 15, loss = 0.39198230\n",
            "Iteration 16, loss = 0.39184985\n",
            "Iteration 17, loss = 0.39173316\n",
            "Iteration 18, loss = 0.39175557\n",
            "Iteration 19, loss = 0.39158839\n",
            "Iteration 20, loss = 0.39153195\n",
            "Iteration 21, loss = 0.39155794\n",
            "Iteration 22, loss = 0.39125220\n",
            "Iteration 23, loss = 0.39098292\n",
            "Iteration 24, loss = 0.39108401\n",
            "Iteration 25, loss = 0.39095352\n",
            "Iteration 26, loss = 0.39107391\n",
            "Iteration 27, loss = 0.39078849\n",
            "Iteration 28, loss = 0.39065078\n",
            "Iteration 29, loss = 0.39064536\n",
            "Iteration 30, loss = 0.39035935\n",
            "[CV 4/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.811 total time=  32.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.41955201\n",
            "Iteration 2, loss = 0.39739242\n",
            "Iteration 3, loss = 0.39565266\n",
            "Iteration 4, loss = 0.39494313\n",
            "Iteration 5, loss = 0.39419321\n",
            "Iteration 6, loss = 0.39394483\n",
            "Iteration 7, loss = 0.39358534\n",
            "Iteration 8, loss = 0.39330970\n",
            "Iteration 9, loss = 0.39305603\n",
            "Iteration 10, loss = 0.39294784\n",
            "Iteration 11, loss = 0.39271222\n",
            "Iteration 12, loss = 0.39257281\n",
            "Iteration 13, loss = 0.39254224\n",
            "Iteration 14, loss = 0.39231247\n",
            "Iteration 15, loss = 0.39204717\n",
            "Iteration 16, loss = 0.39197775\n",
            "Iteration 17, loss = 0.39182562\n",
            "Iteration 18, loss = 0.39170463\n",
            "Iteration 19, loss = 0.39153587\n",
            "Iteration 20, loss = 0.39163899\n",
            "Iteration 21, loss = 0.39138820\n",
            "Iteration 22, loss = 0.39123671\n",
            "Iteration 23, loss = 0.39122037\n",
            "Iteration 24, loss = 0.39125647\n",
            "Iteration 25, loss = 0.39123896\n",
            "Iteration 26, loss = 0.39082597\n",
            "Iteration 27, loss = 0.39076613\n",
            "Iteration 28, loss = 0.39072567\n",
            "Iteration 29, loss = 0.39054837\n",
            "Iteration 30, loss = 0.39052966\n",
            "[CV 5/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.806 total time=  32.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.41235564\n",
            "Iteration 2, loss = 0.40029054\n",
            "Iteration 3, loss = 0.39825124\n",
            "Iteration 4, loss = 0.39740347\n",
            "Iteration 5, loss = 0.39682445\n",
            "Iteration 6, loss = 0.39656099\n",
            "Iteration 7, loss = 0.39611495\n",
            "Iteration 8, loss = 0.39587042\n",
            "Iteration 9, loss = 0.39545403\n",
            "Iteration 10, loss = 0.39540949\n",
            "Iteration 11, loss = 0.39516971\n",
            "Iteration 12, loss = 0.39509047\n",
            "Iteration 13, loss = 0.39496723\n",
            "Iteration 14, loss = 0.39481755\n",
            "Iteration 15, loss = 0.39474822\n",
            "Iteration 16, loss = 0.39470281\n",
            "Iteration 17, loss = 0.39448929\n",
            "Iteration 18, loss = 0.39471836\n",
            "Iteration 19, loss = 0.39405725\n",
            "Iteration 20, loss = 0.39408203\n",
            "Iteration 21, loss = 0.39410285\n",
            "Iteration 22, loss = 0.39410265\n",
            "Iteration 23, loss = 0.39408204\n",
            "Iteration 24, loss = 0.39407417\n",
            "Iteration 25, loss = 0.39395348\n",
            "Iteration 26, loss = 0.39377408\n",
            "Iteration 27, loss = 0.39370041\n",
            "Iteration 28, loss = 0.39350468\n",
            "Iteration 29, loss = 0.39354548\n",
            "Iteration 30, loss = 0.39373943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.809 total time= 2.2min\n",
            "Iteration 1, loss = 0.41259078\n",
            "Iteration 2, loss = 0.40086320\n",
            "Iteration 3, loss = 0.39866104\n",
            "Iteration 4, loss = 0.39784904\n",
            "Iteration 5, loss = 0.39720327\n",
            "Iteration 6, loss = 0.39715832\n",
            "Iteration 7, loss = 0.39648999\n",
            "Iteration 8, loss = 0.39622804\n",
            "Iteration 9, loss = 0.39602549\n",
            "Iteration 10, loss = 0.39612957\n",
            "Iteration 11, loss = 0.39566428\n",
            "Iteration 12, loss = 0.39578220\n",
            "Iteration 13, loss = 0.39552075\n",
            "Iteration 14, loss = 0.39510302\n",
            "Iteration 15, loss = 0.39537456\n",
            "Iteration 16, loss = 0.39514788\n",
            "Iteration 17, loss = 0.39491759\n",
            "Iteration 18, loss = 0.39506306\n",
            "Iteration 19, loss = 0.39472170\n",
            "Iteration 20, loss = 0.39461162\n",
            "Iteration 21, loss = 0.39473232\n",
            "Iteration 22, loss = 0.39466706\n",
            "Iteration 23, loss = 0.39444506\n",
            "Iteration 24, loss = 0.39444649\n",
            "Iteration 25, loss = 0.39463114\n",
            "Iteration 26, loss = 0.39420670\n",
            "Iteration 27, loss = 0.39433652\n",
            "Iteration 28, loss = 0.39408930\n",
            "Iteration 29, loss = 0.39416379\n",
            "Iteration 30, loss = 0.39435545\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.813 total time= 2.1min\n",
            "Iteration 1, loss = 0.41311561\n",
            "Iteration 2, loss = 0.40079994\n",
            "Iteration 3, loss = 0.39882742\n",
            "Iteration 4, loss = 0.39783642\n",
            "Iteration 5, loss = 0.39719492\n",
            "Iteration 6, loss = 0.39716361\n",
            "Iteration 7, loss = 0.39637509\n",
            "Iteration 8, loss = 0.39612156\n",
            "Iteration 9, loss = 0.39599085\n",
            "Iteration 10, loss = 0.39571399\n",
            "Iteration 11, loss = 0.39557348\n",
            "Iteration 12, loss = 0.39551859\n",
            "Iteration 13, loss = 0.39522498\n",
            "Iteration 14, loss = 0.39516811\n",
            "Iteration 15, loss = 0.39516522\n",
            "Iteration 16, loss = 0.39508496\n",
            "Iteration 17, loss = 0.39485301\n",
            "Iteration 18, loss = 0.39498861\n",
            "Iteration 19, loss = 0.39453133\n",
            "Iteration 20, loss = 0.39446645\n",
            "Iteration 21, loss = 0.39453392\n",
            "Iteration 22, loss = 0.39451510\n",
            "Iteration 23, loss = 0.39412821\n",
            "Iteration 24, loss = 0.39434118\n",
            "Iteration 25, loss = 0.39443224\n",
            "Iteration 26, loss = 0.39426347\n",
            "Iteration 27, loss = 0.39432884\n",
            "Iteration 28, loss = 0.39398183\n",
            "Iteration 29, loss = 0.39414073\n",
            "Iteration 30, loss = 0.39430831\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.814 total time= 2.2min\n",
            "Iteration 1, loss = 0.41340309\n",
            "Iteration 2, loss = 0.40078950\n",
            "Iteration 3, loss = 0.39943883\n",
            "Iteration 4, loss = 0.39830466\n",
            "Iteration 5, loss = 0.39760588\n",
            "Iteration 6, loss = 0.39736651\n",
            "Iteration 7, loss = 0.39694046\n",
            "Iteration 8, loss = 0.39669637\n",
            "Iteration 9, loss = 0.39656677\n",
            "Iteration 10, loss = 0.39613542\n",
            "Iteration 11, loss = 0.39588595\n",
            "Iteration 12, loss = 0.39578006\n",
            "Iteration 13, loss = 0.39558428\n",
            "Iteration 14, loss = 0.39580524\n",
            "Iteration 15, loss = 0.39552717\n",
            "Iteration 16, loss = 0.39546453\n",
            "Iteration 17, loss = 0.39515366\n",
            "Iteration 18, loss = 0.39534401\n",
            "Iteration 19, loss = 0.39497866\n",
            "Iteration 20, loss = 0.39483575\n",
            "Iteration 21, loss = 0.39482612\n",
            "Iteration 22, loss = 0.39478176\n",
            "Iteration 23, loss = 0.39455422\n",
            "Iteration 24, loss = 0.39466038\n",
            "Iteration 25, loss = 0.39469568\n",
            "Iteration 26, loss = 0.39454433\n",
            "Iteration 27, loss = 0.39456756\n",
            "Iteration 28, loss = 0.39470806\n",
            "Iteration 29, loss = 0.39420797\n",
            "Iteration 30, loss = 0.39443992\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.809 total time= 2.1min\n",
            "Iteration 1, loss = 0.41341949\n",
            "Iteration 2, loss = 0.40058042\n",
            "Iteration 3, loss = 0.39929787\n",
            "Iteration 4, loss = 0.39816382\n",
            "Iteration 5, loss = 0.39755942\n",
            "Iteration 6, loss = 0.39687137\n",
            "Iteration 7, loss = 0.39702784\n",
            "Iteration 8, loss = 0.39634180\n",
            "Iteration 9, loss = 0.39648844\n",
            "Iteration 10, loss = 0.39572208\n",
            "Iteration 11, loss = 0.39562350\n",
            "Iteration 12, loss = 0.39551418\n",
            "Iteration 13, loss = 0.39539319\n",
            "Iteration 14, loss = 0.39501127\n",
            "Iteration 15, loss = 0.39528302\n",
            "Iteration 16, loss = 0.39524273\n",
            "Iteration 17, loss = 0.39497307\n",
            "Iteration 18, loss = 0.39482678\n",
            "Iteration 19, loss = 0.39479637\n",
            "Iteration 20, loss = 0.39456133\n",
            "Iteration 21, loss = 0.39438076\n",
            "Iteration 22, loss = 0.39447748\n",
            "Iteration 23, loss = 0.39444688\n",
            "Iteration 24, loss = 0.39419573\n",
            "Iteration 25, loss = 0.39422327\n",
            "Iteration 26, loss = 0.39429517\n",
            "Iteration 27, loss = 0.39444569\n",
            "Iteration 28, loss = 0.39417765\n",
            "Iteration 29, loss = 0.39402192\n",
            "Iteration 30, loss = 0.39374509\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.805 total time= 2.1min\n",
            "Iteration 1, loss = 0.42076553\n",
            "Iteration 2, loss = 0.39882559\n",
            "Iteration 3, loss = 0.39739276\n",
            "Iteration 4, loss = 0.39652953\n",
            "Iteration 5, loss = 0.39626891\n",
            "Iteration 6, loss = 0.39549947\n",
            "Iteration 7, loss = 0.39523366\n",
            "Iteration 8, loss = 0.39509871\n",
            "Iteration 9, loss = 0.39490614\n",
            "Iteration 10, loss = 0.39471314\n",
            "Iteration 11, loss = 0.39442160\n",
            "Iteration 12, loss = 0.39432755\n",
            "Iteration 13, loss = 0.39428606\n",
            "Iteration 14, loss = 0.39409733\n",
            "Iteration 15, loss = 0.39437505\n",
            "Iteration 16, loss = 0.39382949\n",
            "Iteration 17, loss = 0.39391828\n",
            "Iteration 18, loss = 0.39386319\n",
            "Iteration 19, loss = 0.39356512\n",
            "Iteration 20, loss = 0.39337169\n",
            "Iteration 21, loss = 0.39369837\n",
            "Iteration 22, loss = 0.39364255\n",
            "Iteration 23, loss = 0.39327896\n",
            "Iteration 24, loss = 0.39326749\n",
            "Iteration 25, loss = 0.39324445\n",
            "Iteration 26, loss = 0.39324768\n",
            "Iteration 27, loss = 0.39324360\n",
            "Iteration 28, loss = 0.39325852\n",
            "Iteration 29, loss = 0.39275852\n",
            "Iteration 30, loss = 0.39310886\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.817 total time=  49.2s\n",
            "Iteration 1, loss = 0.42066431\n",
            "Iteration 2, loss = 0.39904348\n",
            "Iteration 3, loss = 0.39765828\n",
            "Iteration 4, loss = 0.39689968\n",
            "Iteration 5, loss = 0.39673926\n",
            "Iteration 6, loss = 0.39594373\n",
            "Iteration 7, loss = 0.39584019\n",
            "Iteration 8, loss = 0.39548967\n",
            "Iteration 9, loss = 0.39527100\n",
            "Iteration 10, loss = 0.39538708\n",
            "Iteration 11, loss = 0.39506814\n",
            "Iteration 12, loss = 0.39487719\n",
            "Iteration 13, loss = 0.39464904\n",
            "Iteration 14, loss = 0.39471928\n",
            "Iteration 15, loss = 0.39475111\n",
            "Iteration 16, loss = 0.39441333\n",
            "Iteration 17, loss = 0.39440223\n",
            "Iteration 18, loss = 0.39434808\n",
            "Iteration 19, loss = 0.39406421\n",
            "Iteration 20, loss = 0.39398709\n",
            "Iteration 21, loss = 0.39430029\n",
            "Iteration 22, loss = 0.39404571\n",
            "Iteration 23, loss = 0.39389168\n",
            "Iteration 24, loss = 0.39392808\n",
            "Iteration 25, loss = 0.39408571\n",
            "Iteration 26, loss = 0.39383837\n",
            "Iteration 27, loss = 0.39378042\n",
            "Iteration 28, loss = 0.39371364\n",
            "Iteration 29, loss = 0.39352648\n",
            "Iteration 30, loss = 0.39364586\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.812 total time=  50.6s\n",
            "Iteration 1, loss = 0.42108586\n",
            "Iteration 2, loss = 0.39904774\n",
            "Iteration 3, loss = 0.39764127\n",
            "Iteration 4, loss = 0.39701488\n",
            "Iteration 5, loss = 0.39655655\n",
            "Iteration 6, loss = 0.39614147\n",
            "Iteration 7, loss = 0.39582343\n",
            "Iteration 8, loss = 0.39542667\n",
            "Iteration 9, loss = 0.39535007\n",
            "Iteration 10, loss = 0.39509531\n",
            "Iteration 11, loss = 0.39509337\n",
            "Iteration 12, loss = 0.39497190\n",
            "Iteration 13, loss = 0.39469131\n",
            "Iteration 14, loss = 0.39481702\n",
            "Iteration 15, loss = 0.39449839\n",
            "Iteration 16, loss = 0.39448850\n",
            "Iteration 17, loss = 0.39417380\n",
            "Iteration 18, loss = 0.39426563\n",
            "Iteration 19, loss = 0.39426835\n",
            "Iteration 20, loss = 0.39396957\n",
            "Iteration 21, loss = 0.39425480\n",
            "Iteration 22, loss = 0.39399650\n",
            "Iteration 23, loss = 0.39377262\n",
            "Iteration 24, loss = 0.39390408\n",
            "Iteration 25, loss = 0.39370702\n",
            "Iteration 26, loss = 0.39394248\n",
            "Iteration 27, loss = 0.39371859\n",
            "Iteration 28, loss = 0.39360260\n",
            "Iteration 29, loss = 0.39356521\n",
            "Iteration 30, loss = 0.39341650\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.813 total time=  50.1s\n",
            "Iteration 1, loss = 0.42110535\n",
            "Iteration 2, loss = 0.39925955\n",
            "Iteration 3, loss = 0.39811789\n",
            "Iteration 4, loss = 0.39731834\n",
            "Iteration 5, loss = 0.39673417\n",
            "Iteration 6, loss = 0.39651047\n",
            "Iteration 7, loss = 0.39611879\n",
            "Iteration 8, loss = 0.39570064\n",
            "Iteration 9, loss = 0.39558980\n",
            "Iteration 10, loss = 0.39551039\n",
            "Iteration 11, loss = 0.39535747\n",
            "Iteration 12, loss = 0.39529264\n",
            "Iteration 13, loss = 0.39489582\n",
            "Iteration 14, loss = 0.39505367\n",
            "Iteration 15, loss = 0.39469800\n",
            "Iteration 16, loss = 0.39455613\n",
            "Iteration 17, loss = 0.39460634\n",
            "Iteration 18, loss = 0.39467062\n",
            "Iteration 19, loss = 0.39458976\n",
            "Iteration 20, loss = 0.39449673\n",
            "Iteration 21, loss = 0.39461546\n",
            "Iteration 22, loss = 0.39436526\n",
            "Iteration 23, loss = 0.39415428\n",
            "Iteration 24, loss = 0.39420784\n",
            "Iteration 25, loss = 0.39431528\n",
            "Iteration 26, loss = 0.39439316\n",
            "Iteration 27, loss = 0.39414086\n",
            "Iteration 28, loss = 0.39401797\n",
            "Iteration 29, loss = 0.39402795\n",
            "Iteration 30, loss = 0.39379627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.811 total time=  49.2s\n",
            "Iteration 1, loss = 0.42050526\n",
            "Iteration 2, loss = 0.39939326\n",
            "Iteration 3, loss = 0.39802742\n",
            "Iteration 4, loss = 0.39736818\n",
            "Iteration 5, loss = 0.39653807\n",
            "Iteration 6, loss = 0.39637649\n",
            "Iteration 7, loss = 0.39596630\n",
            "Iteration 8, loss = 0.39575188\n",
            "Iteration 9, loss = 0.39546831\n",
            "Iteration 10, loss = 0.39542730\n",
            "Iteration 11, loss = 0.39509964\n",
            "Iteration 12, loss = 0.39495418\n",
            "Iteration 13, loss = 0.39499975\n",
            "Iteration 14, loss = 0.39479095\n",
            "Iteration 15, loss = 0.39459232\n",
            "Iteration 16, loss = 0.39452034\n",
            "Iteration 17, loss = 0.39439714\n",
            "Iteration 18, loss = 0.39434277\n",
            "Iteration 19, loss = 0.39414484\n",
            "Iteration 20, loss = 0.39422149\n",
            "Iteration 21, loss = 0.39410086\n",
            "Iteration 22, loss = 0.39400425\n",
            "Iteration 23, loss = 0.39383895\n",
            "Iteration 24, loss = 0.39395078\n",
            "Iteration 25, loss = 0.39398198\n",
            "Iteration 26, loss = 0.39363323\n",
            "Iteration 27, loss = 0.39373797\n",
            "Iteration 28, loss = 0.39372096\n",
            "Iteration 29, loss = 0.39347056\n",
            "Iteration 30, loss = 0.39352752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.802 total time=  50.5s\n",
            "Iteration 1, loss = 0.40971248\n",
            "Iteration 2, loss = 0.39764788\n",
            "Iteration 3, loss = 0.39562803\n",
            "Iteration 4, loss = 0.39481252\n",
            "Iteration 5, loss = 0.39427624\n",
            "Iteration 6, loss = 0.39405653\n",
            "Iteration 7, loss = 0.39365822\n",
            "Iteration 8, loss = 0.39343019\n",
            "Iteration 9, loss = 0.39304657\n",
            "Iteration 10, loss = 0.39300039\n",
            "Iteration 11, loss = 0.39275366\n",
            "Iteration 12, loss = 0.39267717\n",
            "Iteration 13, loss = 0.39252670\n",
            "Iteration 14, loss = 0.39237565\n",
            "Iteration 15, loss = 0.39231186\n",
            "Iteration 16, loss = 0.39222582\n",
            "Iteration 17, loss = 0.39196351\n",
            "Iteration 18, loss = 0.39216155\n",
            "Iteration 19, loss = 0.39145333\n",
            "Iteration 20, loss = 0.39145877\n",
            "Iteration 21, loss = 0.39138761\n",
            "Iteration 22, loss = 0.39134204\n",
            "Iteration 23, loss = 0.39125366\n",
            "Iteration 24, loss = 0.39114934\n",
            "Iteration 25, loss = 0.39101361\n",
            "Iteration 26, loss = 0.39077829\n",
            "Iteration 27, loss = 0.39063285\n",
            "Iteration 28, loss = 0.39041585\n",
            "Iteration 29, loss = 0.39037315\n",
            "Iteration 30, loss = 0.39044794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.810 total time= 2.1min\n",
            "Iteration 1, loss = 0.40995011\n",
            "Iteration 2, loss = 0.39823217\n",
            "Iteration 3, loss = 0.39605489\n",
            "Iteration 4, loss = 0.39527749\n",
            "Iteration 5, loss = 0.39467683\n",
            "Iteration 6, loss = 0.39466816\n",
            "Iteration 7, loss = 0.39405917\n",
            "Iteration 8, loss = 0.39380914\n",
            "Iteration 9, loss = 0.39364477\n",
            "Iteration 10, loss = 0.39374935\n",
            "Iteration 11, loss = 0.39327941\n",
            "Iteration 12, loss = 0.39338702\n",
            "Iteration 13, loss = 0.39309355\n",
            "Iteration 14, loss = 0.39271105\n",
            "Iteration 15, loss = 0.39289763\n",
            "Iteration 16, loss = 0.39270710\n",
            "Iteration 17, loss = 0.39241278\n",
            "Iteration 18, loss = 0.39253338\n",
            "Iteration 19, loss = 0.39208329\n",
            "Iteration 20, loss = 0.39199029\n",
            "Iteration 21, loss = 0.39197974\n",
            "Iteration 22, loss = 0.39184112\n",
            "Iteration 23, loss = 0.39160720\n",
            "Iteration 24, loss = 0.39150804\n",
            "Iteration 25, loss = 0.39160436\n",
            "Iteration 26, loss = 0.39123185\n",
            "Iteration 27, loss = 0.39121362\n",
            "Iteration 28, loss = 0.39091746\n",
            "Iteration 29, loss = 0.39096319\n",
            "Iteration 30, loss = 0.39106500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.814 total time= 2.2min\n",
            "Iteration 1, loss = 0.41047387\n",
            "Iteration 2, loss = 0.39816812\n",
            "Iteration 3, loss = 0.39622135\n",
            "Iteration 4, loss = 0.39526254\n",
            "Iteration 5, loss = 0.39466746\n",
            "Iteration 6, loss = 0.39468536\n",
            "Iteration 7, loss = 0.39394678\n",
            "Iteration 8, loss = 0.39372774\n",
            "Iteration 9, loss = 0.39363105\n",
            "Iteration 10, loss = 0.39336754\n",
            "Iteration 11, loss = 0.39319946\n",
            "Iteration 12, loss = 0.39316351\n",
            "Iteration 13, loss = 0.39282258\n",
            "Iteration 14, loss = 0.39276003\n",
            "Iteration 15, loss = 0.39267401\n",
            "Iteration 16, loss = 0.39258322\n",
            "Iteration 17, loss = 0.39232837\n",
            "Iteration 18, loss = 0.39238839\n",
            "Iteration 19, loss = 0.39183150\n",
            "Iteration 20, loss = 0.39178735\n",
            "Iteration 21, loss = 0.39177497\n",
            "Iteration 22, loss = 0.39167816\n",
            "Iteration 23, loss = 0.39123998\n",
            "Iteration 24, loss = 0.39136867\n",
            "Iteration 25, loss = 0.39138448\n",
            "Iteration 26, loss = 0.39118705\n",
            "Iteration 27, loss = 0.39116876\n",
            "Iteration 28, loss = 0.39070615\n",
            "Iteration 29, loss = 0.39078870\n",
            "Iteration 30, loss = 0.39086841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.815 total time= 2.1min\n",
            "Iteration 1, loss = 0.41075941\n",
            "Iteration 2, loss = 0.39815148\n",
            "Iteration 3, loss = 0.39683181\n",
            "Iteration 4, loss = 0.39572620\n",
            "Iteration 5, loss = 0.39507475\n",
            "Iteration 6, loss = 0.39488082\n",
            "Iteration 7, loss = 0.39448692\n",
            "Iteration 8, loss = 0.39428305\n",
            "Iteration 9, loss = 0.39416385\n",
            "Iteration 10, loss = 0.39375651\n",
            "Iteration 11, loss = 0.39349232\n",
            "Iteration 12, loss = 0.39339041\n",
            "Iteration 13, loss = 0.39318480\n",
            "Iteration 14, loss = 0.39336828\n",
            "Iteration 15, loss = 0.39306749\n",
            "Iteration 16, loss = 0.39301834\n",
            "Iteration 17, loss = 0.39263863\n",
            "Iteration 18, loss = 0.39283327\n",
            "Iteration 19, loss = 0.39237915\n",
            "Iteration 20, loss = 0.39224830\n",
            "Iteration 21, loss = 0.39214510\n",
            "Iteration 22, loss = 0.39204396\n",
            "Iteration 23, loss = 0.39182359\n",
            "Iteration 24, loss = 0.39185326\n",
            "Iteration 25, loss = 0.39173179\n",
            "Iteration 26, loss = 0.39159701\n",
            "Iteration 27, loss = 0.39157350\n",
            "Iteration 28, loss = 0.39153952\n",
            "Iteration 29, loss = 0.39105205\n",
            "Iteration 30, loss = 0.39113430\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.809 total time= 2.2min\n",
            "Iteration 1, loss = 0.41077888\n",
            "Iteration 2, loss = 0.39794725\n",
            "Iteration 3, loss = 0.39669103\n",
            "Iteration 4, loss = 0.39559464\n",
            "Iteration 5, loss = 0.39504334\n",
            "Iteration 6, loss = 0.39438748\n",
            "Iteration 7, loss = 0.39458250\n",
            "Iteration 8, loss = 0.39391838\n",
            "Iteration 9, loss = 0.39409377\n",
            "Iteration 10, loss = 0.39331263\n",
            "Iteration 11, loss = 0.39322510\n",
            "Iteration 12, loss = 0.39309441\n",
            "Iteration 13, loss = 0.39298356\n",
            "Iteration 14, loss = 0.39260138\n",
            "Iteration 15, loss = 0.39282046\n",
            "Iteration 16, loss = 0.39272941\n",
            "Iteration 17, loss = 0.39242265\n",
            "Iteration 18, loss = 0.39230195\n",
            "Iteration 19, loss = 0.39221946\n",
            "Iteration 20, loss = 0.39187206\n",
            "Iteration 21, loss = 0.39170665\n",
            "Iteration 22, loss = 0.39168790\n",
            "Iteration 23, loss = 0.39164492\n",
            "Iteration 24, loss = 0.39129737\n",
            "Iteration 25, loss = 0.39129936\n",
            "Iteration 26, loss = 0.39128194\n",
            "Iteration 27, loss = 0.39137187\n",
            "Iteration 28, loss = 0.39103404\n",
            "Iteration 29, loss = 0.39086385\n",
            "Iteration 30, loss = 0.39047668\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.808 total time= 2.2min\n",
            "Iteration 1, loss = 0.41909471\n",
            "Iteration 2, loss = 0.39714298\n",
            "Iteration 3, loss = 0.39570008\n",
            "Iteration 4, loss = 0.39481425\n",
            "Iteration 5, loss = 0.39453846\n",
            "Iteration 6, loss = 0.39376482\n",
            "Iteration 7, loss = 0.39348346\n",
            "Iteration 8, loss = 0.39335191\n",
            "Iteration 9, loss = 0.39314082\n",
            "Iteration 10, loss = 0.39295069\n",
            "Iteration 11, loss = 0.39266321\n",
            "Iteration 12, loss = 0.39255804\n",
            "Iteration 13, loss = 0.39248835\n",
            "Iteration 14, loss = 0.39229391\n",
            "Iteration 15, loss = 0.39252777\n",
            "Iteration 16, loss = 0.39197198\n",
            "Iteration 17, loss = 0.39204237\n",
            "Iteration 18, loss = 0.39194128\n",
            "Iteration 19, loss = 0.39164518\n",
            "Iteration 20, loss = 0.39142108\n",
            "Iteration 21, loss = 0.39173472\n",
            "Iteration 22, loss = 0.39164365\n",
            "Iteration 23, loss = 0.39127640\n",
            "Iteration 24, loss = 0.39122287\n",
            "Iteration 25, loss = 0.39118081\n",
            "Iteration 26, loss = 0.39116526\n",
            "Iteration 27, loss = 0.39110662\n",
            "Iteration 28, loss = 0.39113729\n",
            "Iteration 29, loss = 0.39060415\n",
            "Iteration 30, loss = 0.39090763\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.816 total time=  49.9s\n",
            "Iteration 1, loss = 0.41899688\n",
            "Iteration 2, loss = 0.39736555\n",
            "Iteration 3, loss = 0.39598002\n",
            "Iteration 4, loss = 0.39520887\n",
            "Iteration 5, loss = 0.39503199\n",
            "Iteration 6, loss = 0.39423477\n",
            "Iteration 7, loss = 0.39410932\n",
            "Iteration 8, loss = 0.39376285\n",
            "Iteration 9, loss = 0.39353826\n",
            "Iteration 10, loss = 0.39363877\n",
            "Iteration 11, loss = 0.39331831\n",
            "Iteration 12, loss = 0.39311576\n",
            "Iteration 13, loss = 0.39287954\n",
            "Iteration 14, loss = 0.39293543\n",
            "Iteration 15, loss = 0.39292531\n",
            "Iteration 16, loss = 0.39259295\n",
            "Iteration 17, loss = 0.39256102\n",
            "Iteration 18, loss = 0.39246698\n",
            "Iteration 19, loss = 0.39217044\n",
            "Iteration 20, loss = 0.39210442\n",
            "Iteration 21, loss = 0.39237330\n",
            "Iteration 22, loss = 0.39211671\n",
            "Iteration 23, loss = 0.39194618\n",
            "Iteration 24, loss = 0.39197653\n",
            "Iteration 25, loss = 0.39208569\n",
            "Iteration 26, loss = 0.39181150\n",
            "Iteration 27, loss = 0.39171940\n",
            "Iteration 28, loss = 0.39164715\n",
            "Iteration 29, loss = 0.39144772\n",
            "Iteration 30, loss = 0.39153058\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.812 total time=  49.1s\n",
            "Iteration 1, loss = 0.41941473\n",
            "Iteration 2, loss = 0.39735733\n",
            "Iteration 3, loss = 0.39594510\n",
            "Iteration 4, loss = 0.39530630\n",
            "Iteration 5, loss = 0.39482814\n",
            "Iteration 6, loss = 0.39441006\n",
            "Iteration 7, loss = 0.39408544\n",
            "Iteration 8, loss = 0.39368812\n",
            "Iteration 9, loss = 0.39361455\n",
            "Iteration 10, loss = 0.39335545\n",
            "Iteration 11, loss = 0.39334599\n",
            "Iteration 12, loss = 0.39322173\n",
            "Iteration 13, loss = 0.39293026\n",
            "Iteration 14, loss = 0.39305142\n",
            "Iteration 15, loss = 0.39273012\n",
            "Iteration 16, loss = 0.39271515\n",
            "Iteration 17, loss = 0.39238743\n",
            "Iteration 18, loss = 0.39245880\n",
            "Iteration 19, loss = 0.39243548\n",
            "Iteration 20, loss = 0.39214862\n",
            "Iteration 21, loss = 0.39239245\n",
            "Iteration 22, loss = 0.39214165\n",
            "Iteration 23, loss = 0.39189984\n",
            "Iteration 24, loss = 0.39202323\n",
            "Iteration 25, loss = 0.39179110\n",
            "Iteration 26, loss = 0.39199453\n",
            "Iteration 27, loss = 0.39177252\n",
            "Iteration 28, loss = 0.39161799\n",
            "Iteration 29, loss = 0.39156171\n",
            "Iteration 30, loss = 0.39141366\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.813 total time=  50.6s\n",
            "Iteration 1, loss = 0.41943048\n",
            "Iteration 2, loss = 0.39757007\n",
            "Iteration 3, loss = 0.39641977\n",
            "Iteration 4, loss = 0.39561045\n",
            "Iteration 5, loss = 0.39500847\n",
            "Iteration 6, loss = 0.39477238\n",
            "Iteration 7, loss = 0.39437774\n",
            "Iteration 8, loss = 0.39395743\n",
            "Iteration 9, loss = 0.39384745\n",
            "Iteration 10, loss = 0.39375271\n",
            "Iteration 11, loss = 0.39360351\n",
            "Iteration 12, loss = 0.39352568\n",
            "Iteration 13, loss = 0.39313370\n",
            "Iteration 14, loss = 0.39325980\n",
            "Iteration 15, loss = 0.39289890\n",
            "Iteration 16, loss = 0.39275741\n",
            "Iteration 17, loss = 0.39277517\n",
            "Iteration 18, loss = 0.39282186\n",
            "Iteration 19, loss = 0.39271608\n",
            "Iteration 20, loss = 0.39260953\n",
            "Iteration 21, loss = 0.39270443\n",
            "Iteration 22, loss = 0.39243835\n",
            "Iteration 23, loss = 0.39219553\n",
            "Iteration 24, loss = 0.39223518\n",
            "Iteration 25, loss = 0.39229028\n",
            "Iteration 26, loss = 0.39231278\n",
            "Iteration 27, loss = 0.39204562\n",
            "Iteration 28, loss = 0.39189919\n",
            "Iteration 29, loss = 0.39188258\n",
            "Iteration 30, loss = 0.39163874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.811 total time=  50.3s\n",
            "Iteration 1, loss = 0.41883322\n",
            "Iteration 2, loss = 0.39770773\n",
            "Iteration 3, loss = 0.39632638\n",
            "Iteration 4, loss = 0.39565313\n",
            "Iteration 5, loss = 0.39480639\n",
            "Iteration 6, loss = 0.39462844\n",
            "Iteration 7, loss = 0.39421744\n",
            "Iteration 8, loss = 0.39399318\n",
            "Iteration 9, loss = 0.39370939\n",
            "Iteration 10, loss = 0.39366179\n",
            "Iteration 11, loss = 0.39332488\n",
            "Iteration 12, loss = 0.39318371\n",
            "Iteration 13, loss = 0.39323242\n",
            "Iteration 14, loss = 0.39299202\n",
            "Iteration 15, loss = 0.39279175\n",
            "Iteration 16, loss = 0.39270285\n",
            "Iteration 17, loss = 0.39256828\n",
            "Iteration 18, loss = 0.39251353\n",
            "Iteration 19, loss = 0.39229212\n",
            "Iteration 20, loss = 0.39236517\n",
            "Iteration 21, loss = 0.39223820\n",
            "Iteration 22, loss = 0.39211498\n",
            "Iteration 23, loss = 0.39194027\n",
            "Iteration 24, loss = 0.39202515\n",
            "Iteration 25, loss = 0.39201708\n",
            "Iteration 26, loss = 0.39165280\n",
            "Iteration 27, loss = 0.39172224\n",
            "Iteration 28, loss = 0.39168528\n",
            "Iteration 29, loss = 0.39140578\n",
            "Iteration 30, loss = 0.39144141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.803 total time=  48.9s\n",
            "Iteration 1, loss = 0.40975240\n",
            "Iteration 2, loss = 0.39746717\n",
            "Iteration 3, loss = 0.39613682\n",
            "Iteration 4, loss = 0.39577038\n",
            "Iteration 5, loss = 0.39530465\n",
            "Iteration 6, loss = 0.39501039\n",
            "Iteration 7, loss = 0.39489009\n",
            "Iteration 8, loss = 0.39410117\n",
            "Iteration 9, loss = 0.39411540\n",
            "Iteration 10, loss = 0.39388924\n",
            "Iteration 11, loss = 0.39391775\n",
            "Iteration 12, loss = 0.39365555\n",
            "Iteration 13, loss = 0.39352463\n",
            "Iteration 14, loss = 0.39323341\n",
            "Iteration 15, loss = 0.39303804\n",
            "Iteration 16, loss = 0.39322831\n",
            "Iteration 17, loss = 0.39290947\n",
            "Iteration 18, loss = 0.39251124\n",
            "Iteration 19, loss = 0.39278834\n",
            "Iteration 20, loss = 0.39257028\n",
            "Iteration 21, loss = 0.39259390\n",
            "Iteration 22, loss = 0.39252566\n",
            "Iteration 23, loss = 0.39244964\n",
            "Iteration 24, loss = 0.39245079\n",
            "Iteration 25, loss = 0.39217050\n",
            "Iteration 26, loss = 0.39240630\n",
            "Iteration 27, loss = 0.39202525\n",
            "Iteration 28, loss = 0.39221027\n",
            "Iteration 29, loss = 0.39215160\n",
            "Iteration 30, loss = 0.39207319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=MLPClassifier(),\n",
              "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;], &#x27;alpha&#x27;: [0.01, 0.001],\n",
              "                         &#x27;hidden_layer_sizes&#x27;: [(64, 64), (32, 32)],\n",
              "                         &#x27;max_iter&#x27;: [30], &#x27;random_state&#x27;: [42],\n",
              "                         &#x27;solver&#x27;: [&#x27;adam&#x27;], &#x27;verbose&#x27;: [True]},\n",
              "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=MLPClassifier(),\n",
              "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;], &#x27;alpha&#x27;: [0.01, 0.001],\n",
              "                         &#x27;hidden_layer_sizes&#x27;: [(64, 64), (32, 32)],\n",
              "                         &#x27;max_iter&#x27;: [30], &#x27;random_state&#x27;: [42],\n",
              "                         &#x27;solver&#x27;: [&#x27;adam&#x27;], &#x27;verbose&#x27;: [True]},\n",
              "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5, estimator=MLPClassifier(),\n",
              "             param_grid={'activation': ['relu', 'tanh'], 'alpha': [0.01, 0.001],\n",
              "                         'hidden_layer_sizes': [(64, 64), (32, 32)],\n",
              "                         'max_iter': [30], 'random_state': [42],\n",
              "                         'solver': ['adam'], 'verbose': [True]},\n",
              "             scoring='f1_weighted', verbose=3)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_grid_search_clf = GridSearchCV(estimator=mlp_classifer, param_grid=mlp_param_grid, scoring='f1_weighted', cv=5, verbose=3)\n",
        "mlp_grid_search_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4WlgfT3Egs5",
        "outputId": "ca22a434-9d6f-4978-9193-c98837f3390d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (64, 64), 'max_iter': 30, 'random_state': 42, 'solver': 'adam', 'verbose': True}\n"
          ]
        }
      ],
      "source": [
        "print(mlp_grid_search_clf.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "pWd-PmISVMSp",
        "outputId": "fa8807cf-ea6e-458a-dfea-ef19e0f1d348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.40975240\n",
            "Iteration 2, loss = 0.39746717\n",
            "Iteration 3, loss = 0.39613682\n",
            "Iteration 4, loss = 0.39577038\n",
            "Iteration 5, loss = 0.39530465\n",
            "Iteration 6, loss = 0.39501039\n",
            "Iteration 7, loss = 0.39489009\n",
            "Iteration 8, loss = 0.39410117\n",
            "Iteration 9, loss = 0.39411540\n",
            "Iteration 10, loss = 0.39388924\n",
            "Iteration 11, loss = 0.39391775\n",
            "Iteration 12, loss = 0.39365555\n",
            "Iteration 13, loss = 0.39352463\n",
            "Iteration 14, loss = 0.39323341\n",
            "Iteration 15, loss = 0.39303804\n",
            "Iteration 16, loss = 0.39322831\n",
            "Iteration 17, loss = 0.39290947\n",
            "Iteration 18, loss = 0.39251124\n",
            "Iteration 19, loss = 0.39278834\n",
            "Iteration 20, loss = 0.39257028\n",
            "Iteration 21, loss = 0.39259390\n",
            "Iteration 22, loss = 0.39252566\n",
            "Iteration 23, loss = 0.39244964\n",
            "Iteration 24, loss = 0.39245079\n",
            "Iteration 25, loss = 0.39217050\n",
            "Iteration 26, loss = 0.39240630\n",
            "Iteration 27, loss = 0.39202525\n",
            "Iteration 28, loss = 0.39221027\n",
            "Iteration 29, loss = 0.39215160\n",
            "Iteration 30, loss = 0.39207319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30,\n",
              "              random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30,\n",
              "              random_state=42, verbose=True)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "MLPClassifier(alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30,\n",
              "              random_state=42, verbose=True)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_classifer_012 = MLPClassifier()\n",
        "mlp_classifer_012.set_params(**mlp_grid_search_clf.best_params_)\n",
        "mlp_classifer_012.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "G98SlEUIEgs6"
      },
      "outputs": [],
      "source": [
        "mlp_pickle_file_012 = '/content/drive/MyDrive/AML_Final_Project/mlp_classifer_012.pkl'\n",
        "# with open(mlp_pickle_file_012, 'wb') as file:\n",
        "#     pickle.dump(mlp_classifer_012, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "WaFP-smzEgs6"
      },
      "outputs": [],
      "source": [
        "with open(mlp_pickle_file_012, 'rb') as file:\n",
        "    mlp_classifer_012 = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TtjxaTCEgs6",
        "outputId": "cad0df0c-17f5-4775-f8bc-983d8d7954f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.86      0.92     48566\n",
            "         1.0       0.00      0.00      0.00         0\n",
            "         2.0       0.17      0.56      0.26      2170\n",
            "\n",
            "    accuracy                           0.85     50736\n",
            "   macro avg       0.38      0.47      0.39     50736\n",
            "weighted avg       0.94      0.85      0.89     50736\n",
            "\n",
            "[[41862   849  5855]\n",
            " [    0     0     0]\n",
            " [  879    77  1214]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "y_pred = mlp_classifer_012.predict(X_test)\n",
        "print(classification_report(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEvw6clcL8uq"
      },
      "source": [
        "### Training the MLP classifier using the best parameters obtained after grid search and cross validation using the PCA on training data to get the cumulative variance explained by different no. of components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmbGKxJbKDCX",
        "outputId": "6703e77c-32a1-48af-b2c1-b139d49fd824"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cumulative variance explained by 3 components is 0.44254713922655414\n",
            "Classification Report for total components: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.86      0.92     48928\n",
            "         1.0       0.00      0.00      0.00         0\n",
            "         2.0       0.14      0.53      0.22      1808\n",
            "\n",
            "    accuracy                           0.85     50736\n",
            "   macro avg       0.37      0.46      0.38     50736\n",
            "weighted avg       0.95      0.85      0.89     50736\n",
            "\n",
            "\n",
            "Cumulative variance explained by 5 components is 0.6191998687853013\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.85      0.92     49652\n",
            "         1.0       0.00      0.00      0.00         0\n",
            "         2.0       0.09      0.58      0.15      1084\n",
            "\n",
            "    accuracy                           0.85     50736\n",
            "   macro avg       0.36      0.48      0.36     50736\n",
            "weighted avg       0.97      0.85      0.90     50736\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cumulative variance explained by 10 components is 0.8618245551141718\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.86      0.92     49326\n",
            "         1.0       0.00      0.00      0.00         0\n",
            "         2.0       0.12      0.59      0.20      1410\n",
            "\n",
            "    accuracy                           0.85     50736\n",
            "   macro avg       0.37      0.48      0.37     50736\n",
            "weighted avg       0.96      0.85      0.90     50736\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Cumulative variance explained by 15 components is 0.9475985779258699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.86      0.92     48246\n",
            "         1.0       0.00      0.00      0.00         0\n",
            "         2.0       0.19      0.54      0.28      2490\n",
            "\n",
            "    accuracy                           0.85     50736\n",
            "   macro avg       0.39      0.47      0.40     50736\n",
            "weighted avg       0.94      0.85      0.89     50736\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cumulative variance explained by 20 components is 0.995073594383692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.87      0.92     47714\n",
            "         1.0       0.00      0.00      0.00         0\n",
            "         2.0       0.23      0.53      0.32      3022\n",
            "\n",
            "    accuracy                           0.85     50736\n",
            "   macro avg       0.40      0.47      0.41     50736\n",
            "weighted avg       0.93      0.85      0.88     50736\n",
            "\n",
            "\n",
            "Cumulative variance explained by 25 components is 0.9999999999999996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.86      0.92     48479\n",
            "         1.0       0.00      0.00      0.00         0\n",
            "         2.0       0.18      0.55      0.27      2257\n",
            "\n",
            "    accuracy                           0.85     50736\n",
            "   macro avg       0.38      0.47      0.39     50736\n",
            "weighted avg       0.94      0.85      0.89     50736\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "num_components = [3, 5, 10, 15, 20, 25]\n",
        "variance = []\n",
        "\n",
        "for num in num_components:\n",
        "  # Initializing the PCA with defitive components\n",
        "  pca = PCA(n_components=num)\n",
        "\n",
        "  # Fit the PCA on the training data\n",
        "  pca.fit(X_train)\n",
        "\n",
        "  # Transform the train and test data as per the components of the PCA\n",
        "  X_train_pca = pca.transform(X_train)\n",
        "  X_test_pca = pca.transform(X_test)\n",
        "\n",
        "  # Recording the explained variance for each number of components\n",
        "  variance.append(np.sum(pca.explained_variance_ratio_))\n",
        "\n",
        "  print(\"Cumulative variance explained by {} components is {}\".format(num,variance[-1]))\n",
        "\n",
        "  mlp_classifer = MLPClassifier(activation = 'relu', alpha=0.01, hidden_layer_sizes=(64, 64), max_iter = 30, solver='adam', random_state= 42)\n",
        "  mlp_classifer.fit(X_train_pca, y_train)\n",
        "  y_pred = mlp_classifer.predict(X_test_pca)\n",
        "  print(f\"Classification Report for total components: {num}\")\n",
        "  print(classification_report(y_pred, y_test))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "5ycXE_jgKC_n",
        "outputId": "7b54c504-2d01-4608-aa3a-17225c7b6084"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAHWCAYAAAALjsguAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACBbUlEQVR4nOzdd1xV9R/H8fdlLxmyREXcW9Ew9ygzZ5ZZqWVq/srMUZktrdRs2TQbli21NMuyoWWZZo4009xailucCKggIHC59/z+MG9eAeUqcBmv5+PBQ+5Z933P/V7hw/ec79dkGIYhAAAAAADgdC7ODgAAAAAAAM6hSAcAAAAAoJigSAcAAAAAoJigSAcAAAAAoJigSAcAAAAAoJigSAcAAAAAoJigSAcAAAAAoJigSAcAAAAAoJigSAcAAAAAoJigSAcAFKmZM2fKZDLpwIEDDu97zz33qGrVqgWeKT+uJndhKY6ZrtSiRYvUpEkTeXl5yWQy6fTp086O5JDz78X69esL7JjObO8F6cCBAzKZTJo5c6azowBAiUCRDgCF6Pwv7ue/vLy8VLt2bY0cOVLx8fE5to+Pj9djjz2munXrysfHR76+voqJidELL7yQZ9HSvHlzmUwmvf/++/nOdf6X5ry+Xn755St9yWVa48aNVaVKFRmGkec2bdq0UXh4uLKzs4swWfGWlJSkPn36yNvbW1OnTtWsWbPk6+tbaM9XGAU1CobVatWrr76qatWqycvLS40bN9YXX3yRY7t169Zp+PDhiomJkbu7u0wmU67HO3TokCZOnKjmzZsrKChIISEhuu666/Trr78W9ksBgCvm5uwAAFAWPPfcc6pWrZoyMjK0atUqvf/++/rpp5+0fft2+fj4SJL++usvde/eXampqbr77rsVExMjSVq/fr1efvllrVy5UosXL7Y77u7du/XXX3+patWq+vzzzzVs2DCHct15553q3r17juVNmza9wldauD766CNZrVZnx8hT//79NWbMGP3+++9q3759jvUHDhzQmjVrNHLkSLm5Xf2P4AEDBqhfv37y9PS86mM5019//aUzZ87o+eefV6dOnZwdB0709NNP6+WXX9aQIUN07bXXav78+brrrrtkMpnUr18/23Y//fSTPv74YzVu3FjVq1fXrl27cj3e/Pnz9corr6hXr14aNGiQsrOz9dlnn+nGG2/U9OnTNXjw4KJ6aQCQbxTpAFAEunXrpmbNmkmS7rvvPgUHB2vy5MmaP3++7rzzTp0+fVq33nqrXF1dtWnTJtWtW9du/xdffFEfffRRjuPOnj1bYWFheuONN3T77bfrwIEDDl0ee8011+juu+++qtdWlNzd3Z0d4ZLuuusujR07VnPmzMm1SP/iiy9kGIb69+9/Vc+TlpYmX19fubq6ytXV9aqOVRycOHFCkhQYGFhgxzx/jlByHDlyRG+88YZGjBihd999V9K5/y87dOigxx9/XHfccYetvQ8bNkxPPvmkvL29NXLkyDyL9Ouvv15xcXEKCQmxLXvggQfUpEkTjR8/niIdQLHE5e4A4AQdO3aUJO3fv1+S9MEHH+jIkSOaPHlyjgJdksLDw/XMM8/kWD5nzhzdfvvtuummmxQQEKA5c+YUaM7ffvtNLi4uGj9+fI7nvfgSe5PJpJEjR+rzzz9XnTp15OXlpZiYGK1cufKyzzN//nz16NFDFStWlKenp2rUqKHnn39eFovFbruL79E9f9n+66+/rg8//FA1atSQp6enrr32Wv311185nmfnzp26/fbbVb58eXl5ealZs2ZasGBBju3+/vtvdezYUd7e3qpcubJeeOGFfPXgR0ZGqn379po3b57MZnOO9XPmzFGNGjXUokULHTx4UMOHD1edOnXk7e2t4OBg3XHHHTnuLz9/afaKFSs0fPhwhYWFqXLlynbrLtwnv+fyuuuuU8OGDfXPP//o+uuvl4+PjypVqqRXX301R+6MjAw9++yzql27try8vBQREaHevXtr7969tm2sVqumTJmiBg0ayMvLS+Hh4Ro6dKhOnTp1yXN23XXXadCgQZKka6+9ViaTSffcc49t/ddff62YmBh5e3srJCREd999t44cOWJ3jHvuuUd+fn7au3evunfvrnLlyjn8h5Dzx4iLi9NNN90kPz8/VapUSVOnTpUkbdu2TR07dpSvr6+ioqLy/Kylp6dr6NChCg4Olr+/vwYOHJjjHOT3PcrN66+/rtatWys4OFje3t6KiYnRvHnzcmx3/vP4/fffq2HDhvL09FSDBg20aNGiHNseOXJE9957ry1PtWrVNGzYMGVlZdm2OX36tEaNGqXIyEh5enqqZs2aeuWVV3J8Lk6fPq177rlHAQEBCgwM1KBBg/I9vsD8+fNlNps1fPhwu9cxbNgwHT58WGvWrLEtDw8Pl7e392WP2aBBA7sCXZI8PT3VvXt3HT58WGfOnMlXNgAoSvSkA4ATnC9ugoODJUkLFiyQt7e3br/99nwfY+3atdqzZ49mzJghDw8P9e7dW59//rmeeuqpfB8jPT1diYmJOZYHBgbKzc1NHTt21PDhwzVp0iT16tVL11xzjY4dO6YHH3xQnTp10gMPPGC334oVKzR37lw99NBD8vT01HvvvaeuXbtq3bp1atiwYZ45Zs6cKT8/P40ePVp+fn767bffNH78eKWkpOi111677OuYM2eOzpw5o6FDh8pkMunVV19V7969tW/fPlvv+99//602bdqoUqVKGjNmjHx9ffXVV1+pV69e+uabb3TrrbdKko4fP67rr79e2dnZtu0+/PDDfBUE0rlL3u+//3798ssvuummm2zLt23bpu3bt9v+4PHXX3/pjz/+UL9+/VS5cmUdOHBA77//vq677jr9888/ttsgzhs+fLhCQ0M1fvx4paWlFci5PHXqlLp27arevXurT58+mjdvnp588kk1atRI3bp1kyRZLBbddNNNWrp0qfr166eHH35YZ86c0ZIlS7R9+3bVqFFDkjR06FDNnDlTgwcP1kMPPaT9+/fr3Xff1aZNm7R69eo8r4J4+umnVadOHX344Ye220LOH/P88a699lpNmjRJ8fHxeuutt7R69Wpt2rTJruc9OztbXbp0Udu2bfX666/nOH/5YbFY1K1bN7Vv316vvvqqPv/8c40cOVK+vr56+umn1b9/f/Xu3VvTpk3TwIED1apVK1WrVs3uGCNHjlRgYKCeffZZxcbG6v3339fBgwe1fPly233TV9Pe33rrLd18883q37+/srKy9OWXX+qOO+7Qjz/+qB49ethtu2rVKn377bcaPny4ypUrp7ffflu33Xab4uLibP/3HD16VM2bN9fp06d1//33q27dujpy5IjmzZun9PR0eXh4KD09XR06dNCRI0c0dOhQValSRX/88YfGjh2rY8eOacqUKZIkwzB0yy23aNWqVXrggQdUr149fffdd7Y/wlzOpk2b5Ovrq3r16tktb968uW1927Zt83Wsyzl+/Lh8fHyuqJ0AQKEzAACFZsaMGYYk49dffzUSEhKMQ4cOGV9++aURHBxseHt7G4cPHzYMwzCCgoKM6Ohoh449cuRIIzIy0rBarYZhGMbixYsNScamTZsuu+/+/fsNSXl+rVmzxrZtWlqaUbNmTaNBgwZGRkaG0aNHD8Pf3984ePCg3THP77t+/XrbsoMHDxpeXl7GrbfemuOc7N+/37YsPT09R8ahQ4caPj4+RkZGhm3ZoEGDjKioqByvIzg42Dh58qRt+fz58w1Jxg8//GBbdsMNNxiNGjWyO57VajVat25t1KpVy7Zs1KhRhiRj7dq1tmUnTpwwAgICcuTOzcmTJw1PT0/jzjvvtFs+ZswYQ5IRGxub52tes2aNIcn47LPPbMvOn6+2bdsa2dnZdttfzbns0KFDjufKzMw0KlSoYNx22222ZdOnTzckGZMnT85x3PNt7/fffzckGZ9//rnd+kWLFuW6/GLnX8dff/1lW5aVlWWEhYUZDRs2NM6ePWtb/uOPPxqSjPHjx9uWDRo0yJBkjBkz5pLPc6nnO3+Ml156ybbs1KlThre3t2EymYwvv/zStnznzp2GJGPChAk5jhkTE2NkZWXZlr/66quGJGP+/Pm2ZVfa3nPbNysry2jYsKHRsWNHu+WSDA8PD2PPnj22ZVu2bDEkGe+8845t2cCBAw0XFxe7c3He+ff3+eefN3x9fY1du3bZrR8zZozh6upqxMXFGYZhGN9//70hyXj11Vdt22RnZxvt2rUzJBkzZszI8RwX6tGjh1G9evUcy9PS0i75/o4YMcJw5Ffa3bt3G15eXsaAAQPyvQ8AFCUudweAItCpUyeFhoYqMjJS/fr1k5+fn7777jtVqlRJkpSSkqJy5crl+3jZ2dmaO3eu+vbta+ud69ixo8LCwvT555/n+zj333+/lixZkuOrfv36tm18fHw0c+ZM7dixQ+3bt9fChQv15ptvqkqVKjmO16pVK9uAd5JUpUoV3XLLLfrll18ueSnvhb3UZ86cUWJiotq1a6f09HTt3Lnzsq+jb9++CgoKsj1u166dJGnfvn2SpJMnT+q3335Tnz59bMdPTExUUlKSunTpot27d9suof7pp5/UsmVLW++dJIWGhub78umgoCB1795dCxYssPV4G4ahL7/8Us2aNVPt2rVzvGaz2aykpCTVrFlTgYGB2rhxY47jDhkyJF/3nztyLv38/OzGJPDw8FDz5s1t502SvvnmG4WEhOjBBx/M8Vzn297XX3+tgIAA3XjjjbZzm5iYqJiYGPn5+WnZsmWXzX2x9evX68SJExo+fLi8vLxsy3v06KG6detq4cKFOfZxdODE3Nx333227wMDA1WnTh35+vqqT58+tuV16tRRYGCg3Xk67/7777e7amDYsGFyc3PTTz/9ZFt2Ne39wn1PnTql5ORktWvXLtc206lTJ9tVCdK52Qf8/f1tua1Wq77//nv17NnTNmbGhS58f9u1a6egoCC797dTp06yWCy2W1p++uknubm52b0Prq6uubad3Jw9ezbXQRDPv/9nz57N13EuJT09XXfccYe8vb2ZxQJAscXl7gBQBKZOnaratWvLzc1N4eHhqlOnjlxc/vs7qb+/v0P3Ri5evFgJCQlq3ry59uzZY1t+/fXX64svvtArr7xid/y81KpVK1+jabdp00bDhg3T1KlT1aVLF/3vf//L83gXq127ttLT05WQkKAKFSrkut/ff/+tZ555Rr/99ptSUlLs1iUnJ18238V/MDhfsJ+/F3jPnj0yDEPjxo3TuHHjcj3GiRMnVKlSJR08eFAtWrTIsb5OnTqXzXFe//799d1339lGpv7jjz904MABPfzww7Ztzp49q0mTJmnGjBk6cuSI3bRtub3miy+rzosj57Jy5co5pq4KCgrS1q1bbY/37t2rOnXqXHI0+t27dys5OVlhYWG5rj8/MJwjDh48KCn38163bl2tWrXKbpmbm5vtXv0r5eXlpdDQULtlAQEBuZ6ngICAXO+3v/gz4Ofnp4iICLtxA66mvf/444964YUXtHnzZmVmZtqW5zYFWW5/SAsKCrLlTkhIUEpKyiVvRZHOvb9bt27NcW7OO//+Hjx4UBEREfLz87Nbn9/Pjre3t91rOi8jI8O2/mpYLBb169dP//zzj37++WdVrFjxqo4HAIWFIh0AikDz5s1z7ak6r27dutq8ebOysrLk4eFx2eOd7y2/sHfvQitWrND1119/ZWFzkZmZqeXLl0s6V7Slp6cX2L2cp0+fVocOHeTv76/nnntONWrUkJeXlzZu3Kgnn3wyXwO25dXDfL7wPX+Mxx57TF26dMl125o1a17hK8jpwoH87rrrLs2ZM0eurq52U0g9+OCDmjFjhkaNGqVWrVopICDANs1Ubq85PwWKo+fycuctv6xW6yWv4siruCtInp6e+frD1KXkdT4K6jxJV9fef//9d918881q37693nvvPUVERMjd3V0zZszIdSC7gnx/b7zxRj3xxBO5rj9/dcjVioiI0LJly2QYht0fHY4dOyZJV11UDxkyRD/++KM+//xz2+CdAFAcUaQDQDHQs2dPrVmzRt98843uvPPOS26blpam+fPnq2/fvrkONPfQQw/p888/L9AifcKECdqxY4def/11PfnkkxozZozefvvtHNvt3r07x7Jdu3bJx8cnz0Jt+fLlSkpK0rfffms3bdn5ke8LQvXq1SWdm8LtclcOREVF5fo6YmNj8/18np6euv322/XZZ58pPj5eX3/9tTp27Gh3JcG8efM0aNAgvfHGG7ZlGRkZ+R4JOzeFcS5r1KihtWvXymw25zn4W40aNfTrr7+qTZs2V93beV5UVJSkc+f94oIqNjbWtr642b17t91nLzU1VceOHVP37t0lXd179M0338jLy0u//PKL3WXhM2bMuKKsoaGh8vf31/bt2y+5XY0aNZSampqvz87SpUuVmppq15ue389OkyZN9PHHH2vHjh12t9ysXbvWtv5KPf7445oxY4amTJly2f9jAcDZuCcdAIqBBx54QBEREXr00Udzne/3xIkTeuGFFyRJ3333ndLS0jRixAjdfvvtOb5uuukmffPNN7leNnol1q5dq9dff12jRo3So48+qscff1zvvvuuVqxYkWPbNWvW2N0be+jQIc2fP1+dO3e+bC/lhb17WVlZeu+99wokvySFhYXpuuuu0wcffGDrlbtQQkKC7fvu3bvrzz//1Lp16+zWO3Kvv3Tuknez2ayhQ4cqISEhxz3trq6uOXo033nnnXxNw5WXwjiXt912mxITE23zVl/o/PP06dNHFotFzz//fI5tsrOzr+gPD82aNVNYWJimTZtm15Z//vln7dixI8dI5sXFhx9+aDf93vvvv6/s7GzbaPlX8x65urrKZDLZtZEDBw7o+++/v6KsLi4u6tWrl3744QetX78+x/oL3981a9bol19+ybHN6dOnlZ2dLencZyc7O9tuakaLxaJ33nknX3luueUWubu7250LwzA0bdo0VapUSa1bt3bo9Z332muv6fXXX9dTTz1ld8sJABRX9KQDQDEQFBSk7777Tt27d1eTJk1099132wZg27hxo7744gu1atVK0rlL3YODg/P8hfXmm2/WRx99pIULF6p3796XfN6NGzdq9uzZOZbXqFFDrVq1UkZGhgYNGqRatWrpxRdflCRNnDhRP/zwgwYPHqxt27bJ19fXtl/Dhg3VpUsXuynYzu+Tl9atWysoKEiDBg3SQw89JJPJpFmzZl3RpcSXMnXqVLVt21aNGjXSkCFDVL16dcXHx2vNmjU6fPiwtmzZIkl64oknNGvWLHXt2lUPP/ywbQq2qKgou3u1L6dDhw6qXLmy5s+fL29v7xzvxU033aRZs2YpICBA9evX15o1a/Trr7/apsa6EoVxLgcOHKjPPvtMo0eP1rp169SuXTulpaXp119/1fDhw3XLLbeoQ4cOGjp0qCZNmqTNmzerc+fOcnd31+7du/X111/rrbfecmh6QencVQ+vvPKKBg8erA4dOujOO++0TcFWtWpVPfLII1f8mgpTVlaWbrjhBvXp00exsbF677331LZtW918882Sru496tGjhyZPnqyuXbvqrrvu0okTJzR16lTVrFnTobZ5oZdeekmLFy9Whw4ddP/996tevXo6duyYvv76a61atUqBgYF6/PHHtWDBAt1000265557FBMTo7S0NG3btk3z5s3TgQMHFBISop49e6pNmzYaM2aMDhw4oPr16+vbb7/N17gS0rkxEkaNGqXXXntNZrNZ1157rb7//nv9/vvv+vzzz+3+0Hfw4EHNmjVLkmx/YDj/h8yoqCgNGDBA0rk/aj7xxBOqVauW6tWrl+P/uxtvvFHh4eFXdO4AoNAU9XDyAFCW5DbV06UcPXrUeOSRR4zatWsbXl5eho+PjxETE2O8+OKLRnJyshEfH2+4ubldcuqg9PR0w8fHx27as4tdbgq2QYMGGYZhGI888ojh6upqNx2ZYRjG+vXrDTc3N2PYsGG2ZZKMESNGGLNnzzZq1apleHp6Gk2bNjWWLVuW6zm5cNqw1atXGy1btjS8vb2NihUrGk888YTxyy+/GJLs9s9rCrbXXnstx2vURVNkGYZh7N271xg4cKBRoUIFw93d3ahUqZJx0003GfPmzbPbbuvWrUaHDh0MLy8vo1KlSsbzzz9vfPLJJ/magu1Cjz/+uCHJ6NOnT451p06dMgYPHmyEhIQYfn5+RpcuXYydO3caUVFRtvN/4fnKrQ1dzbns0KGD0aBBgxzHzGvar6efftqoVq2a4e7ublSoUMG4/fbbjb1799pt9+GHHxoxMTGGt7e3Ua5cOaNRo0bGE088YRw9evSS5+lSr3Hu3LlG06ZNDU9PT6N8+fJG//79bVMXXpjZ19f3ks9xuefL6xh5naeoqCijR48eOY65YsUK4/777zeCgoIMPz8/o3///kZSUpLdvlfa3g3DMD755BPb56tu3brGjBkzjAkTJuSYguz85zG33Be2L8M4N1XiwIEDjdDQUMPT09OoXr26MWLECCMzM9O2zZkzZ4yxY8caNWvWNDw8PIyQkBCjdevWxuuvv2435VxSUpIxYMAAw9/f3wgICDAGDBhgbNq0KV9TsBmGYVgsFuOll14yoqKiDA8PD6NBgwbG7Nmzc2y3bNmyPP//6tChg2278+cmr6+L/38CgOLAZBgF3FUBACiTTCaTRowYketl0QAAAMgf7kkHAAAAAKCYoEgHAAAAAKCYoEgHAAAAAKCYYHR3AECBYIgTAACAq0dPOgAAAAAAxQRFOgAAAAAAxUSZu9zdarXq6NGjKleunEwmk7PjAAAAAABKOcMwdObMGVWsWFEuLpfuKy9zRfrRo0cVGRnp7BgAAAAAgDLm0KFDqly58iW3KXNFerly5SSdOzn+/v5OToOCZDabtXjxYnXu3Fnu7u7OjgMUOT4DKMto/yjLaP8oy0pK+09JSVFkZKStHr2UMlekn7/E3d/fnyK9lDGbzfLx8ZG/v3+x/oAChYXPAMoy2j/KMto/yrKS1v7zc8s1A8cBAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMOLVIX7lypXr27KmKFSvKZDLp+++/v+w+y5cv1zXXXCNPT0/VrFlTM2fOLPScAAAAAAAUBacW6WlpaYqOjtbUqVPztf3+/fvVo0cPXX/99dq8ebNGjRql++67T7/88kshJwUAAAAAoPC5OfPJu3Xrpm7duuV7+2nTpqlatWp64403JEn16tXTqlWr9Oabb6pLly6FFRMAAAAAgCLh1CLdUWvWrFGnTp3slnXp0kWjRo3Kc5/MzExlZmbaHqekpEiSzGazzGZzoeSEc5x/P3lfUVbxGUBZRvtHWUb7x5WwWg1lWw1ZrIayrdYLvr/gX8u5781Wq926i7fLtlhz7nvR9mbLlR3Dls+S+7HNFquSU1zV/voM+Tn7pF6CI5/PElWkHz9+XOHh4XbLwsPDlZKSorNnz8rb2zvHPpMmTdLEiRNzLF+8eLF8fHwKLSucZ8mSJc6OADgVnwGUZbR/lGW0f8cZhmRIshqSxTj374Xf25bJfv1/60w599MljpNjuem/Zcprm5zLzj2H6bLHtzvORcc3ZHLmqS9gJi3+9Td5uTo7R97S09PzvW2JKtKvxNixYzV69Gjb45SUFEVGRqpz587y9/d3YjIUNLPZrCVLlujGG2+Uu7u7s+MARY7PAMoy2j/KsoJo/4ZhyGooHz2a59bn1Rtq+bdHNq9eT9v6C7ax3+6/586tRzfP9Ress1j+W39xb6zd9v9uB3vuria5upz7crP962Jb5n7hOlf79W52+1y0r+t/68+vu3hfVxeT3FwvPob9+ovzyWrV5k0b1a3zDfL29HT26cvT+Su686NEFekVKlRQfHy83bL4+Hj5+/vn2osuSZ6envLM5c1yd3fnh3gpxXuLso7PAMoy2j/KguR0s/YkpGpfQqr2JqRp74kzOnDERbOPbc6jcP63QL2weM2lEIc994sK0Isf2xWarueWX1houl742MUkN1eXXArYf7dzvbAA/u9xbttdXPyeL5bd/l2Wc98LCmjX3Pe7cLuSxmw2K22fIW9Pz2L9/78j2UpUkd6qVSv99NNPdsuWLFmiVq1aOSkRAAAAUPAsVkOHT6VrX0Ka9iaknvs6kaZ9ialKTM3KZQ8XKeVUgecwmST3yxR1/xWOuRSh/xar7i55F6/nCmCXSxavtt7XXAvdPIpXu30vXby6uprsXqdLCSxWUXo4tUhPTU3Vnj17bI/379+vzZs3q3z58qpSpYrGjh2rI0eO6LPPPpMkPfDAA3r33Xf1xBNP6H//+59+++03ffXVV1q4cKGzXgIAAABwxc5kmLUv4VzxvffEuYJ8X0Ka9ielKSvbmud+EQFeqh7qqxqhfooq7624XX8r5pqm8vRwz1GE5ugBdr1cgUyxCjiTU4v09evX6/rrr7c9Pn/v+KBBgzRz5kwdO3ZMcXFxtvXVqlXTwoUL9cgjj+itt95S5cqV9fHHHzP9GgAAAIotq9XQ0eSzdr3i57+PT8nMcz8PNxdVDzlXiNcI9VX1UD/VCPVTtVBf+Xn+92u82WzWTye3q1vDCsX6cl8A+ePUIv26666TYeR9/8vMmTNz3WfTpk2FmAoAAABw3Nksy7ke8YQ07T2Rqn2J5/9NVYY5717xED9P1Qj1VY2wc0V49VBf1Qz1U8VA7xJ5jzCAq1Oi7kkHAAAAnMkwDJ04k6m9J/69Tzzhv0vUj5w+m+d+7q4mRQX7nivGQ/3+7RU/1zse4E3vN4D/UKQDAAAAF8kwW3QwKf3fAty+GE/NzM5zvyAf938vT/ez3TNeI8xPkUHecnN1KcJXAKCkokgHAABAmWQYhpLSsuwuTd+bcO77QyfTldesZK4uJlUp73PBfeL/9Y6X9/Uo2hcBoNShSAcAAECpZrZYdTAp3a5H/HyvePJZc577lfNys+8R/7cgrxLsI0831yJ8BQDKEop0AAAAlAqn07PsivDz84rHJaUrO49ucZNJqhzkreoh/xbhYb7nvg/zVaifp0wmBm4DULQo0gEAAFBiWKyGDp9KtxXhF05nlpSWled+Ph6uF/WIn+shrxbiKy93esUBFB8U6QAAACh2zmSYc51X/EBiurIseU9nFhHgZbssvUaYn61XvIK/F73iAEoEinQAAAA4hdVq6GjyWe1NSPv3fvH/esdPnMnMcz9PNxdVC/lvXvHzA7dVC/GVrye/3gIo2fhfDAAAAIUqPSvb1hP+X+94mvYnpirDnHeveGg5zxzzitcI9VOlQG+5uNArDqB0okgHAADAVTMMQ/EpmbnOK37k9Nk893N3NalqsG+OecWrh/rK38u9CF8BABQPFOkAAADItwyzRQeS0s71iF8wr/jeE6lKy7LkuV95X49z84r/e4/4+d7xyCBvubm6FOErAIDijSIdAAAAdgzDUGJq1kU94ue+P3QqXUbus5nJ1cWkqPI+9qOo/zulWZCvR9G+CAAooSjSAQAAyiizxaqDSek5RlDfeyJVKRnZee5XzsvNrgg/P3hblfK+8nCjVxwArgZFOgAAQCl3Oj3rv5HTE8/9uy8hVXEn05Vtzb1b3GSSKgd555hXvEaon0L8PJjODAAKCUU6AABAKZBtserwqbMXjaB+7hL1k2lZee7n4+FqN41Z9X97x6sG+8rL3bUIXwEAQKJIBwAAKFFSMszal8u84geT0pVlyXs6s4oBXrZ5xS+8Zzzc35NecQAoRijSAQAAihmr1dCR02dto6ZfeM/4iTOZee7n6eZim0+8ul3vuK98PPi1DwBKAv63BgAAcJL0rOwLLk3/b17x/YmpyjDn3SseVs4zx7ziNUJ9VTHAWy4u9IoDQElGkQ4AAFCIDMNQfErmf/eIn/hvXvGjyRl57ufh6qKqIT5284rXCPVTtVBf+Xu5F+ErAAAUJYp0AACAApBhtuhAUprtHvHz84rvS0hVWpYlz/2CfT1ynVe8cpC33FyZzgwAyhqKdAAAgHwyDEOJqVk55xVPSNXhU2dl5D6bmVxdTIoq72MbOf38aOrVQ/wU5OtRtC8CAFCsUaQDAABcJCvbqriTadpzIk37ElPtesdTMrLz3M/fy802gvqF94xXKe8jDzd6xQEAl0eRDgAAyqxTaVk5esT3JaTp4Ml0Way5d4u7mKTKQT7284qH+qpGmJ+CfT2YzgwAcFUo0gEAQKmWbbHq0KmzdvOK70s8d7/4ybSsPPfz9XD9b17xEF/b91HBPvJydy3CVwAAKEso0gEAQKlwNlvacjhZB09m2PWOH0hKk9mSx83ikioFel8wcNt/U5qFlfOkVxwAUOQo0gEAQIl0Ki1Lq/YkasWuBK3anaDjKW7SX2tz3dbL3UXVQ3LOK14txFc+Hvw6BAAoPvipBAAASgSL1dDmQ6e1cleCVuxK0JbDp3OMph5ezvOiEdTPFeYVA7zl4kKvOACg+KNIBwAAxVZ8SoZW/FuUr9qdqOSzZrv1dSuUU4faoWpdPUjH/16r3jd3lru7u5PSAgBw9SjSAQBAsZGZbdGGA6dshfnO42fs1gd4u6ttrRB1qB2q9rVCVSHAS5JkNpv1U6wzEgMAULAo0gEAgFMdTEo7V5THJuiPvUk6a7bY1plMUnTlwHNFee1QRVcOkJsr840DAEovinQAAFCk0jKz9ee+JFtv+cGkdLv1oeU8bUV5u5ohCvL1cFJSAACKHkU6AAAoVIZhKDb+jFbEnivK/zpw0m5KNHdXk5pFlVeHOucuYa8XUY6pzwAAZRZFOgAAKHCn0/+dHi02QSt3Jyg+JdNufWR5b3WoHaoOtcPUqkaw/Dz5lQQAAIkiHQAAFACL1dDWw6e1YleCVu5K0OZDp2W9YHo0L3cXtaoefK4wrxOmqsE+9JYDAJALinQAAHBFTvw7PdrK3Yn6fXeCTqfbT49WO9zP1lverGqQvNxdnZQUAICSgyIdAADkS1a2VesPntTKXYlasStBO46l2K3393L7b3q02qGKCPB2UlIAAEouinQAAJCnuKR0rdh9bnq0NXsTlZZlPz1a40oB/17CHqroyoFMjwYAwFWiSAcAADbpWeemRzvfW74/Mc1ufYifp9rXPtdb3q5WqMozPRoAAAWKIh0AgDLMMAztik/Vyn/nLF+3/6SyLFbbejcXk2KigmzTo9WP8JeLCwO+AQBQWCjSAQAoY5LPmrX63+nRVuxK0PGUDLv1lQK9dV2dc/eVt64RrHJe7k5KCgBA2UORDgBAKWe1Gtp2JFkr/u0t33zotCwXzI/m6eaiVjWC1b7WuXvLq4f4Mj0aAABOQpEOAEApdOJMhn7/977y33cn6NRF06PVCvNT+9qh6lA7VM2rlWd6NAAAigmKdAAASoGsbKs2xp0611sem6B/LpoerZynm9rUDDl3b3ntUFUKZHo0AACKI4p0AABKqEMn022XsK/Zm6TUzGy79Y0umB6tSWSg3JkeDQCAYo8iHQCAEuJslkV/7k/SitgErdydoH0J9tOjBft62C5hb1srRCF+nk5KCgAArhRFOgAAxZRhGNpzItXWW752/0llZf83PZqri0kxVc5Nj9ahNtOjAQBQGlCkAwBQjKRkmPXHnkTbveVHk3NOj3a+t7x1zWD5Mz0aAAClCkU6AABOZLUa2n40WSv/7S3fGGc/PZqHm4taVg8+d2957RDVCPVjejQAAEoxinQAAIpYYmqmft99rqf8992JSkrLsltfI9RXHWqHqX3tELWoFixvD6ZHAwCgrKBIBwCgkJktVm2KO60Vu05oxa4EbT9iPz2an6eb2tQMVvvaoWpfK1SR5X2clBQAADgbRToAAIXg8Kl0rdyVqBW7TuiPPUk6c9H0aA0r+at9rXP3ll8TFcT0aAAAQBJFOgAABSLDbNHa/Se1IjZBK3ad0N6Lpkcr7+uhdrVC1KF2qNrVClVoOaZHAwAAOTm9SJ86dapee+01HT9+XNHR0XrnnXfUvHnzXLc1m82aNGmSPv30Ux05ckR16tTRK6+8oq5duxZxagBAWWcYhvYmpP03Pdq+JGVeND1a08jAcwO+1QlVw4oBTI8GAAAuy6lF+ty5czV69GhNmzZNLVq00JQpU9SlSxfFxsYqLCwsx/bPPPOMZs+erY8++kh169bVL7/8oltvvVV//PGHmjZt6oRXAAAoS85kmLV6T5JW7ErQyl0JOnL6rN36iACvf0dhD1XrmiEK8GZ6NAAA4BinFumTJ0/WkCFDNHjwYEnStGnTtHDhQk2fPl1jxozJsf2sWbP09NNPq3v37pKkYcOG6ddff9Ubb7yh2bNnF2l2AEDpZ7Ua+udYim3O8o1xp5R90fRoLaqVV4faoWpfO1S1wpgeDQAAXB2nFelZWVnasGGDxo4da1vm4uKiTp06ac2aNbnuk5mZKS8vL7tl3t7eWrVqVZ7Pk5mZqczMTNvjlJRzI+qazWaZzeareQkoZs6/n7yvKKv4DBSMpLQsrdqTpFW7E/X7nqQc06NVC/ZRu1ohal8rWM2rlrebHi07O/viw6GI0P5RltH+UZaVlPbvSD6nFemJiYmyWCwKDw+3Wx4eHq6dO3fmuk+XLl00efJktW/fXjVq1NDSpUv17bffymKx5Pk8kyZN0sSJE3MsX7x4sXx8mOKmNFqyZImzIwBOxWfAMRZDOnBG2nnaRTtOm3Q4TTL0X2+4p4uh2gGG6gYaqhdoKNgrRVKK0vbs07I9zsuN3NH+UZbR/lGWFff2n56enu9tnT5wnCPeeustDRkyRHXr1pXJZFKNGjU0ePBgTZ8+Pc99xo4dq9GjR9sep6SkKDIyUp07d5a/v39RxEYRMZvNWrJkiW688Ua5u3MfKMoePgP5dyw5Q7/vTtTK3Yn6Y99Jncmw7wGvV6Gc2tcKUbtawWoaGSgPN6ZHK+5o/yjLaP8oy0pK+z9/RXd+OK1IDwkJkaurq+Lj4+2Wx8fHq0KFCrnuExoaqu+//14ZGRlKSkpSxYoVNWbMGFWvXj3P5/H09JSnZ85pbtzd3Yv1m4grx3uLso7PQE4ZZovW7T+plf+OxL77RKrd+iAfd7Wrde6+8va1QhTm75XHkVDc0f5RltH+UZYV9/bvSDanFekeHh6KiYnR0qVL1atXL0mS1WrV0qVLNXLkyEvu6+XlpUqVKslsNuubb75Rnz59iiAxAKCkMAxD+xP/mx7tz31JyjD/Nz2ai0lqWiVI7Wudmx6tUaUAuTI9GgAAKAacern76NGjNWjQIDVr1kzNmzfXlClTlJaWZhvtfeDAgapUqZImTZokSVq7dq2OHDmiJk2a6MiRI3r22WdltVr1xBNPOPNlAACKgdTMbP2xJ9FWmB8+ZT89WgV/L7WvHaIOtcPUtmaIAnyK71/bAQBA2eXUIr1v375KSEjQ+PHjdfz4cTVp0kSLFi2yDSYXFxcnF5f/7gPMyMjQM888o3379snPz0/du3fXrFmzFBgY6KRXAABwFsOwnx5tw8GLpkdzddG11YL+nbc8TLXDmR4NAAAUf1dUpM+aNUvTpk3T/v37tWbNGkVFRWnKlCmqVq2abrnlFoeONXLkyDwvb1++fLnd4w4dOuiff/65ksgAgFLgZFqWft99rqf8992JSjiTabe+arDPuaK8TqhaVg+Wj0eJGh8VAADA8SL9/fff1/jx4zVq1Ci9+OKLtunPAgMDNWXKFIeLdAAA8pJtsWrL4dNaEZugFbsTtfXwaRn/dZbLx8NVrWsEq0Ptc4O+RQX7Oi8sAABAAXC4SH/nnXf00UcfqVevXnr55Zdty5s1a6bHHnusQMMBAMqeY8lnbaOwr9qdqJSLpkerW6GcOtQJVYfaoYqJCpKnm6uTkgIAABQ8h4v0/fv3q2nTpjmWe3p6Ki0trUBCAQDKjsxsi/7af0ordp3Qyl2Jio0/Y7c+wNtd7WqF2HrLw5keDQAAlGIOF+nVqlXT5s2bFRUVZbd80aJFqlevXoEFAwCUToZh6EBSulbEntDK3YlaszdJZ80W23qTSWoSGWgryqMrBzI9GgAAKDMcLtJHjx6tESNGKCMjQ4ZhaN26dfriiy80adIkffzxx4WREQBQwqVmZmvN3iTbZexxJ9Pt1oeV87QV5W1rhijI18NJSQEAAJzL4SL9vvvuk7e3t5555hmlp6frrrvuUsWKFfXWW2+pX79+hZERAFDCGIahHcfOaOXuc9OjrT94UmbLfyO+ubuadG3V8mpf+9y95XUrlGN6NAAAAF3hFGz9+/dX//79lZ6ertTUVIWFhRV0LgBACXMqLUur9iRqxa4ErdyVoBMXTY9Wpfy/06PVDlWrGsHy9WR6NAAAgItd0cBx2dnZqlWrlnx8fOTj4yNJ2r17t9zd3VW1atWCzggAKIYsVuO/6dF2JWjLRdOjebu7qtW/06N1qB2qqiFMjwYAAHA5Dhfp99xzj/73v/+pVq1adsvXrl2rjz/+WMuXLy+obACAYiY+JUMrLpgeLfms2W59nfD/pkdrVpXp0QAAABzlcJG+adMmtWnTJsfyli1bauTIkQUSCgBQPGRmW7ThwClbYb7zuP30aP5ebmpX61xR3q52iCICvJ2UFAAAoHRwuEg3mUw6c+ZMjuXJycmyWCy57AEAKEkOJqWdK8pjE7RmX5LSs+ynR2tcOdB2CXt05QC5ubo4MS0AAEDp4nCR3r59e02aNElffPGFXF3PXcZosVg0adIktW3btsADAgAKV1pmtv7cl2Qb8O1Akv30aCF+56ZH61Dn3PRo5ZkeDQAAoNA4XKS/8sorat++verUqaN27dpJkn7//XelpKTot99+K/CAAICCZRiGYuPPaEVsglbuTtBf+08py2K1rXdzMalZ1SB1qB2m9rVDVK+Cv1xcmB4NAACgKDhcpNevX19bt27Vu+++qy1btsjb21sDBw7UyJEjVb58+cLICAC4SqfTz02PtvLfe8vjU+ynR6sc5K3r6oSqfa1Qta4ZIj+mRwMAAHCKK/otrGLFinrppZcKOgsAoIBYrIa2Hj5tu4R986HTsl4wPZqXu4taVQ9W+3/vLa8W4iuTid5yAAAAZ7uiIv306dNat26dTpw4IavVardu4MCBBRIMAOCYE2cyte6ESYu/2qrVe5N0Ot1+erTa4X5qX+vcveXXVi0vL3emRwMAAChuHC7Sf/jhB/Xv31+pqany9/e363kxmUwU6QBQxCxWQ28u2aX3lu+R1XCVdFySVM7LTW1rhqhD7VC1rx2qioFMjwYAAFDcOVykP/roo/rf//6nl156ST4+PoWRCQCQT6fTs/TQl5u1cleCJCnS11DPZjXUsV64mkQGMj0aAABACeNwkX7kyBE99NBDFOgA4GT/HE3R0NnrdejkWXm5u+jFWxrI7cgmde9UU+7u7s6OBwAAgCvgcBdLly5dtH79+sLIAgDIp/mbj6j3+6t16ORZRZb31rfD2ujm6AhnxwIAAMBVcrgnvUePHnr88cf1zz//qFGjRjl6a26++eYCCwcAsJdtsWrSzzv1yar9kqR2tUL0zp1NFejjIbPZfJm9AQAAUNw5XKQPGTJEkvTcc8/lWGcymWSxWK4+FQAgh8TUTI2cs1F/7jspSRp+XQ092rmOXF2YOg0AAKC0cLhIv3jKNQBA4dty6LQemL1Bx5Iz5Ovhqjf6RKtrQy5vBwAAKG2uaJ50AEDR+eqvQ3pm/nZlZVtVPcRXHwyIUa3wcs6OBQAAgEJwRUV6WlqaVqxYobi4OGVlZdmte+ihhwokGACUdZnZFk384R/NWRsnSepUL1yT+0bL34uR2wEAAEorh4v0TZs2qXv37kpPT1daWprKly+vxMRE+fj4KCwsjCIdAApAfEqGHpi9QZviTstkkkZ3qq0R19eUC/efAwAAlGoOT8H2yCOPqGfPnjp16pS8vb31559/6uDBg4qJidHrr79eGBkBoEz568BJ9Xh7lTbFnZa/l5umD7pWD95QiwIdAACgDHC4SN+8ebMeffRRubi4yNXVVZmZmYqMjNSrr76qp556qjAyAkCZYBiGPv3jgO788E8lpmaqboVyWjCyra6vG+bsaAAAACgiDl/u7u7uLheXc7V9WFiY4uLiVK9ePQUEBOjQoUMFHhAAyoIMs0VPfbdN3248Ikm6qXGEXr29sXw8GN8TAACgLHH4t7+mTZvqr7/+Uq1atdShQweNHz9eiYmJmjVrlho2bFgYGQGgVDt8Kl0PzN6g7UdS5GKSxnarp/vaVZPJxOXtAAAAZY3Dl7u/9NJLiog4Nzfviy++qKCgIA0bNkwJCQn68MMPCzwgAJRmq/ckquc7q7T9SIrK+3po9r0tNKR9dQp0AACAMsrhnvRmzZrZvg8LC9OiRYsKNBAAlAWGYejDlfv0yqKdshpSo0oBmjYgRpUCvZ0dDQAAAE7EzY4AUMTSMrP1xDdbtXDrMUnS7TGV9UKvhvJyd3VyMgAAADhbvor0a665RkuXLlVQUJCaNm16ycswN27cWGDhAKC0OZCYpqGzNig2/ozcXEya0LO+7m4ZxeXtAAAAkJTPIv2WW26Rp6enJKlXr16FmQcASq3fdsbr4S8360xGtkLLeer9/teoWdXyzo4FAACAYiRfRfqECRMkSRaLRddff70aN26swMDAwswFAKWG1Wrond/2aMrSXTIMKSYqSO/1v0bh/l7OjgYAAIBixqF70l1dXdW5c2ft2LGDIh0A8iElw6zRc7fo1x3xkqS7W1bR+JsayMPN4ck1AAAAUAY4PHBcw4YNtW/fPlWrVq0w8gBAqbE7/oyGztqgfYlp8nBz0Qu9GqpPs0hnxwIAAEAx5nBXzgsvvKDHHntMP/74o44dO6aUlBS7LwCA9NO2Y7pl6mrtS0xTxQAvzXugFQU6AAAALsvhnvTu3btLkm6++Wa70YgNw5DJZJLFYim4dABQwlishl77JVbTVuyVJLWqHqx372qqYD9PJycDAABASeBwkb5s2bLCyAEAJd6ptCw99OUm/b47UZI0pF01Pdm1rtxcuf8cAAAA+eNwkd6hQ4fCyAEAJdr2I8l6YPYGHT51Vl7uLnr19mjdHF3R2bEAAABQwjhcpJ+Xnp6uuLg4ZWVl2S1v3LjxVYcCgJLku02HNeabbcrMtqpKeR99MCBG9SL8nR0LAAAAJZDDRXpCQoIGDx6sn3/+Odf13JMOoKwwW6x66acdmrH6gCSpQ+1QvdWviQJ9PJwbDAAAACWWwzdKjho1SqdPn9batWvl7e2tRYsW6dNPP1WtWrW0YMGCwsgIAMVOwplM9f94ra1AH3l9TU2/51oKdAAAAFwVh3vSf/vtN82fP1/NmjWTi4uLoqKidOONN8rf31+TJk1Sjx49CiMnABQbm+JOadjsjTqekiE/Tze90SdaXRpUcHYsAAAAlAIO96SnpaUpLCxMkhQUFKSEhARJUqNGjbRx48aCTQcAxcwX6+LU94M/dTwlQzVCffX9iDYU6AAAACgwDvek16lTR7Gxsapataqio6P1wQcfqGrVqpo2bZoiIiIKIyMAOF1mtkXPLvhbX6w7JEnq0iBcr98RrXJe7k5OBgAAgNLE4SL94Ycf1rFjxyRJEyZMUNeuXfX555/Lw8NDM2fOLOh8AOB0x5LPatjsjdp86LRMJumxznU0rEMNubiYnB0NAAAApUy+i/Tbb79d9913n/r37y+T6dwvpjExMTp48KB27typKlWqKCQkpNCCAoAzrN2XpBFzNioxNUsB3u56q18TXVcnzNmxAAAAUErl+570U6dOqUePHqpSpYrGjx+vffv2SZJ8fHx0zTXXUKADKFUMw9CM1fvV/+O1SkzNUt0K5fTDyLYU6AAAAChU+S7Sly5dqn379unee+/V7NmzVatWLXXs2FFz5sxRZmZmYWYEgCJ1Nsui0V9t0cQf/lG21dDN0RX17fDWqhLs4+xoAAAAKOUcGt09KipKzz77rPbt26clS5aoYsWKGjJkiCIiIjRixAht2LDB4QBTp05V1apV5eXlpRYtWmjdunWX3H7KlCmqU6eOvL29FRkZqUceeUQZGRkOPy8A5ObQyXTd9v4f+m7TEbm6mPRMj3p6q18T+Xg4PIQHAAAA4LAr/q2zY8eO6tixo86cOaM5c+boqaee0gcffKDs7Ox8H2Pu3LkaPXq0pk2bphYtWmjKlCnq0qWLYmNjbdO8XWjOnDkaM2aMpk+frtatW2vXrl265557ZDKZNHny5Ct9KQAgSfp9d4Ie/GKTTqebFezroXfuaqrWNbiVBwAAAEXnqrqG9u/fr5kzZ2rmzJlKTk5Wp06dHNp/8uTJGjJkiAYPHixJmjZtmhYuXKjp06drzJgxObb/448/1KZNG911112SpKpVq+rOO+/U2rVrr+ZlACjjDMPQtBX79NovO2U1pMaVAzTt7hhVDPR2djQAAACUMQ4X6RkZGZo3b56mT5+ulStXKjIyUvfee68GDx6syMjIfB8nKytLGzZs0NixY23LXFxc1KlTJ61ZsybXfVq3bq3Zs2dr3bp1at68ufbt26effvpJAwYMyPN5MjMz7e6ZT0lJkSSZzWaZzeZ850Xxd/795H2FI1IzszX2u7+16O94SdLt11TSszfVlae7a4lrS3wGUJbR/lGW0f5RlpWU9u9IvnwX6evWrdP06dM1d+5cZWRk6NZbb9WiRYt0ww032KZkc0RiYqIsFovCw8PtloeHh2vnzp257nPXXXcpMTFRbdu2lWEYys7O1gMPPKCnnnoqz+eZNGmSJk6cmGP54sWL5ePDIFCl0ZIlS5wdASXEibPSJ7GuOn7WJFeTod5VrWrjcVBLlxx0drSrwmcAZRntH2UZ7R9lWXFv/+np6fneNt9FesuWLRUdHa3nn39e/fv3V1BQ0BWFuxrLly/XSy+9pPfee08tWrTQnj179PDDD+v555/XuHHjct1n7NixGj16tO1xSkqKIiMj1blzZ/n7+xdVdBQBs9msJUuW6MYbb5S7u7uz46CYW7rzhN6at12pmdkKK+epd/tFq2mVQGfHuip8BlCW0f5RltH+UZaVlPZ//oru/Mh3kb5+/Xpdc801VxQoNyEhIXJ1dVV8fLzd8vj4eFWoUCHXfcaNG6cBAwbovvvukyQ1atRIaWlpuv/++/X000/LxSXnYPWenp7y9PTMsdzd3b1Yv4m4cry3uBSr1dCUpbv19tLdkqRmUUF6r/81CvP3cnKygsNnAGUZ7R9lGe0fZVlxb/+OZMv3FGwFWaBLkoeHh2JiYrR06VLbMqvVqqVLl6pVq1a57pOenp6jEHd1dZV0buAnALiU5LNm3ffZeluBPqhVlOYMaVmqCnQAAACUbE6d+Hf06NEaNGiQmjVrpubNm2vKlClKS0uzjfY+cOBAVapUSZMmTZIk9ezZU5MnT1bTpk1tl7uPGzdOPXv2tBXrAJCb2ONnNHTWeh1ISpenm4tevLWRbo+p7OxYAAAAgB2nFul9+/ZVQkKCxo8fr+PHj6tJkyZatGiRbTC5uLg4u57zZ555RiaTSc8884yOHDmi0NBQ9ezZUy+++KKzXgKAEuDHrUf1xLytSs+yqFKgtz4YEKOGlQKcHQsAAADIwalFuiSNHDlSI0eOzHXd8uXL7R67ublpwoQJmjBhQhEkA1DSZVuseu2XWH2wcp8kqU3NYL1z5zUq7+vh5GQAAABA7pxepANAYTiZlqUHv9io1XuSJEn3t6+uJ7rUkZtrvofiAAAAAIpcvor0pk2b5nsu9I0bN15VIAC4WtuPJGvorA06cvqsvN1d9ertjdUzuqKzYwEAAACXla8ivVevXrbvMzIy9N5776l+/fq2Udj//PNP/f333xo+fHihhASA/Ppmw2E99d02ZWZbFRXsow8HNFOdCuWcHQsAAADIl3wV6RfeA37ffffpoYce0vPPP59jm0OHDhVsOgDIJ7PFqhd+/EefrjkoSbq+Tqim9GuqAO/iO18mAAAAcDGH70n/+uuvtX79+hzL7777bjVr1kzTp08vkGAAkF8nzmRoxOcb9deBU5Kkh26opVE31JKLS/5u0wEAAACKC4eLdG9vb61evVq1atWyW7569Wp5eXkVWDAAyI8NB09p+OcbFJ+SqXKebprct4lurB/u7FgAAADAFXG4SB81apSGDRumjRs3qnnz5pKktWvXavr06Ro3blyBBwSA3BiGoTnr4vTsgr9lthiqGeanDwbEqEaon7OjAQAAAFfM4SJ9zJgxql69ut566y3Nnj1bklSvXj3NmDFDffr0KfCAAHCxDLNFE+b/rbnrz42D0a1hBb12R7T8PJlVEgAAACXbFf1G26dPHwpyAE5x9PRZDZu9QVsOJ8vFJD3WpY6GdaiR72kiAQAAgOLsior006dPa968edq3b58ee+wxlS9fXhs3blR4eLgqVapU0BkBQJK0Zm+SRs7ZqKS0LAX6uOvtfk3Vvnaos2MBAAAABcbhIn3r1q3q1KmTAgICdODAAd13330qX768vv32W8XFxemzzz4rjJwAyjDDMPTJqv2a9PNOWayG6kX468MBMYos7+PsaAAAAECBcnF0h9GjR+uee+7R7t277UZz7969u1auXFmg4QDgbJZFo+Zu1gsLd8hiNdSrSUV9O6w1BToAAABKJYd70v/66y998MEHOZZXqlRJx48fL5BQACBJcUnpun/Weu08fkauLiY93b2eBrepyv3nAAAAKLUcLtI9PT2VkpKSY/muXbsUGsq9oQAKxopdCXroi01KPmtWiJ+H3r3rGrWsHuzsWAAAAEChcvhy95tvvlnPPfeczGazJMlkMikuLk5PPvmkbrvttgIPCKBsMQxDU5ft0T0z1in5rFnRkYH64cG2FOgAAAAoExwu0t944w2lpqYqLCxMZ8+eVYcOHVSzZk2VK1dOL774YmFkBFBGpGZm64HZG/TaL7EyDKnftZH6amhLRQR4OzsaAAAAUCQcvtw9ICBAS5Ys0apVq7R161alpqbqmmuuUadOnQojH4AyYm9Cqu7/bL32JqTJw9VFE29poDubV3F2LAAAAKBIXdE86ZLUtm1btW3btiCzACijFv99XKO/2qLUzGxV8PfSe3dfo2uqBDk7FgAAAFDkrqhIX7p0qZYuXaoTJ07IarXarZs+fXqBBANQ+lmshqb8ukvv/LZHktS8anlN7X+NQst5OjkZAAAA4BwOF+kTJ07Uc889p2bNmikiIoKpkABckeR0sx6eu0nLYxMkSfe0rqqne9STu6vDQ2UAAAAApYbDRfq0adM0c+ZMDRgwoDDyACgDdh5P0dBZG3QwKV2ebi56+bZGurVpZWfHAgAAAJzO4SI9KytLrVu3LowsAMqABVuO6sl5W3XWbFGlQG99MCBGDSsFODsWAAAAUCw4fF3pfffdpzlz5hRGFgClWLbFqhcX/qOHvtiks2aL2tYM0Y8PtqVABwAAAC7gcE96RkaGPvzwQ/36669q3Lix3N3d7dZPnjy5wMIBKB2SUjM1cs4mrdmXJEl6oEMNPd6ljlxdGNMCAAAAuJDDRfrWrVvVpEkTSdL27dvt1jGIHICLbT18Wg/M2qCjyRny8XDV63dEq3ujCGfHAgAAAIolh4v0ZcuWFUYOAKXQ1+sP6envtysr26pqIb76YECMaoeXc3YsAAAAoNi6onnSAeBSsrKtev7HfzTrz4OSpBvqhmly3yYK8Ha/zJ4AAABA2ZavIr13796aOXOm/P391bt370tu++233xZIMAAl04mUDA3/fKPWHzwlSRrVqZYe6lhLLtx/DgAAAFxWvor0gIAA2/3mAQGMxAwgdxsOntSw2Rt14kymynm5aUrfJrqhXrizYwEAAAAlRr6K9BkzZuT6PQBIkmEYmv3nQT334z8yWwzVDvfTBwOaqVqIr7OjAQAAACUK96QDuCoZZoue+X675m04LEnq0ShCr97eWL6e/PcCAAAAOOqKfoueN2+evvrqK8XFxSkrK8tu3caNGwskGIDi78jps3pg1gZtO5IsF5P0ZNe6ur99daZjBAAAAK6Qi6M7vP322xo8eLDCw8O1adMmNW/eXMHBwdq3b5+6detWGBkBFEN/7ElUz3dWaduRZAX6uOvT/zXX0A41KNABAACAq+Bwkf7ee+/pww8/1DvvvCMPDw898cQTWrJkiR566CElJycXRkYAxYhhGPpo5T7d/clanUzLUoOK/vphZFu1qxXq7GgAAABAiedwkR4XF6fWrVtLkry9vXXmzBlJ0oABA/TFF18UbDoAxUp6VrYe+nKzXvxph6yG1LtpJX0zrLUiy/s4OxoAAABQKjhcpFeoUEEnT56UJFWpUkV//vmnJGn//v0yDKNg0wEoNg4mpan3e3/ohy1H5eZi0rM96+uNPtHycnd1djQAAACg1HB44LiOHTtqwYIFatq0qQYPHqxHHnlE8+bN0/r169W7d+/CyAjAyZbFntDDX2xSSka2Qvw89V7/a9S8WnlnxwIAAABKHYeL9A8//FBWq1WSNGLECAUHB+uPP/7QzTffrKFDhxZ4QADOY7Uamrpsjyb/ukuGITWtEqj3+8eoQoCXs6MBAAAApZLDRbqLi4tcXP67Sr5fv37q169fgYYC4HxnMswa/dUWLfknXpJ0V4sqmtCzvjzduLwdAAAAKCz5KtK3bt2a7wM2btz4isMAKB72nDij+2dt0L6ENHm4uuj5Xg3U99oqzo4FAAAAlHr5KtKbNGkik8l02YHhTCaTLBZLgQQD4ByLth/Xo19tVlqWRREBXnr/7hg1iQx0diwAAACgTMhXkb5///7CzgHAySxWQ5OXxGrqsr2SpBbVymtq/2sU4ufp5GQAAABA2ZGvIj0qKqqwcwBwotPpWXroy81auStBkvS/NtU0tntdubs6PEsjAAAAgKvg8MBxkhQbG6t33nlHO3bskCTVq1dPDz74oOrUqVOg4QAUvn+Opmjo7PU6dPKsvNxd9HLvxurVtJKzYwEAAABlksPdZN98840aNmyoDRs2KDo6WtHR0dq4caMaNmyob775pjAyAigk8zcfUe/3V+vQybOKLO+tb4a1pkAHAAAAnMjhnvQnnnhCY8eO1XPPPWe3fMKECXriiSd02223FVg4AIXDbLFq0k87NX31ufEm2tUK0Tt3NlWgj4eTkwEAAABlm8M96ceOHdPAgQNzLL/77rt17NixAgkFoPAkpmbq7o/X2gr04dfV0MzBzSnQAQAAgGLA4Z706667Tr///rtq1qxpt3zVqlVq165dgQUDUPA2HzqtYbM36Fhyhnw9XPVGn2h1bRjh7FgAAAAA/uVwkX7zzTfrySef1IYNG9SyZUtJ0p9//qmvv/5aEydO1IIFC+y2BVA8zP0rTuO+/1tZFquqh/jqgwExqhVeztmxAAAAAFzA4SJ9+PDhkqT33ntP7733Xq7rJMlkMslisVxlPABXKzPbook//KM5a+MkSZ3qhWty32j5e7k7ORkAAACAizlcpFut1sLIAaAQxKdk6IHZG7Qp7rRMJml0p9oacX1NubiYnB0NAAAAQC6uaJ70vKSnp8vHx6cgDwngCv114KSGzd6oxNRM+Xu56a1+TXV93TBnxwIAAABwCQ6P7n7DDTfoyJEjOZavXbtWTZo0uaIQU6dOVdWqVeXl5aUWLVpo3bp1eW573XXXyWQy5fjq0aPHFT03UNoYhqFP/zigOz/8U4mpmaoTXk4LRralQAcAAABKAIeLdC8vLzVu3Fhz586VdO7y92effVbt2rVT9+7dHQ4wd+5cjR49WhMmTNDGjRsVHR2tLl266MSJE7lu/+233+rYsWO2r+3bt8vV1VV33HGHw88NlDYZZose/XqLJiz4W9lWQz0aR+jb4a1VNcTX2dEAAAAA5IPDl7svXLhQU6dO1f/+9z/Nnz9fBw4c0MGDB/Xjjz+qc+fODgeYPHmyhgwZosGDB0uSpk2bpoULF2r69OkaM2ZMju3Lly9v9/jLL7+Uj48PRTrKvMOn0vXA7A3afiRFLiZpTLe6GtKuukwm7j8HAAAASooruid9xIgROnz4sF555RW5ublp+fLlat26tcPHycrK0oYNGzR27FjbMhcXF3Xq1Elr1qzJ1zE++eQT9evXT76+ufcUZmZmKjMz0/Y4JSVFkmQ2m2U2mx3OjOLr/PtZFt/X1XuT9MhXW3Uq3awgH3dN6dNYrWsEKzs729nRUITK8mcAoP2jLKP9oywrKe3fkXwOF+mnTp3Sfffdp6VLl+qDDz7QihUr1LlzZ7366qt2U7DlR2JioiwWi8LDw+2Wh4eHa+fOnZfdf926ddq+fbs++eSTPLeZNGmSJk6cmGP54sWLGeSulFqyZImzIxQZw5B+O2rSD3EuMmRSpK+h/9U5q9Oxa/VTrLPTwVnK0mcAuBjtH2UZ7R9lWXFv/+np6fne1uEivWHDhqpWrZo2bdqkatWqaciQIZo7d66GDx+uhQsXauHChY4e8op98sknatSokZo3b57nNmPHjtXo0aNtj1NSUhQZGanOnTvL39+/KGKiiJjNZi1ZskQ33nij3N1L/xzgaZnZGvvd3/o5Ll6S1LtpRU3sWU9e7q5OTgZnKWufAeBCtH+UZbR/lGUlpf2fv6I7Pxwu0h944AE9/fTTcnH5b8y5vn37qk2bNrb7yvMrJCRErq6uio+Pt1seHx+vChUqXHLftLQ0ffnll3ruuecuuZ2np6c8PT1zLHd3dy/WbyKuXFl4b/cnpmnorPXaFZ8qNxeTJvSsr7tbRnH/OSSVjc8AkBfaP8oy2j/KsuLe/h3J5vDo7uPGjbMr0M+rXLmyw5cYeHh4KCYmRkuXLrUts1qtWrp0qVq1anXJfb/++mtlZmbq7rvvdug5gZLut53xuvndVdoVn6rQcp768v6WGtCqKgU6AAAAUArku0h/9dVXdfbsWdvj1atX2w3IdubMGYfvSZek0aNH66OPPtKnn36qHTt2aNiwYUpLS7P1yg8cONBuYLnzPvnkE/Xq1UvBwcEOPydQElmtht76dbfu/XS9zmRkKyYqSD8+2FbNqpa//M4AAAAASoR8F+ljx47VmTNnbI+7deumI0eO2B6np6frgw8+cDhA37599frrr2v8+PFq0qSJNm/erEWLFtkGk4uLi9OxY8fs9omNjdWqVat07733Ovx8QEmUkmHW/bM26M1fd8kwpLtbVtEXQ1oq3N/L2dEAAAAAFKB835NuGMYlH1+NkSNHauTIkbmuW758eY5lderUKdDnB4qz3fFnNHTWBu1LTJOHm4te6NVQfZpFOjsWAAAAgEJwRfOkAygaP207pse+3qL0LIsqBnhp2oAYNa4c6OxYAAAAAAoJRTpQDFmshl77JVbTVuyVJLWsXl7v3nWNQvxyzlQAAAAAoPRwqEj/+OOP5efnJ0nKzs7WzJkzFRISIkl296sDuHKn0rL00Jeb9PvuREnSfW2raUy3unJzdXgyBgAAAAAlTL6L9CpVquijjz6yPa5QoYJmzZqVYxsAV277kWQ9MHuDDp86Ky93F71yW2Pd0qSSs2MBAAAAKCL5LtIPHDhQiDEAfLfpsMZ8s02Z2VZVKe+jDwbEqF6Ev7NjAQAAAChC3JMOOJnZYtWLC3do5h8HJEkdaofqrX5NFOjj4dxgAAAAAIocRTrgRAlnMjVizkat239SkjTy+pp65MbacnUxOTkZAAAAAGegSAecZGPcKQ2bvUHxKZny83TTG32i1aVBBWfHAgAAAOBEFOmAE3yxLk4T5v+tLItVNUJ99cGAZqoZ5ufsWAAAAACcjCIdKEKZ2RY9u+BvfbHukCSpS4NwvX5HtMp5uTs5GQAAAIDi4IomXt67d6+eeeYZ3XnnnTpx4oQk6eeff9bff/9doOGA0uRY8ln1/eBPfbHukEwm6fEudfR+/xgKdAAAAAA2DhfpK1asUKNGjbR27Vp9++23Sk1NlSRt2bJFEyZMKPCAQGmwdl+Ser6zSpsPnZa/l5tm3HOtRlxfUy4MEAcAAADgAg4X6WPGjNELL7ygJUuWyMPjvymiOnbsqD///LNAwwElnWEYmrF6v/p/vFaJqVmqW6Gcfniwra6rE+bsaAAAAACKIYfvSd+2bZvmzJmTY3lYWJgSExMLJBRQGpzNsuip77bpu01HJEk3R1fUy7c1ko8HQ0EAAAAAyJ3D1UJgYKCOHTumatWq2S3ftGmTKlWqVGDBgJLs0Ml0DZ21Qf8cS5Gri0lju9XVvW2ryWTi8nYAAAAAeXP4cvd+/frpySef1PHjx2UymWS1WrV69Wo99thjGjhwYGFkBEqUlbsS1PPdVfrnWIqCfT00697muq9ddQp0AAAAAJflcE/6Sy+9pBEjRigyMlIWi0X169eXxWLRXXfdpWeeeaYwMgIlgmEYen/FXr3+S6yshtS4coCm3R2jioHezo4GAAAAoIRwuEj38PDQRx99pHHjxmn79u1KTU1V06ZNVatWrcLIB5QIqZnZevzrLfp5+3FJUp9mlfXcLQ3l5e7q5GQAAAAAShKHi/RVq1apbdu2qlKliqpUqVIYmYASZV9CqobO2qDdJ1Ll7mrShJ4N1L9FFS5vBwAAAOAwh+9J79ixo6pVq6annnpK//zzT2FkAkqMX/+J1y3vrtbuE6kKK+epL+9vpbtbRlGgAwAAALgiDhfpR48e1aOPPqoVK1aoYcOGatKkiV577TUdPny4MPIBxZLVamjykl2677P1OpOZrWZRQfrxwbaKiQpydjQAAAAAJZjDRXpISIhGjhyp1atXa+/evbrjjjv06aefqmrVqurYsWNhZASKleSzZt332Xq9vXS3JGlgqyjNGdJSYf5eTk4GAAAAoKRz+J70C1WrVk1jxoxRdHS0xo0bpxUrVhRULqBYij1+RkNnrdeBpHR5uLnopVsb6faYys6OBQAAAKCUcLgn/bzVq1dr+PDhioiI0F133aWGDRtq4cKFBZkNKFZ+3HpUt763WgeS0lUp0FvfPNCaAh0AAABAgXK4J33s2LH68ssvdfToUd1444166623dMstt8jHx6cw8gFOl22x6rVfYvXByn2SpNY1gvXOnU0V7Ofp5GQAAAAAShuHi/SVK1fq8ccfV58+fRQSElIYmYBi42Ralh78YqNW70mSJN3fvrqe6FJHbq5XfBEKAAAAAOTJ4SJ99erVhZEDKHa2H0nW0FkbdOT0WXm7u+rV2xurZ3RFZ8cCAAAAUIrlq0hfsGCBunXrJnd3dy1YsOCS2958880FEgxwpm82HNZT321TZrZVUcE++nBAM9WpUM7ZsQAAAACUcvkq0nv16qXjx48rLCxMvXr1ynM7k8kki8VSUNmAIpeVbdULC//RZ2sOSpKurxOqKf2aKsDb3cnJAAAAAJQF+SrSrVZrrt8DpcmJMxka8flG/XXglCTpoRtqadQNteTiYnJyMgAAAABlhcOjX3322WfKzMzMsTwrK0ufffZZgYQCitqGg6d009ur9NeBUyrn6aaPBjbT6BtrU6ADAAAAKFIOF+mDBw9WcnJyjuVnzpzR4MGDCyQUUFQMw9Dnaw+q34drdOJMpmqG+en7kW10Y/1wZ0cDAAAAUAY5PLq7YRgymXL2Lh4+fFgBAQEFEgooChlmiybM/1tz1x+SJHVtUEGv94mWn6fDHwsAAAAAKBD5rkaaNm0qk8kkk8mkG264QW5u/+1qsVi0f/9+de3atVBCAgXt6OmzGjZ7g7YcTpbJJD3epY6GdaiR6x+gAAAAAKCo5LtIPz+q++bNm9WlSxf5+fnZ1nl4eKhq1aq67bbbCjwgUNDW7E3SyDkblZSWpQBvd71zZ1O1rx3q7FgAAAAAkP8ifcKECZKkqlWrqm/fvvLy8iq0UEBhMAxDn6zar0k/75TFaqhehL8+HBCjyPI+zo4GAAAAAJKu4J70QYMGFUYOoFCdzbJozLdbNX/zUUlSryYVNal3Y3l7uDo5GQAAAAD8x+Ei3WKx6M0339RXX32luLg4ZWVl2a0/efJkgYUDCkJcUrrun7VeO4+fkauLSU93r6fBbapy/zkAAACAYsfhKdgmTpyoyZMnq2/fvkpOTtbo0aPVu3dvubi46Nlnny2EiMCVWx57Qj3fXaWdx88oxM9Dn9/XQv9rW40CHQAAAECx5HCR/vnnn+ujjz7So48+Kjc3N9155536+OOPNX78eP3555+FkRFwmGEYmrpsjwbP/EvJZ82KjgzUDw+2Vcvqwc6OBgAAAAB5crhIP378uBo1aiRJ8vPzU3JysiTppptu0sKFCws2HXAFzmRk64HZG/TaL7EyDKnftZH6amhLRQR4OzsaAAAAAFySw0V65cqVdezYMUlSjRo1tHjxYknSX3/9JU9Pz4JNBzgo/qx0+wdr9cvf8fJwddGk3o308m2N5enGAHEAAAAAij+HB4679dZbtXTpUrVo0UIPPvig7r77bn3yySeKi4vTI488UhgZgXxZsy9Jb2xzVaYlTRX8vfTe3dfomipBzo4FAAAAAPnmcJH+8ssv277v27evqlSpojVr1qhWrVrq2bNngYYD8ispNVOPfLVNmRaTmkUF6v27mym0HFd2AAAAAChZHC7SL9aqVSu1atWqILIAV8QwDI39dpuS0rJUwdvQzEEx8vOhQAcAAABQ8uSrSF+wYEG+D3jzzTdfcRjgSny94bAW/xMvd1eTBtTKlqc7958DAAAAKJnyVaT36tUrXwczmUyyWCxXkwdwyKGT6Xruh38kSQ93rKnKqTucnAgAAAAArly+Rne3Wq35+qJAR1GyWA09+tUWpWZmq1lUkO5rW9XZkQAAAADgqjg8BRtQXHz8+z6tO3BSvh6umtyniVxdTM6OBAAAAABXxeGB45577rlLrh8/fvwVhwHya8exFL2xeJckadxN9VUl2Edms9nJqQAAAADg6jhcpH/33Xd2j81ms/bv3y83NzfVqFGDIh2FLjPbokfmblaWxapO9cLU99pIZ0cCAAAAgALh8OXumzZtsvvavn27jh07phtuuEGPPPKIwwGmTp2qqlWrysvLSy1atNC6desuuf3p06c1YsQIRUREyNPTU7Vr19ZPP/3k8POi5Jq8ZJd2Hj+jYF8PTerdWCYTl7kDAAAAKB0K5J50f39/TZw4UePGjXNov7lz52r06NGaMGGCNm7cqOjoaHXp0kUnTpzIdfusrCzdeOONOnDggObNm6fY2Fh99NFHqlSpUkG8DJQAa/cl6cOV+yRJL/VupNByzIcOAAAAoPRw+HL3vCQnJys5OdmhfSZPnqwhQ4Zo8ODBkqRp06Zp4cKFmj59usaMGZNj++nTp+vkyZP6448/5O7uLkmqWrXqVWdHyXAmw6xHv94iw5DuiKmsLg0qODsSAAAAABQoh4v0t99+2+6xYRg6duyYZs2apW7duuX7OFlZWdqwYYPGjh1rW+bi4qJOnTppzZo1ue6zYMECtWrVSiNGjND8+fMVGhqqu+66S08++aRcXV1z3SczM1OZmZm2xykpKZLO3UvPQGMly8QFf+vwqbOqHOilsV1r53j/zj/mfUVZxWcAZRntH2UZ7R9lWUlp/47kc7hIf/PNN+0eu7i4KDQ0VIMGDbIruC8nMTFRFotF4eHhdsvDw8O1c+fOXPfZt2+ffvvtN/Xv318//fST9uzZo+HDh8tsNmvChAm57jNp0iRNnDgxx/LFixfLx8cn33nhXNtOmjQv1lUmGbq1Uqp+/21xntsuWbKkCJMBxQ+fAZRltH+UZbR/lGXFvf2np6fne1uHi/T9+/c7ukuBsVqtCgsL04cffihXV1fFxMToyJEjeu211/Is0seOHavRo0fbHqekpCgyMlKdO3eWv79/UUXHVUhMzdTEd/+QZNa9bavpoS61c93ObDZryZIluvHGG223QwBlCZ8BlGW0f5RltH+UZSWl/Z+/ojs/CuyedEeFhITI1dVV8fHxdsvj4+NVoULu9xpHRETI3d3d7tL2evXq6fjx48rKypKHh0eOfTw9PeXpmXNwMXd392L9JuIcwzA0bsFmnUwzq26Fcnq8a125u+V+a8N5vLco6/gMoCyj/aMso/2jLCvu7d+RbA4X6RkZGXrnnXe0bNkynThxQlar1W79xo0b83UcDw8PxcTEaOnSperVq5ekcz3lS5cu1ciRI3Pdp02bNpozZ46sVqtcXM4NTL9r1y5FRETkWqCj5Ptq/SH9uuOEPFxd9GbfJvK8TIEOAAAAACWZw0X6vffeq8WLF+v2229X8+bNr2qO6tGjR2vQoEFq1qyZmjdvrilTpigtLc022vvAgQNVqVIlTZo0SZI0bNgwvfvuu3r44Yf14IMPavfu3XrppZf00EMPXXEGFF9xSel67od/JEmjO9dWvQhuTwAAAABQujlcpP/444/66aef1KZNm6t+8r59+yohIUHjx4/X8ePH1aRJEy1atMg2mFxcXJytx1ySIiMj9csvv+iRRx5R48aNValSJT388MN68sknrzoLiheL1dDorzYrLcui5lXLa0i76s6OBAAAAACFzuEivVKlSipXrlyBBRg5cmSel7cvX748x7JWrVrpzz//LLDnR/H04cp9Wn/wlHw9XPVGn2i5ulz5FRsAAAAAUFK4XH4Te2+88YaefPJJHTx4sDDyAPr7aLImL4mVJE24uYEiyzNVHgAAAICyweGe9GbNmikjI0PVq1eXj49PjlHqTp48WWDhUPZkmC0aPXeLzBZDN9YP1x0xlZ0dCQAAAACKjMNF+p133qkjR47opZdeUnh4+FUNHAdc7I3FsYqNP6MQPw9N6t2I9gUAAACgTHG4SP/jjz+0Zs0aRUdHF0YelGF/7kvSx6v2S5Je7t1YIX4557cHAAAAgNLM4XvS69atq7NnzxZGFpRhKRlmPfrVFhmG1LdZpDrVD3d2JAAAAAAocg4X6S+//LIeffRRLV++XElJSUpJSbH7Aq7ExAX/6Mjps4os761xPes7Ow4AAAAAOIXDl7t37dpVknTDDTfYLTcMQyaTSRaLpWCSocxYtP2Yvtl4WCaTNLlPE/l5OtwsAQAAAKBUcLgaWrZsWWHkQBl14kyGxn67TZL0QIcaurZqeScnAgAAAADncbhI79ChQ2HkQBlkGIbGfLNNp9LNqhfhr0c61XZ2JAAAAABwKoeL9JUrV15yffv27a84DMqWL/86pN92npCHq4um9G0iDzeHh0gAAAAAgFLF4SL9uuuuy7HswrmsuScd+XEwKU3P//iPJOnxLnVUp0I5JycCAAAAAOdzuOvy1KlTdl8nTpzQokWLdO2112rx4sWFkRGlTLbFqkfmblZ6lkUtqpXXvW2rOTsSAAAAABQLDvekBwQE5Fh24403ysPDQ6NHj9aGDRsKJBhKrw9W7tPGuNPy83TTG32i5eJiuvxOAAAAAFAGFNhNwOHh4YqNjS2ow6GU2n4kWW8u2SVJevbmBqoc5OPkRAAAAABQfDjck75161a7x4Zh6NixY3r55ZfVpEmTgsqFUijDbNEjczcr22qoS4Nw3XZNJWdHAgAAAIBixeEivUmTJjKZTDIMw255y5YtNX369AILhtLntV9itftEqkL8PPXSrY3sBhwEAAAAAFxBkb5//367xy4uLgoNDZWXl1eBhULp88eeRH2y6lzbefX2Rgr283RyIgAAAAAofhwu0qOiogojB0qx5LNmPfb1FknSnc2rqGPdcCcnAgAAAIDiKd8Dx/3222+qX7++UlJScqxLTk5WgwYN9PvvvxdoOJQOExf8raPJGYoK9tEzPeo5Ow4AAAAAFFv5LtKnTJmiIUOGyN/fP8e6gIAADR06VJMnTy7QcCj5ftp2TN9uOiIXkzS5T7R8PR2+eAMAAAAAyox8F+lbtmxR165d81zfuXNn5kiHnRMpGXrqu22SpGHX1VBMVHknJwIAAACA4i3fRXp8fLzc3d3zXO/m5qaEhIQCCYWSzzAMPfHNVp1ON6tBRX89fENtZ0cCAAAAgGIv30V6pUqVtH379jzXb926VREREQUSCiXf52vjtDw2QR5uLnqzbxN5uOW7qQEAAABAmZXvyql79+4aN26cMjIycqw7e/asJkyYoJtuuqlAw6Fk2p+YphcX7pAkPdGljmqHl3NyIgAAAAAoGfI9itczzzyjb7/9VrVr19bIkSNVp04dSdLOnTs1depUWSwWPf3004UWFCVDtsWq0V9t1lmzRa2qB+t/bao5OxIAAAAAlBj5LtLDw8P1xx9/aNiwYRo7dqwMw5AkmUwmdenSRVOnTlV4OPNfl3XvL9+rTXGnVc7TTa/3iZaLi8nZkQAAAACgxHBoPqyoqCj99NNPOnXqlPbs2SPDMFSrVi0FBQUVVj6UINsOJ+utpbslSRNvaaBKgd5OTgQAAAAAJcsVTVodFBSka6+9tqCzoATLMFs0au4mZVsNdW9UQbc2reTsSAAAAABQ4jDkNgrEK4t2am9CmkLLeerFXo1kMnGZOwAAAAA4iiIdV231nkTNWH1AkvTq7Y0V5Ovh3EAAAAAAUEJRpOOqJJ8167Gvt0iS+reoouvrhDk5EQAAAACUXBTpuCoT5m/XseQMVQ320dM96jk7DgAAAACUaBTpuGI/bj2q7zcflYtJmty3iXw8rmgcQgAAAADAvyjScUXiUzL09HfbJUkjrq+pa6owDR8AAAAAXC2KdDjMMAw9Pm+rks+a1ahSgB66oZazIwEAAABAqUCRDofN/vOgVu5KkKebi97sGy13V5oRAAAAABQEqis4ZF9Cql78aYck6cmudVUzrJyTEwEAAABA6UGRjnzLtlj1yFdblGG2qk3NYN3TuqqzIwEAAABAqUKRjnybumyvthw6rXJebnrt9mi5uJicHQkAAAAAShWKdOTLlkOn9fZvuyVJL/RqqIqB3k5OBAAAAAClD0U6LutslkWPfLVZFquhHo0jdHN0RWdHAgAAAIBSiSIdl/XKop3al5CmsHKeerFXQ5lMXOYOAAAAAIWBIh2X9PvuBM3844Ak6bU7ohXo4+HcQAAAAABQilGkI0/J6WY9/vVWSdKAllHqUDvUyYkAAAAAoHSjSEeexs3fruMpGaoe4qux3es6Ow4AAAAAlHoU6cjVgi1HtWDLUbm6mDS5bxP5eLg5OxIAAAAAlHoU6cjheHKGnvlumyRp5PU11SQy0LmBAAAAAKCMoEiHHavV0OPztiglI1uNKwdoZMeazo4EAAAAAGUGRTrszPrzoH7fnShPNxdN7tNE7q40EQAAAAAoKlRgsNlzIlWTft4hSXqqez3VDPNzciIAAAAAKFso0iFJMlusGv3VZmWYrWpXK0QDWkY5OxIAAAAAlDkU6ZAkvfvbHm09nKwAb3e9dnu0XFxMzo4EAAAAAGVOsSjSp06dqqpVq8rLy0stWrTQunXr8tx25syZMplMdl9eXl5FmLb02XzotN5dtkeS9HyvhqoQwPkEAAAAAGdwepE+d+5cjR49WhMmTNDGjRsVHR2tLl266MSJE3nu4+/vr2PHjtm+Dh48WISJS5ezWRaNnrtZFquhntEVdXN0RWdHAgAAAIAyy+lF+uTJkzVkyBANHjxY9evX17Rp0+Tj46Pp06fnuY/JZFKFChVsX+Hh4UWYuHSZ9PMO7UtMUwV/Lz1/SwNnxwEAAACAMs3NmU+elZWlDRs2aOzYsbZlLi4u6tSpk9asWZPnfqmpqYqKipLVatU111yjl156SQ0a5F5gZmZmKjMz0/Y4JSVFkmQ2m2U2mwvolZRMv+9O1Gdrzl2FMOnWBvJ1N5Xoc3I+e0l+DcDV4DOAsoz2j7KM9o+yrKS0f0fyObVIT0xMlMViydETHh4erp07d+a6T506dTR9+nQ1btxYycnJev3119W6dWv9/fffqly5co7tJ02apIkTJ+ZYvnjxYvn4+BTMCymB0szSy1tcJZnUvoJVKbvW6qddzk5VMJYsWeLsCIBT8RlAWUb7R1lG+0dZVtzbf3p6er63dWqRfiVatWqlVq1a2R63bt1a9erV0wcffKDnn38+x/Zjx47V6NGjbY9TUlIUGRmpzp07y9/fv0gyFzeGYWjUV1uVYo5X9RAfvTuklbw9XJ0d66qZzWYtWbJEN954o9zd3Z0dByhyfAZQltH+UZbR/lGWlZT2f/6K7vxwapEeEhIiV1dXxcfH2y2Pj49XhQoV8nUMd3d3NW3aVHv27Ml1vaenpzw9PXPdrzi/iYVp/uYj+ml7vFxdTHqzb1P5+5au0dzL8nsLSHwGULbR/lGW0f5RlhX39u9INqcOHOfh4aGYmBgtXbrUtsxqtWrp0qV2veWXYrFYtG3bNkVERBRWzFLl6OmzGvf9dknSQx1rKToy0LmBAAAAAAA2Tr/cffTo0Ro0aJCaNWum5s2ba8qUKUpLS9PgwYMlSQMHDlSlSpU0adIkSdJzzz2nli1bqmbNmjp9+rRee+01HTx4UPfdd58zX0aJYLUaenzeFqVkZCs6MlAjrq/h7EgAAAAAgAs4vUjv27evEhISNH78eB0/flxNmjTRokWLbIPJxcXFycXlvw7/U6dOaciQITp+/LiCgoIUExOjP/74Q/Xr13fWSygxPl1zQKv3JMnL3UVv9omWm6vTZ+ADAAAAAFzA6UW6JI0cOVIjR47Mdd3y5cvtHr/55pt68803iyBV6bLnxBm9/PO5EfOf7l5P1UP9nJwIAAAAAHAxulLLALPFqkfmblFmtlXta4fq7pZRzo4EAAAAAMgFRXoZ8M7S3dp2JFkB3u567fbGMplMzo4EAAAAAMgFRXoptzHulN5ddm56uhdvbahw/9I13RoAAAAAlCYU6aVYela2Rs/dLKsh9WpSUTc1rujsSAAAAACAS6BIL8VeXLhDB5LSFRHgpYm3NHR2HAAAAADAZVCkl1LLYk/o87VxkqTX74hWgLe7kxMBAAAAAC6HIr0UOpWWpSfmbZUkDW5TVW1qhjg5EQAAAAAgPyjSSxnDMPT099uUcCZTNcP89GTXus6OBAAAAADIJ4r0Uub7zUf007bjcnMx6c0+TeTl7ursSAAAAACAfKJIL0WOnD6r8d//LUl6+IZaalQ5wMmJAAAAAACOoEgvJaxWQ499tUVnMrPVtEqghl1Xw9mRAAAAAAAOokgvJWb8cUBr9iXJ291Vb/ZpIjdX3loAAAAAKGmo5EqBXfFn9MqinZKkp3vUU9UQXycnAgAAAABcCYr0Ei4r26pH5m5WVrZV19UJVf8WVZwdCQAAAABwhSjSS7i3lu7S30dTFOTjrldvayyTyeTsSAAAAACAK0SRXoJtOHhS7y/fK0l66dZGCvP3cnIiAAAAAMDVoEgvodIyszX6qy2yGlLvppXUrVGEsyMBAAAAAK4SRXoJ9cLCHTqYlK6KAV569pYGzo4DAAAAACgAFOkl0G874/XFujhJ0ut9ouXv5e7kRAAAAACAgkCRXsIkpWbqiXnbJEn3tq2m1jVCnJwIAAAAAFBQKNJLEMMw9PR325WYmqlaYX56vEsdZ0cCAAAAABQgivQS5NuNR7To7+NydzXpzb5N5OXu6uxIAAAAAIACRJFeQhw+la4JC/6WJI3qVFsNKwU4OREAAAAAoKBRpJcAVquhR7/aotTMbMVEBWlo++rOjgQAAAAAKAQU6SXAJ6v2a+3+k/LxcNXkPtFyc+VtAwAAAIDSiGqvmIs9fkav/RIrSRp3U31FBfs6OREAAAAAoLBQpBdjmdkWjZq7WVkWq26oG6Z+10Y6OxIAAAAAoBBRpBdjU37drR3HUhTk465JtzWSyWRydiQAAAAAQCGiSC+m/jpwUh+s2CtJmtS7kcLKeTk5EQAAAACgsFGkF1NfrIuT1ZBuu6ayujaMcHYcAAAAAEARcHN2AOTutduj1SQyUL2aVnJ2FAAAAABAEaFIL6ZcXUwa2Kqqs2MAAAAAAIoQl7sDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMUKQDAAAAAFBMuDk7QFEzDEOSlJKS4uQkKGhms1np6elKSUmRu7u7s+MARY7PAMoy2j/KMto/yrKS0v7P15/n69FLKXNF+pkzZyRJkZGRTk4CAAAAAChLzpw5o4CAgEtuYzLyU8qXIlarVUePHlW5cuVkMpmcHQcFKCUlRZGRkTp06JD8/f2dHQcocnwGUJbR/lGW0f5RlpWU9m8Yhs6cOaOKFSvKxeXSd52XuZ50FxcXVa5c2dkxUIj8/f2L9QcUKGx8BlCW0f5RltH+UZaVhPZ/uR708xg4DgAAAACAYoIiHQAAAACAYoIiHaWGp6enJkyYIE9PT2dHAZyCzwDKMto/yjLaP8qy0tj+y9zAcQAAAAAAFFf0pAMAAAAAUExQpAMAAAAAUExQpAMAAAAAUExQpAMAAAAAUExQpKPEe/bZZ2Uymey+6tat6+xYQKFYuXKlevbsqYoVK8pkMun777+3W28YhsaPH6+IiAh5e3urU6dO2r17t3PCAgXscu3/nnvuyfHzoGvXrs4JCxSwSZMm6dprr1W5cuUUFhamXr16KTY21m6bjIwMjRgxQsHBwfLz89Ntt92m+Ph4JyUGCk5+2v91112X42fAAw884KTEV4ciHaVCgwYNdOzYMdvXqlWrnB0JKBRpaWmKjo7W1KlTc13/6quv6u2339a0adO0du1a+fr6qkuXLsrIyCjipEDBu1z7l6SuXbva/Tz44osvijAhUHhWrFihESNG6M8//9SSJUtkNpvVuXNnpaWl2bZ55JFH9MMPP+jrr7/WihUrdPToUfXu3duJqYGCkZ/2L0lDhgyx+xnw6quvOinx1XFzdgCgILi5ualChQrOjgEUum7duqlbt265rjMMQ1OmTNEzzzyjW265RZL02WefKTw8XN9//7369etXlFGBAnep9n+ep6cnPw9QKi1atMju8cyZMxUWFqYNGzaoffv2Sk5O1ieffKI5c+aoY8eOkqQZM2aoXr16+vPPP9WyZUtnxAYKxOXa/3k+Pj6l4mcAPekoFXbv3q2KFSuqevXq6t+/v+Li4pwdCShy+/fv1/Hjx9WpUyfbsoCAALVo0UJr1qxxYjKg6CxfvlxhYWGqU6eOhg0bpqSkJGdHAgpFcnKyJKl8+fKSpA0bNshsNtv9DKhbt66qVKnCzwCUOhe3//M+//xzhYSEqGHDhho7dqzS09OdEe+q0ZOOEq9FixaaOXOm6tSpo2PHjmnixIlq166dtm/frnLlyjk7HlBkjh8/LkkKDw+3Wx4eHm5bB5RmXbt2Ve/evVWtWjXt3btXTz31lLp166Y1a9bI1dXV2fGAAmO1WjVq1Ci1adNGDRs2lHTuZ4CHh4cCAwPttuVnAEqb3Nq/JN11112KiopSxYoVtXXrVj355JOKjY3Vt99+68S0V4YiHSXehZc+Nm7cWC1atFBUVJS++uor3XvvvU5MBgAoShfe0tGoUSM1btxYNWrU0PLly3XDDTc4MRlQsEaMGKHt27czBg/KpLza//3332/7vlGjRoqIiNANN9ygvXv3qkaNGkUd86pwuTtKncDAQNWuXVt79uxxdhSgSJ2/B+vikXzj4+NLxf1ZgKOqV6+ukJAQfh6gVBk5cqR+/PFHLVu2TJUrV7Ytr1ChgrKysnT69Gm77fkZgNIkr/afmxYtWkhSifwZQJGOUic1NVV79+5VRESEs6MARapatWqqUKGCli5daluWkpKitWvXqlWrVk5MBjjH4cOHlZSUxM8DlAqGYWjkyJH67rvv9Ntvv6latWp262NiYuTu7m73MyA2NlZxcXH8DECJd7n2n5vNmzdLUon8GcDl7ijxHnvsMfXs2VNRUVE6evSoJkyYIFdXV915553OjgYUuNTUVLu/CO/fv1+bN29W+fLlVaVKFY0aNUovvPCCatWqpWrVqmncuHGqWLGievXq5bzQQAG5VPsvX768Jk6cqNtuu00VKlTQ3r179cQTT6hmzZrq0qWLE1MDBWPEiBGaM2eO5s+fr3LlytnuMw8ICJC3t7cCAgJ07733avTo0Spfvrz8/f314IMPqlWrVozsjhLvcu1/7969mjNnjrp3767g4GBt3bpVjzzyiNq3b6/GjRs7Of0VMIASrm/fvkZERITh4eFhVKpUyejbt6+xZ88eZ8cCCsWyZcsMSTm+Bg0aZBiGYVitVmPcuHFGeHi44enpadxwww1GbGysc0MDBeRS7T89Pd3o3LmzERoaari7uxtRUVHGkCFDjOPHjzs7NlAgcmv7kowZM2bYtjl79qwxfPhwIygoyPDx8TFuvfVW49ixY84LDRSQy7X/uLg4o3379kb58uUNT09Po2bNmsbjjz9uJCcnOzf4FTIZhmEU5R8FAAAAAABA7rgnHQAAAACAYoIiHQAAAACAYoIiHQAAAACAYoIiHQAAAACAYoIiHQAAAACAYoIiHQAAAACAYoIiHQAAAACAYoIiHQAAAACAYoIiHQCAInDgwAGZTCZt3rzZ2VFsdu7cqZYtW8rLy0tNmjRxdhwAACCKdABAGXHPPffIZDLp5Zdftlv+/fffy2QyOSmVc02YMEG+vr6KjY3V0qVL89zu+PHjevDBB1W9enV5enoqMjJSPXv2vOQ+ZdE999yjXr16OTsGAKCEo0gHAJQZXl5eeuWVV3Tq1ClnRykwWVlZV7zv3r171bZtW0VFRSk4ODjXbQ4cOKCYmBj99ttveu2117Rt2zYtWrRI119/vUaMGHHFzw0AAHJHkQ4AKDM6deqkChUqaNKkSXlu8+yzz+a49HvKlCmqWrWq7fH5HtOXXnpJ4eHhCgwM1HPPPafs7Gw9/vjjKl++vCpXrqwZM2bkOP7OnTvVunVreXl5qWHDhlqxYoXd+u3bt6tbt27y8/NTeHi4BgwYoMTERNv66667TiNHjtSoUaMUEhKiLl265Po6rFarnnvuOVWuXFmenp5q0qSJFi1aZFtvMpm0YcMGPffcczKZTHr22WdzPc7w4cNlMpm0bt063Xbbbapdu7YaNGig0aNH688//7RtFxcXp1tuuUV+fn7y9/dXnz59FB8fn+O8Tp8+XVWqVJGfn5+GDx8ui8WiV199VRUqVFBYWJhefPFFu+c3mUx6//331a1bN3l7e6t69eqaN2+e3Tbbtm1Tx44d5e3treDgYN1///1KTU3N8X69/vrrioiIUHBwsEaMGCGz2WzbJjMzU4899pgqVaokX19ftWjRQsuXL7etnzlzpgIDA/XLL7+oXr168vPzU9euXXXs2DHb6/v00081f/58mUwmmUwmLV++XFlZWRo5cqQiIiLk5eWlqKioS7Y/AAAo0gEAZYarq6teeuklvfPOOzp8+PBVHeu3337T0aNHtXLlSk2ePFkTJkzQTTfdpKCgIK1du1YPPPCAhg4dmuN5Hn/8cT366KPatGmTWrVqpZ49eyopKUmSdPr0aXXs2FFNmzbV+vXrtWjRIsXHx6tPnz52x/j000/l4eGh1atXa9q0abnme+utt/TGG2/o9ddf19atW9WlSxfdfPPN2r17tyTp2LFjatCggR599FEdO3ZMjz32WI5jnDx5UosWLdKIESPk6+ubY31gYKCkc38QuOWWW3Ty5EmtWLFCS5Ys0b59+9S3b1+77ffu3auff/5ZixYt0hdffKFPPvlEPXr00OHDh7VixQq98soreuaZZ7R27Vq7/caNG6fbbrtNW7ZsUf/+/dWvXz/t2LFDkpSWlqYuXbooKChIf/31l77++mv9+uuvGjlypN0xli1bpr1792rZsmX69NNPNXPmTM2cOdO2fuTIkVqzZo2+/PJLbd26VXfccYe6du1qO1+SlJ6ertdff12zZs3SypUrFRcXZztvjz32mPr06WMr3I8dO6bWrVvr7bff1oIFC/TVV18pNjZWn3/+ud0ffAAAyMEAAKAMGDRokHHLLbcYhmEYLVu2NP73v/8ZhmEY3333nXHhj8MJEyYY0dHRdvu++eabRlRUlN2xoqKiDIvFYltWp04do127drbH2dnZhq+vr/HFF18YhmEY+/fvNyQZL7/8sm0bs9lsVK5c2XjllVcMwzCM559/3ujcubPdcx86dMiQZMTGxhqGYRgdOnQwmjZtetnXW7FiRePFF1+0W3bttdcaw4cPtz2Ojo42JkyYkOcx1q5da0gyvv3220s+1+LFiw1XV1cjLi7Otuzvv/82JBnr1q0zDOPcefXx8TFSUlJs23Tp0sWoWrVqjvM4adIk22NJxgMPPGD3fC1atDCGDRtmGIZhfPjhh0ZQUJCRmppqW79w4ULDxcXFOH78uGEY/71f2dnZtm3uuOMOo2/fvoZhGMbBgwcNV1dX48iRI3bPc8MNNxhjx441DMMwZsyYYUgy9uzZY1s/depUIzw83Pb4wjZ23oMPPmh07NjRsFqteZ4/AAAuRE86AKDMeeWVV/Tpp5/aemOvRIMGDeTi8t+P0fDwcDVq1Mj22NXVVcHBwTpx4oTdfq1atbJ97+bmpmbNmtlybNmyRcuWLZOfn5/tq27dupLO9UKfFxMTc8lsKSkpOnr0qNq0aWO3vE2bNg69ZsMw8rXdjh07FBkZqcjISNuy+vXrKzAw0O75qlatqnLlytkeh4eHq379+jnO46XO2fnH54+7Y8cORUdH2/X0t2nTRlarVbGxsbZlDRo0kKurq+1xRESE7Xm2bdsmi8Wi2rVr2537FStW2J13Hx8f1ahRI9dj5OWee+7R5s2bVadOHT300ENavHjxJbcHAMDN2QEAAChq7du3V5cuXTR27Fjdc889dutcXFxyFKcX3rt8nru7u91jk8mU6zKr1ZrvXKmpqerZs6deeeWVHOsiIiJs3+d26XlhqFWrlkwmk3bu3FkgxyuMc3Y1z33+eVJTU+Xq6qoNGzbYFfKS5Ofnd8ljXO4PGddcc43279+vn3/+Wb/++qv69OmjTp065bivHgCA8+hJBwCUSS+//LJ++OEHrVmzxm55aGiojh8/bld8FeTc5hcOtpadna0NGzaoXr16ks4VdH///beqVq2qmjVr2n05Upj7+/urYsWKWr16td3y1atXq379+vk+Tvny5dWlSxdNnTpVaWlpOdafPn1aklSvXj0dOnRIhw4dsq37559/dPr0aYeeLy8XnrPzj8+fs3r16mnLli12+VavXi0XFxfVqVMnX8dv2rSpLBaLTpw4keO8V6hQId85PTw8ZLFYciz39/dX37599dFHH2nu3Ln65ptvdPLkyXwfFwBQtlCkAwDKpEaNGql///56++237ZZfd911SkhI0Kuvvqq9e/dq6tSp+vnnnwvseadOnarvvvtOO3fu1IgRI3Tq1Cn973//kySNGDFCJ0+e1J133qm//vpLe/fu1S+//KLBgwfnWvxdyuOPP65XXnlFc+fOVWxsrMaMGaPNmzfr4YcfdjivxWJR8+bN9c0332j37t3asWOH3n77bdtl6J06dbKdz40bN2rdunUaOHCgOnTooGbNmjn0fLn5+uuvNX36dO3atUsTJkzQunXrbAPD9e/fX15eXho0aJC2b9+uZcuW6cEHH9SAAQMUHh6er+PXrl1b/fv318CBA/Xtt99q//79WrdunSZNmqSFCxfmO2fVqlW1detWxcbGKjExUWazWZMnT9YXX3yhnTt3ateuXfr6669VoUIF26B7AABcjCIdAFBmPffcczkura5Xr57ee+89TZ06VdHR0Vq3bl2uI59fqZdfflkvv/yyoqOjtWrVKi1YsEAhISGSZOv9tlgs6ty5sxo1aqRRo0YpMDDQ7r7t/HjooYf0//buV1WxKIoD8LIKBoPVcEBOUZNWQdR+gtnmC3iewGoWjIJFTaJBNBhNgs/gE/gKM2Fg2sC13Dlwv+8B1t6w02+v/Wc2m0We59FqteJyucTpdIpGo/FRnSRJ4vl8Rr/fjzzPo9lsxmg0itvtFqvVKiL+HPs+Ho9RrVaj1+vFcDiMJEliv99/NNa/zOfz2O120W63Y7PZxHa7/duhL5fLcb1e4/1+R7fbjfF4HIPBIJbL5UdjrNfrmEwmked5pGkaWZbF4/GIer3+5RrT6TTSNI1OpxO1Wi3u93tUKpVYLBbR6XSi2+3G6/WK8/n88XoC8HOUfn31VRgAgG9WKpXicDhElmX/eyoA8C1s4wIAAEBBCOkAAABQEL5gAwAKy608AH4anXQAAAAoCCEdAAAACkJIBwAAgIIQ0gEAAKAghHQAAAAoCCEdAAAACkJIBwAAgIIQ0gEAAKAgfgOVyMVx0zKneQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1200x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### START CODE ###\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(num_components, variance)\n",
        "plt.title(\"PCA Explained Variance for Imbalanced 012\")\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.grid(True)\n",
        "### END CODE ###\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFJY7g36Egs6"
      },
      "source": [
        "# Training the model for 2-Class Balanced Split Diabetes Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "cDohSZktEgs6"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/AML_Final_Project/Dataset/train_binary_split.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/AML_Final_Project/Dataset/test_binary_split.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "NYeR9JnqEgs6",
        "outputId": "fd48006b-0c16-406d-b101-4e9a2f079601"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b77ccce9-2ebd-49c1-9566-7e8492f75646\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BMI</th>\n",
              "      <th>GenHlth</th>\n",
              "      <th>MentHlth</th>\n",
              "      <th>PhysHlth</th>\n",
              "      <th>DiffWalk</th>\n",
              "      <th>Age</th>\n",
              "      <th>Education</th>\n",
              "      <th>Income</th>\n",
              "      <th>HighBP_0</th>\n",
              "      <th>HighBP_1</th>\n",
              "      <th>...</th>\n",
              "      <th>Veggies_1</th>\n",
              "      <th>HvyAlcoholConsump_0</th>\n",
              "      <th>HvyAlcoholConsump_1</th>\n",
              "      <th>AnyHealthcare_0</th>\n",
              "      <th>AnyHealthcare_1</th>\n",
              "      <th>NoDocbcCost_0</th>\n",
              "      <th>NoDocbcCost_1</th>\n",
              "      <th>Sex_0</th>\n",
              "      <th>Sex_1</th>\n",
              "      <th>Diabetes_binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.119897</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.822423</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.706673</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.020609</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.723136</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 35 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b77ccce9-2ebd-49c1-9566-7e8492f75646')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b77ccce9-2ebd-49c1-9566-7e8492f75646 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b77ccce9-2ebd-49c1-9566-7e8492f75646');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5e53db26-f43e-4967-af11-0f599fb7b3c2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5e53db26-f43e-4967-af11-0f599fb7b3c2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5e53db26-f43e-4967-af11-0f599fb7b3c2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        BMI  GenHlth  MentHlth  PhysHlth  DiffWalk       Age  Education  \\\n",
              "0 -0.119897     0.25       0.0  0.000000       0.0  0.750000        1.0   \n",
              "1 -0.822423     0.50       0.5  0.200000       0.0  0.500000        0.8   \n",
              "2  1.706673     0.50       0.0  0.333333       1.0  0.833333        0.8   \n",
              "3  0.020609     0.50       0.0  0.033333       0.0  0.750000        0.8   \n",
              "4  0.723136     0.50       0.0  0.000000       0.0  0.416667        0.6   \n",
              "\n",
              "     Income  HighBP_0  HighBP_1  ...  Veggies_1  HvyAlcoholConsump_0  \\\n",
              "0  1.000000       0.0       1.0  ...        1.0                  1.0   \n",
              "1  0.000000       1.0       0.0  ...        1.0                  1.0   \n",
              "2  0.428571       0.0       1.0  ...        1.0                  1.0   \n",
              "3  0.571429       0.0       1.0  ...        1.0                  1.0   \n",
              "4  0.571429       0.0       1.0  ...        1.0                  1.0   \n",
              "\n",
              "   HvyAlcoholConsump_1  AnyHealthcare_0  AnyHealthcare_1  NoDocbcCost_0  \\\n",
              "0                  0.0              0.0              1.0            1.0   \n",
              "1                  0.0              0.0              1.0            1.0   \n",
              "2                  0.0              0.0              1.0            1.0   \n",
              "3                  0.0              0.0              1.0            1.0   \n",
              "4                  0.0              0.0              1.0            1.0   \n",
              "\n",
              "   NoDocbcCost_1  Sex_0  Sex_1  Diabetes_binary  \n",
              "0            0.0    0.0    1.0              1.0  \n",
              "1            0.0    1.0    0.0              0.0  \n",
              "2            0.0    1.0    0.0              1.0  \n",
              "3            0.0    1.0    0.0              1.0  \n",
              "4            0.0    0.0    1.0              0.0  \n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1Q7arfmoEgs6"
      },
      "outputs": [],
      "source": [
        "X_train = train_data.drop(['Diabetes_binary'], axis=1)\n",
        "y_train = train_data['Diabetes_binary']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XEp0sFI0Egs7"
      },
      "outputs": [],
      "source": [
        "X_test = test_data.drop(['Diabetes_binary'], axis=1)\n",
        "y_test = test_data['Diabetes_binary']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n2QU_eCEgs7"
      },
      "outputs": [],
      "source": [
        "mlp_classifer = MLPClassifier()\n",
        "mlp_param_grid ={\"hidden_layer_sizes\": [(64, 64), (32, 32)],\n",
        "                \"activation\": ['relu', 'tanh'],\n",
        "                \"alpha\" : [0.01, 0.001],\n",
        "                 \"solver\": ['adam'],\n",
        "                \"random_state\": [42],\n",
        "                \"verbose\" : [True],\n",
        "                 \"max_iter\" : [30]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5_fyhqJgEgs7",
        "outputId": "bee1f28d-ae73-49fc-aacb-8a055b2d5b6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Iteration 1, loss = 0.53720015\n",
            "Iteration 2, loss = 0.51019126\n",
            "Iteration 3, loss = 0.50714668\n",
            "Iteration 4, loss = 0.50632728\n",
            "Iteration 5, loss = 0.50441353\n",
            "Iteration 6, loss = 0.50385104\n",
            "Iteration 7, loss = 0.50374988\n",
            "Iteration 8, loss = 0.50249743\n",
            "Iteration 9, loss = 0.50206004\n",
            "Iteration 10, loss = 0.50154064\n",
            "Iteration 11, loss = 0.50173803\n",
            "Iteration 12, loss = 0.50061141\n",
            "Iteration 13, loss = 0.50126242\n",
            "Iteration 14, loss = 0.49976115\n",
            "Iteration 15, loss = 0.49993845\n",
            "Iteration 16, loss = 0.50031951\n",
            "Iteration 17, loss = 0.49929016\n",
            "Iteration 18, loss = 0.49876924\n",
            "Iteration 19, loss = 0.49847352\n",
            "Iteration 20, loss = 0.49842410\n",
            "Iteration 21, loss = 0.49793989\n",
            "Iteration 22, loss = 0.49818343\n",
            "Iteration 23, loss = 0.49815228\n",
            "Iteration 24, loss = 0.49731108\n",
            "Iteration 25, loss = 0.49726024\n",
            "Iteration 26, loss = 0.49661310\n",
            "Iteration 27, loss = 0.49633539\n",
            "Iteration 28, loss = 0.49599943\n",
            "Iteration 29, loss = 0.49582048\n",
            "Iteration 30, loss = 0.49539355\n",
            "[CV 1/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.750 total time=  20.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53905145\n",
            "Iteration 2, loss = 0.51214796\n",
            "Iteration 3, loss = 0.50891989\n",
            "Iteration 4, loss = 0.50748961\n",
            "Iteration 5, loss = 0.50665241\n",
            "Iteration 6, loss = 0.50539776\n",
            "Iteration 7, loss = 0.50595781\n",
            "Iteration 8, loss = 0.50464163\n",
            "Iteration 9, loss = 0.50330295\n",
            "Iteration 10, loss = 0.50289870\n",
            "Iteration 11, loss = 0.50254731\n",
            "Iteration 12, loss = 0.50205177\n",
            "Iteration 13, loss = 0.50233061\n",
            "Iteration 14, loss = 0.50151071\n",
            "Iteration 15, loss = 0.50107613\n",
            "Iteration 16, loss = 0.50130842\n",
            "Iteration 17, loss = 0.50049698\n",
            "Iteration 18, loss = 0.50027149\n",
            "Iteration 19, loss = 0.49987240\n",
            "Iteration 20, loss = 0.49932224\n",
            "Iteration 21, loss = 0.49969853\n",
            "Iteration 22, loss = 0.49964363\n",
            "Iteration 23, loss = 0.49937522\n",
            "Iteration 24, loss = 0.49919737\n",
            "Iteration 25, loss = 0.49806173\n",
            "Iteration 26, loss = 0.49785529\n",
            "Iteration 27, loss = 0.49796294\n",
            "Iteration 28, loss = 0.49727900\n",
            "Iteration 29, loss = 0.49693966\n",
            "Iteration 30, loss = 0.49704910\n",
            "[CV 2/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.756 total time=  21.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53828418\n",
            "Iteration 2, loss = 0.51048805\n",
            "Iteration 3, loss = 0.50689985\n",
            "Iteration 4, loss = 0.50541216\n",
            "Iteration 5, loss = 0.50443664\n",
            "Iteration 6, loss = 0.50291612\n",
            "Iteration 7, loss = 0.50301090\n",
            "Iteration 8, loss = 0.50227399\n",
            "Iteration 9, loss = 0.50184700\n",
            "Iteration 10, loss = 0.50082235\n",
            "Iteration 11, loss = 0.50104604\n",
            "Iteration 12, loss = 0.50021059\n",
            "Iteration 13, loss = 0.49978119\n",
            "Iteration 14, loss = 0.49925864\n",
            "Iteration 15, loss = 0.49881032\n",
            "Iteration 16, loss = 0.49868718\n",
            "Iteration 17, loss = 0.49800505\n",
            "Iteration 18, loss = 0.49880915\n",
            "Iteration 19, loss = 0.49778084\n",
            "Iteration 20, loss = 0.49711572\n",
            "Iteration 21, loss = 0.49757839\n",
            "Iteration 22, loss = 0.49667042\n",
            "Iteration 23, loss = 0.49689059\n",
            "Iteration 24, loss = 0.49690132\n",
            "Iteration 25, loss = 0.49536518\n",
            "Iteration 26, loss = 0.49606763\n",
            "Iteration 27, loss = 0.49543082\n",
            "Iteration 28, loss = 0.49545110\n",
            "Iteration 29, loss = 0.49480456\n",
            "Iteration 30, loss = 0.49467861\n",
            "[CV 3/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.748 total time=  21.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53661934\n",
            "Iteration 2, loss = 0.50880439\n",
            "Iteration 3, loss = 0.50677136\n",
            "Iteration 4, loss = 0.50519386\n",
            "Iteration 5, loss = 0.50404682\n",
            "Iteration 6, loss = 0.50261238\n",
            "Iteration 7, loss = 0.50215629\n",
            "Iteration 8, loss = 0.50157639\n",
            "Iteration 9, loss = 0.50085181\n",
            "Iteration 10, loss = 0.50064274\n",
            "Iteration 11, loss = 0.50007629\n",
            "Iteration 12, loss = 0.49921559\n",
            "Iteration 13, loss = 0.49990823\n",
            "Iteration 14, loss = 0.49909299\n",
            "Iteration 15, loss = 0.49901090\n",
            "Iteration 16, loss = 0.49835738\n",
            "Iteration 17, loss = 0.49872049\n",
            "Iteration 18, loss = 0.49769641\n",
            "Iteration 19, loss = 0.49701437\n",
            "Iteration 20, loss = 0.49713370\n",
            "Iteration 21, loss = 0.49662840\n",
            "Iteration 22, loss = 0.49681507\n",
            "Iteration 23, loss = 0.49615344\n",
            "Iteration 24, loss = 0.49589615\n",
            "Iteration 25, loss = 0.49527371\n",
            "Iteration 26, loss = 0.49505590\n",
            "Iteration 27, loss = 0.49477615\n",
            "Iteration 28, loss = 0.49491187\n",
            "Iteration 29, loss = 0.49452759\n",
            "Iteration 30, loss = 0.49541903\n",
            "[CV 4/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.745 total time=  18.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53868622\n",
            "Iteration 2, loss = 0.51073999\n",
            "Iteration 3, loss = 0.50826786\n",
            "Iteration 4, loss = 0.50641797\n",
            "Iteration 5, loss = 0.50588494\n",
            "Iteration 6, loss = 0.50480679\n",
            "Iteration 7, loss = 0.50349136\n",
            "Iteration 8, loss = 0.50302309\n",
            "Iteration 9, loss = 0.50281077\n",
            "Iteration 10, loss = 0.50251552\n",
            "Iteration 11, loss = 0.50166985\n",
            "Iteration 12, loss = 0.50115337\n",
            "Iteration 13, loss = 0.50232682\n",
            "Iteration 14, loss = 0.50103009\n",
            "Iteration 15, loss = 0.50038548\n",
            "Iteration 16, loss = 0.50064671\n",
            "Iteration 17, loss = 0.50032180\n",
            "Iteration 18, loss = 0.49961422\n",
            "Iteration 19, loss = 0.49857854\n",
            "Iteration 20, loss = 0.49892097\n",
            "Iteration 21, loss = 0.49868482\n",
            "Iteration 22, loss = 0.49789833\n",
            "Iteration 23, loss = 0.49758494\n",
            "Iteration 24, loss = 0.49738227\n",
            "Iteration 25, loss = 0.49671136\n",
            "Iteration 26, loss = 0.49639094\n",
            "Iteration 27, loss = 0.49672016\n",
            "Iteration 28, loss = 0.49636077\n",
            "Iteration 29, loss = 0.49567357\n",
            "Iteration 30, loss = 0.49625098\n",
            "[CV 5/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.754 total time=  17.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.55011772\n",
            "Iteration 2, loss = 0.51328183\n",
            "Iteration 3, loss = 0.50942990\n",
            "Iteration 4, loss = 0.50815943\n",
            "Iteration 5, loss = 0.50682039\n",
            "Iteration 6, loss = 0.50673908\n",
            "Iteration 7, loss = 0.50481451\n",
            "Iteration 8, loss = 0.50428933\n",
            "Iteration 9, loss = 0.50393537\n",
            "Iteration 10, loss = 0.50355007\n",
            "Iteration 11, loss = 0.50304638\n",
            "Iteration 12, loss = 0.50276901\n",
            "Iteration 13, loss = 0.50267340\n",
            "Iteration 14, loss = 0.50246286\n",
            "Iteration 15, loss = 0.50146969\n",
            "Iteration 16, loss = 0.50175400\n",
            "Iteration 17, loss = 0.50118766\n",
            "Iteration 18, loss = 0.50130142\n",
            "Iteration 19, loss = 0.50134494\n",
            "Iteration 20, loss = 0.50056163\n",
            "Iteration 21, loss = 0.50076890\n",
            "Iteration 22, loss = 0.50056967\n",
            "Iteration 23, loss = 0.50050927\n",
            "Iteration 24, loss = 0.49995488\n",
            "Iteration 25, loss = 0.50022494\n",
            "Iteration 26, loss = 0.49953037\n",
            "Iteration 27, loss = 0.49982195\n",
            "Iteration 28, loss = 0.49968892\n",
            "Iteration 29, loss = 0.49927005\n",
            "Iteration 30, loss = 0.49944396\n",
            "[CV 1/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.751 total time=   9.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.55173254\n",
            "Iteration 2, loss = 0.51510147\n",
            "Iteration 3, loss = 0.51061668\n",
            "Iteration 4, loss = 0.50982135\n",
            "Iteration 5, loss = 0.50839563\n",
            "Iteration 6, loss = 0.50710688\n",
            "Iteration 7, loss = 0.50604365\n",
            "Iteration 8, loss = 0.50530244\n",
            "Iteration 9, loss = 0.50552564\n",
            "Iteration 10, loss = 0.50464066\n",
            "Iteration 11, loss = 0.50434201\n",
            "Iteration 12, loss = 0.50373559\n",
            "Iteration 13, loss = 0.50380242\n",
            "Iteration 14, loss = 0.50329504\n",
            "Iteration 15, loss = 0.50261892\n",
            "Iteration 16, loss = 0.50260562\n",
            "Iteration 17, loss = 0.50258651\n",
            "Iteration 18, loss = 0.50269341\n",
            "Iteration 19, loss = 0.50210250\n",
            "Iteration 20, loss = 0.50195613\n",
            "Iteration 21, loss = 0.50242251\n",
            "Iteration 22, loss = 0.50131588\n",
            "Iteration 23, loss = 0.50165357\n",
            "Iteration 24, loss = 0.50122165\n",
            "Iteration 25, loss = 0.50101726\n",
            "Iteration 26, loss = 0.50080024\n",
            "Iteration 27, loss = 0.50084901\n",
            "Iteration 28, loss = 0.50083892\n",
            "Iteration 29, loss = 0.50021815\n",
            "Iteration 30, loss = 0.50134188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.758 total time=   6.3s\n",
            "Iteration 1, loss = 0.55197515\n",
            "Iteration 2, loss = 0.51340260\n",
            "Iteration 3, loss = 0.50848210\n",
            "Iteration 4, loss = 0.50715036\n",
            "Iteration 5, loss = 0.50558089\n",
            "Iteration 6, loss = 0.50518209\n",
            "Iteration 7, loss = 0.50382717\n",
            "Iteration 8, loss = 0.50334677\n",
            "Iteration 9, loss = 0.50387003\n",
            "Iteration 10, loss = 0.50204040\n",
            "Iteration 11, loss = 0.50263671\n",
            "Iteration 12, loss = 0.50125837\n",
            "Iteration 13, loss = 0.50104023\n",
            "Iteration 14, loss = 0.50101777\n",
            "Iteration 15, loss = 0.50057387\n",
            "Iteration 16, loss = 0.50063180\n",
            "Iteration 17, loss = 0.50019214\n",
            "Iteration 18, loss = 0.50051797\n",
            "Iteration 19, loss = 0.49999972\n",
            "Iteration 20, loss = 0.49959164\n",
            "Iteration 21, loss = 0.49980418\n",
            "Iteration 22, loss = 0.49940195\n",
            "Iteration 23, loss = 0.49904001\n",
            "Iteration 24, loss = 0.49911343\n",
            "Iteration 25, loss = 0.49895574\n",
            "Iteration 26, loss = 0.49851329\n",
            "Iteration 27, loss = 0.49870917\n",
            "Iteration 28, loss = 0.49843079\n",
            "Iteration 29, loss = 0.49811622\n",
            "Iteration 30, loss = 0.49911476\n",
            "[CV 3/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.749 total time=   7.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.55046463\n",
            "Iteration 2, loss = 0.51286632\n",
            "Iteration 3, loss = 0.50853825\n",
            "Iteration 4, loss = 0.50597994\n",
            "Iteration 5, loss = 0.50637076\n",
            "Iteration 6, loss = 0.50466631\n",
            "Iteration 7, loss = 0.50378740\n",
            "Iteration 8, loss = 0.50328996\n",
            "Iteration 9, loss = 0.50251549\n",
            "Iteration 10, loss = 0.50271680\n",
            "Iteration 11, loss = 0.50249032\n",
            "Iteration 12, loss = 0.50164287\n",
            "Iteration 13, loss = 0.50155933\n",
            "Iteration 14, loss = 0.50078631\n",
            "Iteration 15, loss = 0.50117699\n",
            "Iteration 16, loss = 0.50062752\n",
            "Iteration 17, loss = 0.50027514\n",
            "Iteration 18, loss = 0.50001836\n",
            "Iteration 19, loss = 0.49948794\n",
            "Iteration 20, loss = 0.49958419\n",
            "Iteration 21, loss = 0.49929212\n",
            "Iteration 22, loss = 0.49885879\n",
            "Iteration 23, loss = 0.49863062\n",
            "Iteration 24, loss = 0.49895462\n",
            "Iteration 25, loss = 0.49896619\n",
            "Iteration 26, loss = 0.49858796\n",
            "Iteration 27, loss = 0.49789203\n",
            "Iteration 28, loss = 0.49829049\n",
            "Iteration 29, loss = 0.49774467\n",
            "Iteration 30, loss = 0.49801756\n",
            "[CV 4/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.744 total time=   9.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.55219369\n",
            "Iteration 2, loss = 0.51374031\n",
            "Iteration 3, loss = 0.50969718\n",
            "Iteration 4, loss = 0.50765259\n",
            "Iteration 5, loss = 0.50744379\n",
            "Iteration 6, loss = 0.50597024\n",
            "Iteration 7, loss = 0.50513094\n",
            "Iteration 8, loss = 0.50485984\n",
            "Iteration 9, loss = 0.50430636\n",
            "Iteration 10, loss = 0.50391592\n",
            "Iteration 11, loss = 0.50357620\n",
            "Iteration 12, loss = 0.50320907\n",
            "Iteration 13, loss = 0.50332485\n",
            "Iteration 14, loss = 0.50245672\n",
            "Iteration 15, loss = 0.50281293\n",
            "Iteration 16, loss = 0.50232011\n",
            "Iteration 17, loss = 0.50226966\n",
            "Iteration 18, loss = 0.50161253\n",
            "Iteration 19, loss = 0.50146079\n",
            "Iteration 20, loss = 0.50147770\n",
            "Iteration 21, loss = 0.50099767\n",
            "Iteration 22, loss = 0.50127402\n",
            "Iteration 23, loss = 0.50155310\n",
            "Iteration 24, loss = 0.50088929\n",
            "Iteration 25, loss = 0.50092411\n",
            "Iteration 26, loss = 0.50063374\n",
            "Iteration 27, loss = 0.50035815\n",
            "Iteration 28, loss = 0.50072127\n",
            "Iteration 29, loss = 0.50053600\n",
            "Iteration 30, loss = 0.50001332\n",
            "[CV 5/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.749 total time=   6.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53487885\n",
            "Iteration 2, loss = 0.50796891\n",
            "Iteration 3, loss = 0.50504502\n",
            "Iteration 4, loss = 0.50415447\n",
            "Iteration 5, loss = 0.50225688\n",
            "Iteration 6, loss = 0.50151110\n",
            "Iteration 7, loss = 0.50153129\n",
            "Iteration 8, loss = 0.50014861\n",
            "Iteration 9, loss = 0.49957783\n",
            "Iteration 10, loss = 0.49913339\n",
            "Iteration 11, loss = 0.49923491\n",
            "Iteration 12, loss = 0.49799988\n",
            "Iteration 13, loss = 0.49842489\n",
            "Iteration 14, loss = 0.49701515\n",
            "Iteration 15, loss = 0.49711675\n",
            "Iteration 16, loss = 0.49732393\n",
            "Iteration 17, loss = 0.49627695\n",
            "Iteration 18, loss = 0.49550680\n",
            "Iteration 19, loss = 0.49535497\n",
            "Iteration 20, loss = 0.49508503\n",
            "Iteration 21, loss = 0.49476141\n",
            "Iteration 22, loss = 0.49485980\n",
            "Iteration 23, loss = 0.49467761\n",
            "Iteration 24, loss = 0.49360398\n",
            "Iteration 25, loss = 0.49353615\n",
            "Iteration 26, loss = 0.49308251\n",
            "Iteration 27, loss = 0.49250269\n",
            "Iteration 28, loss = 0.49210299\n",
            "Iteration 29, loss = 0.49168310\n",
            "Iteration 30, loss = 0.49135834\n",
            "[CV 1/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.749 total time=  21.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53690860\n",
            "Iteration 2, loss = 0.50983330\n",
            "Iteration 3, loss = 0.50670594\n",
            "Iteration 4, loss = 0.50515928\n",
            "Iteration 5, loss = 0.50447482\n",
            "Iteration 6, loss = 0.50305118\n",
            "Iteration 7, loss = 0.50370584\n",
            "Iteration 8, loss = 0.50221542\n",
            "Iteration 9, loss = 0.50089788\n",
            "Iteration 10, loss = 0.50039100\n",
            "Iteration 11, loss = 0.50006565\n",
            "Iteration 12, loss = 0.49937692\n",
            "Iteration 13, loss = 0.49960250\n",
            "Iteration 14, loss = 0.49889796\n",
            "Iteration 15, loss = 0.49831309\n",
            "Iteration 16, loss = 0.49838649\n",
            "Iteration 17, loss = 0.49742139\n",
            "Iteration 18, loss = 0.49714468\n",
            "Iteration 19, loss = 0.49655450\n",
            "Iteration 20, loss = 0.49606915\n",
            "Iteration 21, loss = 0.49588325\n",
            "Iteration 22, loss = 0.49604463\n",
            "Iteration 23, loss = 0.49559374\n",
            "Iteration 24, loss = 0.49519248\n",
            "Iteration 25, loss = 0.49412368\n",
            "Iteration 26, loss = 0.49384952\n",
            "Iteration 27, loss = 0.49391211\n",
            "Iteration 28, loss = 0.49305417\n",
            "Iteration 29, loss = 0.49246695\n",
            "Iteration 30, loss = 0.49248615\n",
            "[CV 2/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.757 total time=  20.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53589344\n",
            "Iteration 2, loss = 0.50816939\n",
            "Iteration 3, loss = 0.50477846\n",
            "Iteration 4, loss = 0.50319731\n",
            "Iteration 5, loss = 0.50232457\n",
            "Iteration 6, loss = 0.50075518\n",
            "Iteration 7, loss = 0.50075280\n",
            "Iteration 8, loss = 0.49982309\n",
            "Iteration 9, loss = 0.49951649\n",
            "Iteration 10, loss = 0.49831321\n",
            "Iteration 11, loss = 0.49845708\n",
            "Iteration 12, loss = 0.49751626\n",
            "Iteration 13, loss = 0.49690102\n",
            "Iteration 14, loss = 0.49623482\n",
            "Iteration 15, loss = 0.49562352\n",
            "Iteration 16, loss = 0.49547560\n",
            "Iteration 17, loss = 0.49469374\n",
            "Iteration 18, loss = 0.49533121\n",
            "Iteration 19, loss = 0.49423224\n",
            "Iteration 20, loss = 0.49341115\n",
            "Iteration 21, loss = 0.49373706\n",
            "Iteration 22, loss = 0.49277339\n",
            "Iteration 23, loss = 0.49280730\n",
            "Iteration 24, loss = 0.49266685\n",
            "Iteration 25, loss = 0.49099260\n",
            "Iteration 26, loss = 0.49144064\n",
            "Iteration 27, loss = 0.49067296\n",
            "Iteration 28, loss = 0.49014208\n",
            "Iteration 29, loss = 0.48981848\n",
            "Iteration 30, loss = 0.48944357\n",
            "[CV 3/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.747 total time=  20.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53421111\n",
            "Iteration 2, loss = 0.50658680\n",
            "Iteration 3, loss = 0.50453089\n",
            "Iteration 4, loss = 0.50288356\n",
            "Iteration 5, loss = 0.50174131\n",
            "Iteration 6, loss = 0.50036656\n",
            "Iteration 7, loss = 0.49983057\n",
            "Iteration 8, loss = 0.49916472\n",
            "Iteration 9, loss = 0.49833257\n",
            "Iteration 10, loss = 0.49804198\n",
            "Iteration 11, loss = 0.49732118\n",
            "Iteration 12, loss = 0.49643504\n",
            "Iteration 13, loss = 0.49697143\n",
            "Iteration 14, loss = 0.49609140\n",
            "Iteration 15, loss = 0.49595988\n",
            "Iteration 16, loss = 0.49506401\n",
            "Iteration 17, loss = 0.49545756\n",
            "Iteration 18, loss = 0.49416976\n",
            "Iteration 19, loss = 0.49348136\n",
            "Iteration 20, loss = 0.49319465\n",
            "Iteration 21, loss = 0.49278264\n",
            "Iteration 22, loss = 0.49255417\n",
            "Iteration 23, loss = 0.49176369\n",
            "Iteration 24, loss = 0.49123920\n",
            "Iteration 25, loss = 0.49038849\n",
            "Iteration 26, loss = 0.48996000\n",
            "Iteration 27, loss = 0.48964956\n",
            "Iteration 28, loss = 0.48964455\n",
            "Iteration 29, loss = 0.48874982\n",
            "Iteration 30, loss = 0.48946927\n",
            "[CV 4/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.744 total time=  17.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53634597\n",
            "Iteration 2, loss = 0.50843882\n",
            "Iteration 3, loss = 0.50593175\n",
            "Iteration 4, loss = 0.50398869\n",
            "Iteration 5, loss = 0.50364457\n",
            "Iteration 6, loss = 0.50254273\n",
            "Iteration 7, loss = 0.50126464\n",
            "Iteration 8, loss = 0.50069479\n",
            "Iteration 9, loss = 0.50047248\n",
            "Iteration 10, loss = 0.50000720\n",
            "Iteration 11, loss = 0.49912792\n",
            "Iteration 12, loss = 0.49846385\n",
            "Iteration 13, loss = 0.49960602\n",
            "Iteration 14, loss = 0.49827647\n",
            "Iteration 15, loss = 0.49753831\n",
            "Iteration 16, loss = 0.49752426\n",
            "Iteration 17, loss = 0.49726967\n",
            "Iteration 18, loss = 0.49639939\n",
            "Iteration 19, loss = 0.49524775\n",
            "Iteration 20, loss = 0.49544055\n",
            "Iteration 21, loss = 0.49525223\n",
            "Iteration 22, loss = 0.49434096\n",
            "Iteration 23, loss = 0.49400335\n",
            "Iteration 24, loss = 0.49364349\n",
            "Iteration 25, loss = 0.49264798\n",
            "Iteration 26, loss = 0.49225379\n",
            "Iteration 27, loss = 0.49252540\n",
            "Iteration 28, loss = 0.49200112\n",
            "Iteration 29, loss = 0.49118292\n",
            "Iteration 30, loss = 0.49126915\n",
            "[CV 5/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.754 total time=  17.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.54848381\n",
            "Iteration 2, loss = 0.51164759\n",
            "Iteration 3, loss = 0.50796366\n",
            "Iteration 4, loss = 0.50653551\n",
            "Iteration 5, loss = 0.50503280\n",
            "Iteration 6, loss = 0.50496523\n",
            "Iteration 7, loss = 0.50320207\n",
            "Iteration 8, loss = 0.50268599\n",
            "Iteration 9, loss = 0.50232724\n",
            "Iteration 10, loss = 0.50194973\n",
            "Iteration 11, loss = 0.50140206\n",
            "Iteration 12, loss = 0.50124434\n",
            "Iteration 13, loss = 0.50102267\n",
            "Iteration 14, loss = 0.50081940\n",
            "Iteration 15, loss = 0.49979613\n",
            "Iteration 16, loss = 0.50005853\n",
            "Iteration 17, loss = 0.49945010\n",
            "Iteration 18, loss = 0.49960321\n",
            "Iteration 19, loss = 0.49959312\n",
            "Iteration 20, loss = 0.49885807\n",
            "Iteration 21, loss = 0.49897972\n",
            "Iteration 22, loss = 0.49866555\n",
            "Iteration 23, loss = 0.49859208\n",
            "Iteration 24, loss = 0.49800526\n",
            "Iteration 25, loss = 0.49816893\n",
            "Iteration 26, loss = 0.49734917\n",
            "Iteration 27, loss = 0.49774968\n",
            "Iteration 28, loss = 0.49754061\n",
            "Iteration 29, loss = 0.49713606\n",
            "Iteration 30, loss = 0.49721340\n",
            "[CV 1/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.752 total time=   9.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.55022222\n",
            "Iteration 2, loss = 0.51354110\n",
            "Iteration 3, loss = 0.50919428\n",
            "Iteration 4, loss = 0.50837567\n",
            "Iteration 5, loss = 0.50695570\n",
            "Iteration 6, loss = 0.50564357\n",
            "Iteration 7, loss = 0.50448770\n",
            "Iteration 8, loss = 0.50380275\n",
            "Iteration 9, loss = 0.50395376\n",
            "Iteration 10, loss = 0.50305520\n",
            "Iteration 11, loss = 0.50271825\n",
            "Iteration 12, loss = 0.50221378\n",
            "Iteration 13, loss = 0.50215582\n",
            "Iteration 14, loss = 0.50169813\n",
            "Iteration 15, loss = 0.50089675\n",
            "Iteration 16, loss = 0.50098202\n",
            "Iteration 17, loss = 0.50095159\n",
            "Iteration 18, loss = 0.50087245\n",
            "Iteration 19, loss = 0.50045856\n",
            "Iteration 20, loss = 0.50042626\n",
            "Iteration 21, loss = 0.50077569\n",
            "Iteration 22, loss = 0.49960261\n",
            "Iteration 23, loss = 0.50003346\n",
            "Iteration 24, loss = 0.49933511\n",
            "Iteration 25, loss = 0.49927279\n",
            "Iteration 26, loss = 0.49912176\n",
            "Iteration 27, loss = 0.49904802\n",
            "Iteration 28, loss = 0.49906853\n",
            "Iteration 29, loss = 0.49835276\n",
            "Iteration 30, loss = 0.49935852\n",
            "[CV 2/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.759 total time=   7.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.55046687\n",
            "Iteration 2, loss = 0.51197635\n",
            "Iteration 3, loss = 0.50692143\n",
            "Iteration 4, loss = 0.50571226\n",
            "Iteration 5, loss = 0.50415898\n",
            "Iteration 6, loss = 0.50365462\n",
            "Iteration 7, loss = 0.50241092\n",
            "Iteration 8, loss = 0.50185343\n",
            "Iteration 9, loss = 0.50237699\n",
            "Iteration 10, loss = 0.50046644\n",
            "Iteration 11, loss = 0.50091767\n",
            "Iteration 12, loss = 0.49954828\n",
            "Iteration 13, loss = 0.49925791\n",
            "Iteration 14, loss = 0.49917746\n",
            "Iteration 15, loss = 0.49880097\n",
            "Iteration 16, loss = 0.49872833\n",
            "Iteration 17, loss = 0.49831624\n",
            "Iteration 18, loss = 0.49861293\n",
            "Iteration 19, loss = 0.49796448\n",
            "Iteration 20, loss = 0.49757785\n",
            "Iteration 21, loss = 0.49759819\n",
            "Iteration 22, loss = 0.49713434\n",
            "Iteration 23, loss = 0.49685087\n",
            "Iteration 24, loss = 0.49685079\n",
            "Iteration 25, loss = 0.49656322\n",
            "Iteration 26, loss = 0.49611583\n",
            "Iteration 27, loss = 0.49606909\n",
            "Iteration 28, loss = 0.49580867\n",
            "Iteration 29, loss = 0.49532115\n",
            "Iteration 30, loss = 0.49637467\n",
            "[CV 3/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.749 total time=   6.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.54904099\n",
            "Iteration 2, loss = 0.51129237\n",
            "Iteration 3, loss = 0.50707802\n",
            "Iteration 4, loss = 0.50444782\n",
            "Iteration 5, loss = 0.50473266\n",
            "Iteration 6, loss = 0.50302660\n",
            "Iteration 7, loss = 0.50226192\n",
            "Iteration 8, loss = 0.50180902\n",
            "Iteration 9, loss = 0.50104611\n",
            "Iteration 10, loss = 0.50121176\n",
            "Iteration 11, loss = 0.50094394\n",
            "Iteration 12, loss = 0.50010177\n",
            "Iteration 13, loss = 0.50013310\n",
            "Iteration 14, loss = 0.49931011\n",
            "Iteration 15, loss = 0.49978018\n",
            "Iteration 16, loss = 0.49913298\n",
            "Iteration 17, loss = 0.49881053\n",
            "Iteration 18, loss = 0.49854512\n",
            "Iteration 19, loss = 0.49803940\n",
            "Iteration 20, loss = 0.49796614\n",
            "Iteration 21, loss = 0.49774320\n",
            "Iteration 22, loss = 0.49717026\n",
            "Iteration 23, loss = 0.49701670\n",
            "Iteration 24, loss = 0.49706543\n",
            "Iteration 25, loss = 0.49702679\n",
            "Iteration 26, loss = 0.49682619\n",
            "Iteration 27, loss = 0.49598039\n",
            "Iteration 28, loss = 0.49629772\n",
            "Iteration 29, loss = 0.49568448\n",
            "Iteration 30, loss = 0.49585021\n",
            "[CV 4/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.743 total time=   9.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.55080034\n",
            "Iteration 2, loss = 0.51244523\n",
            "Iteration 3, loss = 0.50842002\n",
            "Iteration 4, loss = 0.50636796\n",
            "Iteration 5, loss = 0.50621817\n",
            "Iteration 6, loss = 0.50481349\n",
            "Iteration 7, loss = 0.50389474\n",
            "Iteration 8, loss = 0.50356031\n",
            "Iteration 9, loss = 0.50297024\n",
            "Iteration 10, loss = 0.50256274\n",
            "Iteration 11, loss = 0.50215110\n",
            "Iteration 12, loss = 0.50182818\n",
            "Iteration 13, loss = 0.50180608\n",
            "Iteration 14, loss = 0.50093310\n",
            "Iteration 15, loss = 0.50139428\n",
            "Iteration 16, loss = 0.50083411\n",
            "Iteration 17, loss = 0.50072710\n",
            "Iteration 18, loss = 0.50007385\n",
            "Iteration 19, loss = 0.49993700\n",
            "Iteration 20, loss = 0.49987093\n",
            "Iteration 21, loss = 0.49933429\n",
            "Iteration 22, loss = 0.49959536\n",
            "Iteration 23, loss = 0.49984023\n",
            "Iteration 24, loss = 0.49919937\n",
            "Iteration 25, loss = 0.49921151\n",
            "Iteration 26, loss = 0.49895246\n",
            "Iteration 27, loss = 0.49848777\n",
            "Iteration 28, loss = 0.49902803\n",
            "Iteration 29, loss = 0.49862522\n",
            "Iteration 30, loss = 0.49808299\n",
            "[CV 5/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.749 total time=   6.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53074297\n",
            "Iteration 2, loss = 0.51399419\n",
            "Iteration 3, loss = 0.51127225\n",
            "Iteration 4, loss = 0.51038881\n",
            "Iteration 5, loss = 0.50823940\n",
            "Iteration 6, loss = 0.50765060\n",
            "Iteration 7, loss = 0.50762010\n",
            "Iteration 8, loss = 0.50652890\n",
            "Iteration 9, loss = 0.50608310\n",
            "Iteration 10, loss = 0.50577592\n",
            "Iteration 11, loss = 0.50595961\n",
            "Iteration 12, loss = 0.50485807\n",
            "Iteration 13, loss = 0.50555042\n",
            "Iteration 14, loss = 0.50437789\n",
            "Iteration 15, loss = 0.50453636\n",
            "Iteration 16, loss = 0.50485865\n",
            "Iteration 17, loss = 0.50386508\n",
            "Iteration 18, loss = 0.50383203\n",
            "Iteration 19, loss = 0.50362297\n",
            "Iteration 20, loss = 0.50377162\n",
            "Iteration 21, loss = 0.50329754\n",
            "Iteration 22, loss = 0.50366898\n",
            "Iteration 23, loss = 0.50352631\n",
            "Iteration 24, loss = 0.50352499\n",
            "Iteration 25, loss = 0.50318182\n",
            "Iteration 26, loss = 0.50255322\n",
            "Iteration 27, loss = 0.50277404\n",
            "Iteration 28, loss = 0.50264537\n",
            "Iteration 29, loss = 0.50231815\n",
            "Iteration 30, loss = 0.50213260\n",
            "[CV 1/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.753 total time=  34.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53206504\n",
            "Iteration 2, loss = 0.51511107\n",
            "Iteration 3, loss = 0.51234788\n",
            "Iteration 4, loss = 0.51114198\n",
            "Iteration 5, loss = 0.51019384\n",
            "Iteration 6, loss = 0.50915375\n",
            "Iteration 7, loss = 0.50940576\n",
            "Iteration 8, loss = 0.50834689\n",
            "Iteration 9, loss = 0.50708258\n",
            "Iteration 10, loss = 0.50680055\n",
            "Iteration 11, loss = 0.50654034\n",
            "Iteration 12, loss = 0.50597376\n",
            "Iteration 13, loss = 0.50622930\n",
            "Iteration 14, loss = 0.50583528\n",
            "Iteration 15, loss = 0.50558597\n",
            "Iteration 16, loss = 0.50590686\n",
            "Iteration 17, loss = 0.50512955\n",
            "Iteration 18, loss = 0.50511388\n",
            "Iteration 19, loss = 0.50478541\n",
            "Iteration 20, loss = 0.50434570\n",
            "Iteration 21, loss = 0.50440849\n",
            "Iteration 22, loss = 0.50500764\n",
            "Iteration 23, loss = 0.50454836\n",
            "Iteration 24, loss = 0.50474684\n",
            "Iteration 25, loss = 0.50375589\n",
            "Iteration 26, loss = 0.50359889\n",
            "Iteration 27, loss = 0.50381446\n",
            "Iteration 28, loss = 0.50373896\n",
            "Iteration 29, loss = 0.50300250\n",
            "Iteration 30, loss = 0.50351449\n",
            "[CV 2/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.761 total time=  35.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53054045\n",
            "Iteration 2, loss = 0.51297425\n",
            "Iteration 3, loss = 0.51004170\n",
            "Iteration 4, loss = 0.50907285\n",
            "Iteration 5, loss = 0.50789361\n",
            "Iteration 6, loss = 0.50642089\n",
            "Iteration 7, loss = 0.50648640\n",
            "Iteration 8, loss = 0.50581771\n",
            "Iteration 9, loss = 0.50532501\n",
            "Iteration 10, loss = 0.50471723\n",
            "Iteration 11, loss = 0.50476364\n",
            "Iteration 12, loss = 0.50418408\n",
            "Iteration 13, loss = 0.50390420\n",
            "Iteration 14, loss = 0.50347023\n",
            "Iteration 15, loss = 0.50324631\n",
            "Iteration 16, loss = 0.50329161\n",
            "Iteration 17, loss = 0.50280121\n",
            "Iteration 18, loss = 0.50354578\n",
            "Iteration 19, loss = 0.50278406\n",
            "Iteration 20, loss = 0.50201872\n",
            "Iteration 21, loss = 0.50246766\n",
            "Iteration 22, loss = 0.50201966\n",
            "Iteration 23, loss = 0.50206512\n",
            "Iteration 24, loss = 0.50246552\n",
            "Iteration 25, loss = 0.50117611\n",
            "Iteration 26, loss = 0.50186115\n",
            "Iteration 27, loss = 0.50130013\n",
            "Iteration 28, loss = 0.50155159\n",
            "Iteration 29, loss = 0.50098367\n",
            "Iteration 30, loss = 0.50104932\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.751 total time=  34.1s\n",
            "Iteration 1, loss = 0.53060253\n",
            "Iteration 2, loss = 0.51181435\n",
            "Iteration 3, loss = 0.51059126\n",
            "Iteration 4, loss = 0.50916676\n",
            "Iteration 5, loss = 0.50785944\n",
            "Iteration 6, loss = 0.50676549\n",
            "Iteration 7, loss = 0.50638352\n",
            "Iteration 8, loss = 0.50589115\n",
            "Iteration 9, loss = 0.50506765\n",
            "Iteration 10, loss = 0.50483865\n",
            "Iteration 11, loss = 0.50451766\n",
            "Iteration 12, loss = 0.50378501\n",
            "Iteration 13, loss = 0.50440253\n",
            "Iteration 14, loss = 0.50363875\n",
            "Iteration 15, loss = 0.50353282\n",
            "Iteration 16, loss = 0.50315689\n",
            "Iteration 17, loss = 0.50372534\n",
            "Iteration 18, loss = 0.50267050\n",
            "Iteration 19, loss = 0.50242651\n",
            "Iteration 20, loss = 0.50240255\n",
            "Iteration 21, loss = 0.50203536\n",
            "Iteration 22, loss = 0.50217868\n",
            "Iteration 23, loss = 0.50206405\n",
            "Iteration 24, loss = 0.50174456\n",
            "Iteration 25, loss = 0.50120727\n",
            "Iteration 26, loss = 0.50103885\n",
            "Iteration 27, loss = 0.50067090\n",
            "Iteration 28, loss = 0.50109158\n",
            "Iteration 29, loss = 0.50082566\n",
            "Iteration 30, loss = 0.50148687\n",
            "[CV 4/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.746 total time=  35.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53296867\n",
            "Iteration 2, loss = 0.51388471\n",
            "Iteration 3, loss = 0.51216369\n",
            "Iteration 4, loss = 0.51017480\n",
            "Iteration 5, loss = 0.50963865\n",
            "Iteration 6, loss = 0.50859604\n",
            "Iteration 7, loss = 0.50747001\n",
            "Iteration 8, loss = 0.50720578\n",
            "Iteration 9, loss = 0.50681708\n",
            "Iteration 10, loss = 0.50638218\n",
            "Iteration 11, loss = 0.50582739\n",
            "Iteration 12, loss = 0.50532561\n",
            "Iteration 13, loss = 0.50653396\n",
            "Iteration 14, loss = 0.50556185\n",
            "Iteration 15, loss = 0.50471814\n",
            "Iteration 16, loss = 0.50513335\n",
            "Iteration 17, loss = 0.50511488\n",
            "Iteration 18, loss = 0.50448001\n",
            "Iteration 19, loss = 0.50364511\n",
            "Iteration 20, loss = 0.50394610\n",
            "Iteration 21, loss = 0.50415812\n",
            "Iteration 22, loss = 0.50364932\n",
            "Iteration 23, loss = 0.50337835\n",
            "Iteration 24, loss = 0.50335346\n",
            "Iteration 25, loss = 0.50266752\n",
            "Iteration 26, loss = 0.50248619\n",
            "Iteration 27, loss = 0.50285804\n",
            "Iteration 28, loss = 0.50272043\n",
            "Iteration 29, loss = 0.50237948\n",
            "Iteration 30, loss = 0.50258779\n",
            "[CV 5/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.754 total time=  34.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53814836\n",
            "Iteration 2, loss = 0.51326679\n",
            "Iteration 3, loss = 0.51061732\n",
            "Iteration 4, loss = 0.50952254\n",
            "Iteration 5, loss = 0.50856395\n",
            "Iteration 6, loss = 0.50845541\n",
            "Iteration 7, loss = 0.50700194\n",
            "Iteration 8, loss = 0.50637028\n",
            "Iteration 9, loss = 0.50621073\n",
            "Iteration 10, loss = 0.50588668\n",
            "Iteration 11, loss = 0.50538008\n",
            "Iteration 12, loss = 0.50524438\n",
            "Iteration 13, loss = 0.50493742\n",
            "Iteration 14, loss = 0.50482307\n",
            "Iteration 15, loss = 0.50397178\n",
            "Iteration 16, loss = 0.50419412\n",
            "Iteration 17, loss = 0.50374442\n",
            "Iteration 18, loss = 0.50383756\n",
            "Iteration 19, loss = 0.50379649\n",
            "Iteration 20, loss = 0.50336501\n",
            "Iteration 21, loss = 0.50331784\n",
            "Iteration 22, loss = 0.50318872\n",
            "Iteration 23, loss = 0.50299126\n",
            "Iteration 24, loss = 0.50253146\n",
            "Iteration 25, loss = 0.50273944\n",
            "Iteration 26, loss = 0.50209027\n",
            "Iteration 27, loss = 0.50250520\n",
            "Iteration 28, loss = 0.50222368\n",
            "Iteration 29, loss = 0.50217090\n",
            "Iteration 30, loss = 0.50215378\n",
            "[CV 1/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.752 total time=  13.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53989281\n",
            "Iteration 2, loss = 0.51464717\n",
            "Iteration 3, loss = 0.51147102\n",
            "Iteration 4, loss = 0.51119818\n",
            "Iteration 5, loss = 0.51044528\n",
            "Iteration 6, loss = 0.50924751\n",
            "Iteration 7, loss = 0.50832645\n",
            "Iteration 8, loss = 0.50763935\n",
            "Iteration 9, loss = 0.50798642\n",
            "Iteration 10, loss = 0.50720150\n",
            "Iteration 11, loss = 0.50677882\n",
            "Iteration 12, loss = 0.50635317\n",
            "Iteration 13, loss = 0.50624983\n",
            "Iteration 14, loss = 0.50587370\n",
            "Iteration 15, loss = 0.50508772\n",
            "Iteration 16, loss = 0.50529475\n",
            "Iteration 17, loss = 0.50519444\n",
            "Iteration 18, loss = 0.50528792\n",
            "Iteration 19, loss = 0.50476830\n",
            "Iteration 20, loss = 0.50479657\n",
            "Iteration 21, loss = 0.50511771\n",
            "Iteration 22, loss = 0.50417876\n",
            "Iteration 23, loss = 0.50447273\n",
            "Iteration 24, loss = 0.50409488\n",
            "Iteration 25, loss = 0.50391988\n",
            "Iteration 26, loss = 0.50373987\n",
            "Iteration 27, loss = 0.50377967\n",
            "Iteration 28, loss = 0.50371681\n",
            "Iteration 29, loss = 0.50325477\n",
            "Iteration 30, loss = 0.50429514\n",
            "[CV 2/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.757 total time=  13.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.54047403\n",
            "Iteration 2, loss = 0.51359597\n",
            "Iteration 3, loss = 0.50983509\n",
            "Iteration 4, loss = 0.50937547\n",
            "Iteration 5, loss = 0.50797998\n",
            "Iteration 6, loss = 0.50751571\n",
            "Iteration 7, loss = 0.50630186\n",
            "Iteration 8, loss = 0.50578575\n",
            "Iteration 9, loss = 0.50633648\n",
            "Iteration 10, loss = 0.50480527\n",
            "Iteration 11, loss = 0.50503931\n",
            "Iteration 12, loss = 0.50389322\n",
            "Iteration 13, loss = 0.50368211\n",
            "Iteration 14, loss = 0.50351024\n",
            "Iteration 15, loss = 0.50320326\n",
            "Iteration 16, loss = 0.50326533\n",
            "Iteration 17, loss = 0.50274163\n",
            "Iteration 18, loss = 0.50304389\n",
            "Iteration 19, loss = 0.50268522\n",
            "Iteration 20, loss = 0.50241043\n",
            "Iteration 21, loss = 0.50230562\n",
            "Iteration 22, loss = 0.50201718\n",
            "Iteration 23, loss = 0.50171511\n",
            "Iteration 24, loss = 0.50180847\n",
            "Iteration 25, loss = 0.50169750\n",
            "Iteration 26, loss = 0.50137543\n",
            "Iteration 27, loss = 0.50133909\n",
            "Iteration 28, loss = 0.50144781\n",
            "Iteration 29, loss = 0.50097280\n",
            "Iteration 30, loss = 0.50176827\n",
            "[CV 3/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.749 total time=  11.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53926641\n",
            "Iteration 2, loss = 0.51236555\n",
            "Iteration 3, loss = 0.50969883\n",
            "Iteration 4, loss = 0.50783158\n",
            "Iteration 5, loss = 0.50824922\n",
            "Iteration 6, loss = 0.50712069\n",
            "Iteration 7, loss = 0.50640421\n",
            "Iteration 8, loss = 0.50570979\n",
            "Iteration 9, loss = 0.50493165\n",
            "Iteration 10, loss = 0.50509250\n",
            "Iteration 11, loss = 0.50473523\n",
            "Iteration 12, loss = 0.50421035\n",
            "Iteration 13, loss = 0.50400434\n",
            "Iteration 14, loss = 0.50326620\n",
            "Iteration 15, loss = 0.50363098\n",
            "Iteration 16, loss = 0.50341856\n",
            "Iteration 17, loss = 0.50285043\n",
            "Iteration 18, loss = 0.50273601\n",
            "Iteration 19, loss = 0.50231886\n",
            "Iteration 20, loss = 0.50237978\n",
            "Iteration 21, loss = 0.50216841\n",
            "Iteration 22, loss = 0.50192338\n",
            "Iteration 23, loss = 0.50161918\n",
            "Iteration 24, loss = 0.50168608\n",
            "Iteration 25, loss = 0.50172994\n",
            "Iteration 26, loss = 0.50149442\n",
            "Iteration 27, loss = 0.50087105\n",
            "Iteration 28, loss = 0.50136459\n",
            "Iteration 29, loss = 0.50078135\n",
            "Iteration 30, loss = 0.50097406\n",
            "[CV 4/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.747 total time=  14.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.54038819\n",
            "Iteration 2, loss = 0.51410191\n",
            "Iteration 3, loss = 0.51129422\n",
            "Iteration 4, loss = 0.50979267\n",
            "Iteration 5, loss = 0.50964523\n",
            "Iteration 6, loss = 0.50859667\n",
            "Iteration 7, loss = 0.50792146\n",
            "Iteration 8, loss = 0.50749661\n",
            "Iteration 9, loss = 0.50705784\n",
            "Iteration 10, loss = 0.50673376\n",
            "Iteration 11, loss = 0.50635239\n",
            "Iteration 12, loss = 0.50616723\n",
            "Iteration 13, loss = 0.50599206\n",
            "Iteration 14, loss = 0.50521590\n",
            "Iteration 15, loss = 0.50538227\n",
            "Iteration 16, loss = 0.50514349\n",
            "Iteration 17, loss = 0.50495993\n",
            "Iteration 18, loss = 0.50437855\n",
            "Iteration 19, loss = 0.50416962\n",
            "Iteration 20, loss = 0.50409875\n",
            "Iteration 21, loss = 0.50379352\n",
            "Iteration 22, loss = 0.50392221\n",
            "Iteration 23, loss = 0.50415170\n",
            "Iteration 24, loss = 0.50354602\n",
            "Iteration 25, loss = 0.50340402\n",
            "Iteration 26, loss = 0.50346704\n",
            "Iteration 27, loss = 0.50304651\n",
            "Iteration 28, loss = 0.50363215\n",
            "Iteration 29, loss = 0.50302028\n",
            "Iteration 30, loss = 0.50271308\n",
            "[CV 5/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.751 total time=  12.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.52818811\n",
            "Iteration 2, loss = 0.51140939\n",
            "Iteration 3, loss = 0.50867820\n",
            "Iteration 4, loss = 0.50778799\n",
            "Iteration 5, loss = 0.50562875\n",
            "Iteration 6, loss = 0.50503180\n",
            "Iteration 7, loss = 0.50500242\n",
            "Iteration 8, loss = 0.50389376\n",
            "Iteration 9, loss = 0.50343391\n",
            "Iteration 10, loss = 0.50312012\n",
            "Iteration 11, loss = 0.50329674\n",
            "Iteration 12, loss = 0.50217161\n",
            "Iteration 13, loss = 0.50284711\n",
            "Iteration 14, loss = 0.50166491\n",
            "Iteration 15, loss = 0.50178170\n",
            "Iteration 16, loss = 0.50209890\n",
            "Iteration 17, loss = 0.50109348\n",
            "Iteration 18, loss = 0.50102405\n",
            "Iteration 19, loss = 0.50081527\n",
            "Iteration 20, loss = 0.50093115\n",
            "Iteration 21, loss = 0.50038262\n",
            "Iteration 22, loss = 0.50074925\n",
            "Iteration 23, loss = 0.50056510\n",
            "Iteration 24, loss = 0.50052715\n",
            "Iteration 25, loss = 0.50016062\n",
            "Iteration 26, loss = 0.49948850\n",
            "Iteration 27, loss = 0.49961033\n",
            "Iteration 28, loss = 0.49948615\n",
            "Iteration 29, loss = 0.49908625\n",
            "Iteration 30, loss = 0.49885068\n",
            "[CV 1/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.753 total time=  35.8s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.52951107\n",
            "Iteration 2, loss = 0.51253228\n",
            "Iteration 3, loss = 0.50975894\n",
            "Iteration 4, loss = 0.50854294\n",
            "Iteration 5, loss = 0.50758647\n",
            "Iteration 6, loss = 0.50652853\n",
            "Iteration 7, loss = 0.50677952\n",
            "Iteration 8, loss = 0.50569519\n",
            "Iteration 9, loss = 0.50441851\n",
            "Iteration 10, loss = 0.50412134\n",
            "Iteration 11, loss = 0.50384783\n",
            "Iteration 12, loss = 0.50325625\n",
            "Iteration 13, loss = 0.50349427\n",
            "Iteration 14, loss = 0.50307853\n",
            "Iteration 15, loss = 0.50280111\n",
            "Iteration 16, loss = 0.50311151\n",
            "Iteration 17, loss = 0.50229606\n",
            "Iteration 18, loss = 0.50223078\n",
            "Iteration 19, loss = 0.50189975\n",
            "Iteration 20, loss = 0.50142319\n",
            "Iteration 21, loss = 0.50143852\n",
            "Iteration 22, loss = 0.50208248\n",
            "Iteration 23, loss = 0.50152100\n",
            "Iteration 24, loss = 0.50170379\n",
            "Iteration 25, loss = 0.50066800\n",
            "Iteration 26, loss = 0.50050414\n",
            "Iteration 27, loss = 0.50063747\n",
            "Iteration 28, loss = 0.50054887\n",
            "Iteration 29, loss = 0.49975484\n",
            "Iteration 30, loss = 0.50023139\n",
            "[CV 2/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.760 total time=  36.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.52798351\n",
            "Iteration 2, loss = 0.51039431\n",
            "Iteration 3, loss = 0.50744338\n",
            "Iteration 4, loss = 0.50646807\n",
            "Iteration 5, loss = 0.50528041\n",
            "Iteration 6, loss = 0.50379182\n",
            "Iteration 7, loss = 0.50384392\n",
            "Iteration 8, loss = 0.50315824\n",
            "Iteration 9, loss = 0.50264929\n",
            "Iteration 10, loss = 0.50202504\n",
            "Iteration 11, loss = 0.50205189\n",
            "Iteration 12, loss = 0.50145600\n",
            "Iteration 13, loss = 0.50114748\n",
            "Iteration 14, loss = 0.50068008\n",
            "Iteration 15, loss = 0.50042738\n",
            "Iteration 16, loss = 0.50045034\n",
            "Iteration 17, loss = 0.49992063\n",
            "Iteration 18, loss = 0.50059596\n",
            "Iteration 19, loss = 0.49984617\n",
            "Iteration 20, loss = 0.49901745\n",
            "Iteration 21, loss = 0.49940855\n",
            "Iteration 22, loss = 0.49896695\n",
            "Iteration 23, loss = 0.49895330\n",
            "Iteration 24, loss = 0.49930363\n",
            "Iteration 25, loss = 0.49799843\n",
            "Iteration 26, loss = 0.49864345\n",
            "Iteration 27, loss = 0.49801367\n",
            "Iteration 28, loss = 0.49826807\n",
            "Iteration 29, loss = 0.49763098\n",
            "Iteration 30, loss = 0.49763153\n",
            "[CV 3/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.751 total time=  34.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.52805108\n",
            "Iteration 2, loss = 0.50923540\n",
            "Iteration 3, loss = 0.50799948\n",
            "Iteration 4, loss = 0.50655961\n",
            "Iteration 5, loss = 0.50524013\n",
            "Iteration 6, loss = 0.50412426\n",
            "Iteration 7, loss = 0.50372801\n",
            "Iteration 8, loss = 0.50321394\n",
            "Iteration 9, loss = 0.50237137\n",
            "Iteration 10, loss = 0.50212514\n",
            "Iteration 11, loss = 0.50178000\n",
            "Iteration 12, loss = 0.50102247\n",
            "Iteration 13, loss = 0.50160154\n",
            "Iteration 14, loss = 0.50081609\n",
            "Iteration 15, loss = 0.50068508\n",
            "Iteration 16, loss = 0.50027986\n",
            "Iteration 17, loss = 0.50082534\n",
            "Iteration 18, loss = 0.49972126\n",
            "Iteration 19, loss = 0.49943319\n",
            "Iteration 20, loss = 0.49940918\n",
            "Iteration 21, loss = 0.49897604\n",
            "Iteration 22, loss = 0.49905761\n",
            "Iteration 23, loss = 0.49893342\n",
            "Iteration 24, loss = 0.49858510\n",
            "Iteration 25, loss = 0.49797235\n",
            "Iteration 26, loss = 0.49776578\n",
            "Iteration 27, loss = 0.49737769\n",
            "Iteration 28, loss = 0.49768950\n",
            "Iteration 29, loss = 0.49738079\n",
            "Iteration 30, loss = 0.49796718\n",
            "[CV 4/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.747 total time=  41.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53041473\n",
            "Iteration 2, loss = 0.51130236\n",
            "Iteration 3, loss = 0.50957583\n",
            "Iteration 4, loss = 0.50757333\n",
            "Iteration 5, loss = 0.50703184\n",
            "Iteration 6, loss = 0.50597956\n",
            "Iteration 7, loss = 0.50484048\n",
            "Iteration 8, loss = 0.50456227\n",
            "Iteration 9, loss = 0.50416316\n",
            "Iteration 10, loss = 0.50371896\n",
            "Iteration 11, loss = 0.50314863\n",
            "Iteration 12, loss = 0.50263271\n",
            "Iteration 13, loss = 0.50380855\n",
            "Iteration 14, loss = 0.50282920\n",
            "Iteration 15, loss = 0.50196869\n",
            "Iteration 16, loss = 0.50232166\n",
            "Iteration 17, loss = 0.50230243\n",
            "Iteration 18, loss = 0.50164565\n",
            "Iteration 19, loss = 0.50077422\n",
            "Iteration 20, loss = 0.50108734\n",
            "Iteration 21, loss = 0.50123627\n",
            "Iteration 22, loss = 0.50068205\n",
            "Iteration 23, loss = 0.50039766\n",
            "Iteration 24, loss = 0.50033650\n",
            "Iteration 25, loss = 0.49957503\n",
            "Iteration 26, loss = 0.49936064\n",
            "Iteration 27, loss = 0.49971343\n",
            "Iteration 28, loss = 0.49948943\n",
            "Iteration 29, loss = 0.49910864\n",
            "Iteration 30, loss = 0.49926188\n",
            "[CV 5/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.755 total time=  30.9s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53656127\n",
            "Iteration 2, loss = 0.51164768\n",
            "Iteration 3, loss = 0.50899351\n",
            "Iteration 4, loss = 0.50789240\n",
            "Iteration 5, loss = 0.50692395\n",
            "Iteration 6, loss = 0.50680313\n",
            "Iteration 7, loss = 0.50533523\n",
            "Iteration 8, loss = 0.50468072\n",
            "Iteration 9, loss = 0.50450442\n",
            "Iteration 10, loss = 0.50416617\n",
            "Iteration 11, loss = 0.50363606\n",
            "Iteration 12, loss = 0.50348023\n",
            "Iteration 13, loss = 0.50314495\n",
            "Iteration 14, loss = 0.50300714\n",
            "Iteration 15, loss = 0.50212071\n",
            "Iteration 16, loss = 0.50230718\n",
            "Iteration 17, loss = 0.50184142\n",
            "Iteration 18, loss = 0.50190879\n",
            "Iteration 19, loss = 0.50183198\n",
            "Iteration 20, loss = 0.50139194\n",
            "Iteration 21, loss = 0.50130283\n",
            "Iteration 22, loss = 0.50115376\n",
            "Iteration 23, loss = 0.50092941\n",
            "Iteration 24, loss = 0.50043510\n",
            "Iteration 25, loss = 0.50061550\n",
            "Iteration 26, loss = 0.49993870\n",
            "Iteration 27, loss = 0.50033957\n",
            "Iteration 28, loss = 0.50002605\n",
            "Iteration 29, loss = 0.49996806\n",
            "Iteration 30, loss = 0.49990959\n",
            "[CV 1/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.752 total time=  14.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53830679\n",
            "Iteration 2, loss = 0.51303230\n",
            "Iteration 3, loss = 0.50985135\n",
            "Iteration 4, loss = 0.50957388\n",
            "Iteration 5, loss = 0.50881734\n",
            "Iteration 6, loss = 0.50760503\n",
            "Iteration 7, loss = 0.50666984\n",
            "Iteration 8, loss = 0.50596640\n",
            "Iteration 9, loss = 0.50628840\n",
            "Iteration 10, loss = 0.50549440\n",
            "Iteration 11, loss = 0.50505193\n",
            "Iteration 12, loss = 0.50460761\n",
            "Iteration 13, loss = 0.50447947\n",
            "Iteration 14, loss = 0.50409974\n",
            "Iteration 15, loss = 0.50327939\n",
            "Iteration 16, loss = 0.50346916\n",
            "Iteration 17, loss = 0.50333704\n",
            "Iteration 18, loss = 0.50340909\n",
            "Iteration 19, loss = 0.50287888\n",
            "Iteration 20, loss = 0.50287919\n",
            "Iteration 21, loss = 0.50317533\n",
            "Iteration 22, loss = 0.50220838\n",
            "Iteration 23, loss = 0.50248939\n",
            "Iteration 24, loss = 0.50207405\n",
            "Iteration 25, loss = 0.50186684\n",
            "Iteration 26, loss = 0.50164522\n",
            "Iteration 27, loss = 0.50167824\n",
            "Iteration 28, loss = 0.50155001\n",
            "Iteration 29, loss = 0.50107781\n",
            "Iteration 30, loss = 0.50210026\n",
            "[CV 2/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.757 total time=  12.4s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53889061\n",
            "Iteration 2, loss = 0.51198128\n",
            "Iteration 3, loss = 0.50821373\n",
            "Iteration 4, loss = 0.50774894\n",
            "Iteration 5, loss = 0.50634801\n",
            "Iteration 6, loss = 0.50586608\n",
            "Iteration 7, loss = 0.50463038\n",
            "Iteration 8, loss = 0.50410162\n",
            "Iteration 9, loss = 0.50462684\n",
            "Iteration 10, loss = 0.50308712\n",
            "Iteration 11, loss = 0.50329579\n",
            "Iteration 12, loss = 0.50212584\n",
            "Iteration 13, loss = 0.50189539\n",
            "Iteration 14, loss = 0.50169667\n",
            "Iteration 15, loss = 0.50136909\n",
            "Iteration 16, loss = 0.50140526\n",
            "Iteration 17, loss = 0.50083981\n",
            "Iteration 18, loss = 0.50112717\n",
            "Iteration 19, loss = 0.50074972\n",
            "Iteration 20, loss = 0.50044433\n",
            "Iteration 21, loss = 0.50029233\n",
            "Iteration 22, loss = 0.49999430\n",
            "Iteration 23, loss = 0.49965523\n",
            "Iteration 24, loss = 0.49972209\n",
            "Iteration 25, loss = 0.49957425\n",
            "Iteration 26, loss = 0.49921357\n",
            "Iteration 27, loss = 0.49916423\n",
            "Iteration 28, loss = 0.49921377\n",
            "Iteration 29, loss = 0.49872534\n",
            "Iteration 30, loss = 0.49948361\n",
            "[CV 3/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.748 total time=  13.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53768281\n",
            "Iteration 2, loss = 0.51074960\n",
            "Iteration 3, loss = 0.50807536\n",
            "Iteration 4, loss = 0.50620200\n",
            "Iteration 5, loss = 0.50661144\n",
            "Iteration 6, loss = 0.50547515\n",
            "Iteration 7, loss = 0.50473971\n",
            "Iteration 8, loss = 0.50402893\n",
            "Iteration 9, loss = 0.50323016\n",
            "Iteration 10, loss = 0.50336802\n",
            "Iteration 11, loss = 0.50299219\n",
            "Iteration 12, loss = 0.50244454\n",
            "Iteration 13, loss = 0.50221522\n",
            "Iteration 14, loss = 0.50146056\n",
            "Iteration 15, loss = 0.50176891\n",
            "Iteration 16, loss = 0.50154999\n",
            "Iteration 17, loss = 0.50093140\n",
            "Iteration 18, loss = 0.50078497\n",
            "Iteration 19, loss = 0.50035478\n",
            "Iteration 20, loss = 0.50037855\n",
            "Iteration 21, loss = 0.50012980\n",
            "Iteration 22, loss = 0.49984823\n",
            "Iteration 23, loss = 0.49949359\n",
            "Iteration 24, loss = 0.49954587\n",
            "Iteration 25, loss = 0.49954989\n",
            "Iteration 26, loss = 0.49928768\n",
            "Iteration 27, loss = 0.49862671\n",
            "Iteration 28, loss = 0.49908875\n",
            "Iteration 29, loss = 0.49847171\n",
            "Iteration 30, loss = 0.49860239\n",
            "[CV 4/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.747 total time=  13.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.53880414\n",
            "Iteration 2, loss = 0.51248950\n",
            "Iteration 3, loss = 0.50967830\n",
            "Iteration 4, loss = 0.50817498\n",
            "Iteration 5, loss = 0.50802009\n",
            "Iteration 6, loss = 0.50696470\n",
            "Iteration 7, loss = 0.50627116\n",
            "Iteration 8, loss = 0.50583703\n",
            "Iteration 9, loss = 0.50537907\n",
            "Iteration 10, loss = 0.50503260\n",
            "Iteration 11, loss = 0.50463519\n",
            "Iteration 12, loss = 0.50443669\n",
            "Iteration 13, loss = 0.50423149\n",
            "Iteration 14, loss = 0.50344697\n",
            "Iteration 15, loss = 0.50357064\n",
            "Iteration 16, loss = 0.50332705\n",
            "Iteration 17, loss = 0.50311310\n",
            "Iteration 18, loss = 0.50250810\n",
            "Iteration 19, loss = 0.50228718\n",
            "Iteration 20, loss = 0.50219669\n",
            "Iteration 21, loss = 0.50187649\n",
            "Iteration 22, loss = 0.50195479\n",
            "Iteration 23, loss = 0.50217503\n",
            "Iteration 24, loss = 0.50153928\n",
            "Iteration 25, loss = 0.50137527\n",
            "Iteration 26, loss = 0.50142947\n",
            "Iteration 27, loss = 0.50096458\n",
            "Iteration 28, loss = 0.50153653\n",
            "Iteration 29, loss = 0.50087434\n",
            "Iteration 30, loss = 0.50052020\n",
            "[CV 5/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.751 total time=  12.2s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.52900524\n",
            "Iteration 2, loss = 0.51276830\n",
            "Iteration 3, loss = 0.51026062\n",
            "Iteration 4, loss = 0.50890515\n",
            "Iteration 5, loss = 0.50789563\n",
            "Iteration 6, loss = 0.50773033\n",
            "Iteration 7, loss = 0.50666715\n",
            "Iteration 8, loss = 0.50585023\n",
            "Iteration 9, loss = 0.50652858\n",
            "Iteration 10, loss = 0.50536643\n",
            "Iteration 11, loss = 0.50529797\n",
            "Iteration 12, loss = 0.50484627\n",
            "Iteration 13, loss = 0.50417156\n",
            "Iteration 14, loss = 0.50444159\n",
            "Iteration 15, loss = 0.50420878\n",
            "Iteration 16, loss = 0.50352852\n",
            "Iteration 17, loss = 0.50350372\n",
            "Iteration 18, loss = 0.50320902\n",
            "Iteration 19, loss = 0.50321546\n",
            "Iteration 20, loss = 0.50305321\n",
            "Iteration 21, loss = 0.50292497\n",
            "Iteration 22, loss = 0.50268385\n",
            "Iteration 23, loss = 0.50302049\n",
            "Iteration 24, loss = 0.50245658\n",
            "Iteration 25, loss = 0.50270674\n",
            "Iteration 26, loss = 0.50204829\n",
            "Iteration 27, loss = 0.50182244\n",
            "Iteration 28, loss = 0.50202919\n",
            "Iteration 29, loss = 0.50186557\n",
            "Iteration 30, loss = 0.50193447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=MLPClassifier(),\n",
              "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;], &#x27;alpha&#x27;: [0.01, 0.001],\n",
              "                         &#x27;hidden_layer_sizes&#x27;: [(64, 64), (32, 32)],\n",
              "                         &#x27;max_iter&#x27;: [30], &#x27;random_state&#x27;: [42],\n",
              "                         &#x27;solver&#x27;: [&#x27;adam&#x27;], &#x27;verbose&#x27;: [True]},\n",
              "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=MLPClassifier(),\n",
              "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;], &#x27;alpha&#x27;: [0.01, 0.001],\n",
              "                         &#x27;hidden_layer_sizes&#x27;: [(64, 64), (32, 32)],\n",
              "                         &#x27;max_iter&#x27;: [30], &#x27;random_state&#x27;: [42],\n",
              "                         &#x27;solver&#x27;: [&#x27;adam&#x27;], &#x27;verbose&#x27;: [True]},\n",
              "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5, estimator=MLPClassifier(),\n",
              "             param_grid={'activation': ['relu', 'tanh'], 'alpha': [0.01, 0.001],\n",
              "                         'hidden_layer_sizes': [(64, 64), (32, 32)],\n",
              "                         'max_iter': [30], 'random_state': [42],\n",
              "                         'solver': ['adam'], 'verbose': [True]},\n",
              "             scoring='f1_weighted', verbose=3)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_grid_search_clf = GridSearchCV(estimator=mlp_classifer, param_grid=mlp_param_grid, scoring='f1_weighted', cv=5, verbose=3)\n",
        "mlp_grid_search_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4r608uy8Egs7",
        "outputId": "6e129136-3a27-43bc-def6-6cefd1640c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'activation': 'tanh', 'alpha': 0.01, 'hidden_layer_sizes': (64, 64), 'max_iter': 30, 'random_state': 42, 'solver': 'adam', 'verbose': True}\n"
          ]
        }
      ],
      "source": [
        "print(mlp_grid_search_clf.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "S9Vxz57SV9qf",
        "outputId": "9168209a-cccf-41db-c5f6-ac1666103ba0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.52900524\n",
            "Iteration 2, loss = 0.51276830\n",
            "Iteration 3, loss = 0.51026062\n",
            "Iteration 4, loss = 0.50890515\n",
            "Iteration 5, loss = 0.50789563\n",
            "Iteration 6, loss = 0.50773033\n",
            "Iteration 7, loss = 0.50666715\n",
            "Iteration 8, loss = 0.50585023\n",
            "Iteration 9, loss = 0.50652858\n",
            "Iteration 10, loss = 0.50536643\n",
            "Iteration 11, loss = 0.50529797\n",
            "Iteration 12, loss = 0.50484627\n",
            "Iteration 13, loss = 0.50417156\n",
            "Iteration 14, loss = 0.50444159\n",
            "Iteration 15, loss = 0.50420878\n",
            "Iteration 16, loss = 0.50352852\n",
            "Iteration 17, loss = 0.50350372\n",
            "Iteration 18, loss = 0.50320902\n",
            "Iteration 19, loss = 0.50321546\n",
            "Iteration 20, loss = 0.50305321\n",
            "Iteration 21, loss = 0.50292497\n",
            "Iteration 22, loss = 0.50268385\n",
            "Iteration 23, loss = 0.50302049\n",
            "Iteration 24, loss = 0.50245658\n",
            "Iteration 25, loss = 0.50270674\n",
            "Iteration 26, loss = 0.50204829\n",
            "Iteration 27, loss = 0.50182244\n",
            "Iteration 28, loss = 0.50202919\n",
            "Iteration 29, loss = 0.50186557\n",
            "Iteration 30, loss = 0.50193447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, alpha=0.01, hidden_layer_sizes=(64, 64),\n",
              "              max_iter=30, random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;tanh&#x27;, alpha=0.01, hidden_layer_sizes=(64, 64),\n",
              "              max_iter=30, random_state=42, verbose=True)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "MLPClassifier(activation='tanh', alpha=0.01, hidden_layer_sizes=(64, 64),\n",
              "              max_iter=30, random_state=42, verbose=True)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_classifer_binary_split = MLPClassifier()\n",
        "mlp_classifer_binary_split.set_params(**mlp_grid_search_clf.best_params_)\n",
        "mlp_classifer_binary_split.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "7Ne3W_CeEgs7"
      },
      "outputs": [],
      "source": [
        "mlp_pickle_file_binary_split = '/content/drive/MyDrive/AML_Final_Project/mlp_classifer_binary_split.pkl'\n",
        "# with open(mlp_pickle_file_binary_split, 'wb') as file:\n",
        "#     pickle.dump(mlp_classifer_binary_split, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "veqFW_DQEgs7"
      },
      "outputs": [],
      "source": [
        "with open(mlp_pickle_file_binary_split, 'rb') as file:\n",
        "    mlp_classifer_binary_split = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqT8S12REgs7",
        "outputId": "7187aba8-72e6-4d37-b4e2-40a2faf9e0c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.81      0.72      5651\n",
            "         1.0       0.85      0.71      0.77      8488\n",
            "\n",
            "    accuracy                           0.75     14139\n",
            "   macro avg       0.75      0.76      0.75     14139\n",
            "weighted avg       0.77      0.75      0.75     14139\n",
            "\n",
            "[[4597 1054]\n",
            " [2473 6015]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = mlp_classifer_binary_split.predict(X_test)\n",
        "print(classification_report(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOPv0-chOLqA"
      },
      "source": [
        "### Training the MLP classifier using the best parameters obtained after grid search and cross validation using the PCA on training data to get the cumulative variance explained by different no. of components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVQZMbpIONG_",
        "outputId": "5edd1f2a-9182-433f-f36b-e4edc7f20b36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cumulative variance explained by 3 components is 0.43404642271751837\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      0.73      0.72      6899\n",
            "         1.0       0.73      0.71      0.72      7240\n",
            "\n",
            "    accuracy                           0.72     14139\n",
            "   macro avg       0.72      0.72      0.72     14139\n",
            "weighted avg       0.72      0.72      0.72     14139\n",
            "\n",
            "\n",
            "Cumulative variance explained by 5 components is 0.6065148562363322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.71      0.73      0.72      6841\n",
            "         1.0       0.74      0.72      0.73      7298\n",
            "\n",
            "    accuracy                           0.72     14139\n",
            "   macro avg       0.72      0.72      0.72     14139\n",
            "weighted avg       0.72      0.72      0.72     14139\n",
            "\n",
            "\n",
            "Cumulative variance explained by 10 components is 0.8612429795606062\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.74      0.74      6954\n",
            "         1.0       0.75      0.74      0.74      7185\n",
            "\n",
            "    accuracy                           0.74     14139\n",
            "   macro avg       0.74      0.74      0.74     14139\n",
            "weighted avg       0.74      0.74      0.74     14139\n",
            "\n",
            "\n",
            "Cumulative variance explained by 15 components is 0.9517394483608925\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.78      0.73      6357\n",
            "         1.0       0.80      0.72      0.76      7782\n",
            "\n",
            "    accuracy                           0.75     14139\n",
            "   macro avg       0.75      0.75      0.75     14139\n",
            "weighted avg       0.75      0.75      0.75     14139\n",
            "\n",
            "\n",
            "Cumulative variance explained by 20 components is 0.994974739824596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 20\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.73      0.76      0.75      6836\n",
            "         1.0       0.77      0.74      0.75      7303\n",
            "\n",
            "    accuracy                           0.75     14139\n",
            "   macro avg       0.75      0.75      0.75     14139\n",
            "weighted avg       0.75      0.75      0.75     14139\n",
            "\n",
            "\n",
            "Cumulative variance explained by 25 components is 0.9999999999999996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.70      0.78      0.74      6324\n",
            "         1.0       0.80      0.73      0.76      7815\n",
            "\n",
            "    accuracy                           0.75     14139\n",
            "   macro avg       0.75      0.75      0.75     14139\n",
            "weighted avg       0.76      0.75      0.75     14139\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "num_components = [3, 5, 10, 15, 20, 25]\n",
        "variance = []\n",
        "\n",
        "for num in num_components:\n",
        "  # Initializing the PCA with defitive components\n",
        "  pca = PCA(n_components=num)\n",
        "\n",
        "  # Fit the PCA on the training data\n",
        "  pca.fit(X_train)\n",
        "\n",
        "  # Transform the train and test data as per the components of the PCA\n",
        "  X_train_pca = pca.transform(X_train)\n",
        "  X_test_pca = pca.transform(X_test)\n",
        "\n",
        "  # Recording the explained variance for each number of components\n",
        "  variance.append(np.sum(pca.explained_variance_ratio_))\n",
        "\n",
        "  print(\"Cumulative variance explained by {} components is {}\".format(num,variance[-1]))\n",
        "\n",
        "  mlp_classifer = MLPClassifier(activation = 'tanh', alpha=0.01, hidden_layer_sizes=(64, 64), max_iter = 30, solver='adam', random_state= 42)\n",
        "  mlp_classifer.fit(X_train_pca, y_train)\n",
        "  y_pred = mlp_classifer.predict(X_test_pca)\n",
        "  print(f\"Classification Report for total components: {num}\")\n",
        "  print(classification_report(y_pred, y_test))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "wqHMwhSXONEw",
        "outputId": "67b4fc57-d3d9-4304-9d2b-89bb23c6b91f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### START CODE ###\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(num_components, variance)\n",
        "plt.title(\"PCA Explained Variance for Binary Balanced Split\")\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.grid(True)\n",
        "### END CODE ###\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWogWNZPEgs7"
      },
      "source": [
        "# Training the model for 2-Class Imbalanced Split Diabetes Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "55Z6XhSBEgs7"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_csv('/content/drive/MyDrive/AML_Final_Project/Dataset/train_binary_imbalanced_split.csv')\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/AML_Final_Project/Dataset/test_binary_imbalanced_split.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "cZXPL2-kEgs7",
        "outputId": "31b8dfbe-8a7c-4e67-c3fa-65d09e11dd0f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-263a30ac-ce33-4167-8aba-0129385d4bea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BMI</th>\n",
              "      <th>GenHlth</th>\n",
              "      <th>MentHlth</th>\n",
              "      <th>PhysHlth</th>\n",
              "      <th>DiffWalk</th>\n",
              "      <th>Age</th>\n",
              "      <th>Education</th>\n",
              "      <th>Income</th>\n",
              "      <th>HighBP_0</th>\n",
              "      <th>HighBP_1</th>\n",
              "      <th>...</th>\n",
              "      <th>Veggies_1</th>\n",
              "      <th>HvyAlcoholConsump_0</th>\n",
              "      <th>HvyAlcoholConsump_1</th>\n",
              "      <th>AnyHealthcare_0</th>\n",
              "      <th>AnyHealthcare_1</th>\n",
              "      <th>NoDocbcCost_0</th>\n",
              "      <th>NoDocbcCost_1</th>\n",
              "      <th>Sex_0</th>\n",
              "      <th>Sex_1</th>\n",
              "      <th>Diabetes_binary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.057282</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.083333</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.815055</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.094273</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.609820</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.6</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.875938</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 35 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-263a30ac-ce33-4167-8aba-0129385d4bea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-263a30ac-ce33-4167-8aba-0129385d4bea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-263a30ac-ce33-4167-8aba-0129385d4bea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fadfdbf2-1fc2-47b8-a17b-0ae99f34a1fc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fadfdbf2-1fc2-47b8-a17b-0ae99f34a1fc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fadfdbf2-1fc2-47b8-a17b-0ae99f34a1fc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        BMI  GenHlth  MentHlth  PhysHlth  DiffWalk       Age  Education  \\\n",
              "0 -0.057282     0.25       0.0       0.0       0.0  0.083333        0.6   \n",
              "1 -0.815055     0.25       0.0       0.0       0.0  1.000000        0.6   \n",
              "2  0.094273     0.00       0.0       0.0       0.0  0.666667        1.0   \n",
              "3  1.609820     0.75       0.0       0.0       0.0  0.500000        0.6   \n",
              "4 -1.875938     1.00       1.0       1.0       1.0  0.500000        0.8   \n",
              "\n",
              "     Income  HighBP_0  HighBP_1  ...  Veggies_1  HvyAlcoholConsump_0  \\\n",
              "0  0.571429       1.0       0.0  ...        1.0                  1.0   \n",
              "1  0.857143       0.0       1.0  ...        1.0                  1.0   \n",
              "2  1.000000       0.0       1.0  ...        1.0                  1.0   \n",
              "3  0.857143       0.0       1.0  ...        0.0                  1.0   \n",
              "4  0.000000       1.0       0.0  ...        1.0                  1.0   \n",
              "\n",
              "   HvyAlcoholConsump_1  AnyHealthcare_0  AnyHealthcare_1  NoDocbcCost_0  \\\n",
              "0                  0.0              0.0              1.0            1.0   \n",
              "1                  0.0              0.0              1.0            1.0   \n",
              "2                  0.0              0.0              1.0            1.0   \n",
              "3                  0.0              0.0              1.0            1.0   \n",
              "4                  0.0              0.0              1.0            0.0   \n",
              "\n",
              "   NoDocbcCost_1  Sex_0  Sex_1  Diabetes_binary  \n",
              "0            0.0    0.0    1.0              0.0  \n",
              "1            0.0    0.0    1.0              0.0  \n",
              "2            0.0    0.0    1.0              0.0  \n",
              "3            0.0    0.0    1.0              0.0  \n",
              "4            1.0    1.0    0.0              0.0  \n",
              "\n",
              "[5 rows x 35 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zX_ekgwsEgs7"
      },
      "outputs": [],
      "source": [
        "X_train = train_data.drop(['Diabetes_binary'], axis=1)\n",
        "y_train = train_data['Diabetes_binary']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "epNHSyuDEgs8"
      },
      "outputs": [],
      "source": [
        "X_test = test_data.drop(['Diabetes_binary'], axis=1)\n",
        "y_test = test_data['Diabetes_binary']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR5S5apfEgs8"
      },
      "outputs": [],
      "source": [
        "mlp_classifer = MLPClassifier()\n",
        "mlp_param_grid ={\"hidden_layer_sizes\": [(64, 64), (32, 32)],\n",
        "                \"activation\": ['relu', 'tanh'],\n",
        "                \"alpha\" : [0.01, 0.001],\n",
        "                 \"solver\": ['adam'],\n",
        "                \"random_state\": [42],\n",
        "                \"verbose\" : [True],\n",
        "                 \"max_iter\" : [30]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w8lKKKvlEgs8",
        "outputId": "aa949a1d-f034-456b-d095-c5ec2d9a65d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "Iteration 1, loss = 0.32689652\n",
            "Iteration 2, loss = 0.31662935\n",
            "Iteration 3, loss = 0.31579485\n",
            "Iteration 4, loss = 0.31490482\n",
            "Iteration 5, loss = 0.31439419\n",
            "Iteration 6, loss = 0.31412306\n",
            "Iteration 7, loss = 0.31375098\n",
            "Iteration 8, loss = 0.31366607\n",
            "Iteration 9, loss = 0.31336558\n",
            "Iteration 10, loss = 0.31318310\n",
            "Iteration 11, loss = 0.31305788\n",
            "Iteration 12, loss = 0.31280667\n",
            "Iteration 13, loss = 0.31276024\n",
            "Iteration 14, loss = 0.31261268\n",
            "Iteration 15, loss = 0.31245980\n",
            "Iteration 16, loss = 0.31266852\n",
            "Iteration 17, loss = 0.31237476\n",
            "Iteration 18, loss = 0.31233744\n",
            "Iteration 19, loss = 0.31209887\n",
            "Iteration 20, loss = 0.31218185\n",
            "Iteration 21, loss = 0.31184974\n",
            "Iteration 22, loss = 0.31196552\n",
            "Iteration 23, loss = 0.31175673\n",
            "Iteration 24, loss = 0.31167261\n",
            "Iteration 25, loss = 0.31161650\n",
            "Iteration 26, loss = 0.31155927\n",
            "Iteration 27, loss = 0.31172254\n",
            "Iteration 28, loss = 0.31135251\n",
            "Iteration 29, loss = 0.31133899\n",
            "Iteration 30, loss = 0.31121498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.830 total time= 1.6min\n",
            "Iteration 1, loss = 0.32646122\n",
            "Iteration 2, loss = 0.31654074\n",
            "Iteration 3, loss = 0.31520063\n",
            "Iteration 4, loss = 0.31477557\n",
            "Iteration 5, loss = 0.31401788\n",
            "Iteration 6, loss = 0.31362236\n",
            "Iteration 7, loss = 0.31327822\n",
            "Iteration 8, loss = 0.31308721\n",
            "Iteration 9, loss = 0.31272204\n",
            "Iteration 10, loss = 0.31267696\n",
            "Iteration 11, loss = 0.31242096\n",
            "Iteration 12, loss = 0.31228919\n",
            "Iteration 13, loss = 0.31213619\n",
            "Iteration 14, loss = 0.31202748\n",
            "Iteration 15, loss = 0.31208082\n",
            "Iteration 16, loss = 0.31185649\n",
            "Iteration 17, loss = 0.31177997\n",
            "Iteration 18, loss = 0.31171815\n",
            "Iteration 19, loss = 0.31150151\n",
            "Iteration 20, loss = 0.31157540\n",
            "Iteration 21, loss = 0.31132092\n",
            "Iteration 22, loss = 0.31137964\n",
            "Iteration 23, loss = 0.31119451\n",
            "Iteration 24, loss = 0.31104441\n",
            "Iteration 25, loss = 0.31111278\n",
            "Iteration 26, loss = 0.31116292\n",
            "Iteration 27, loss = 0.31082845\n",
            "Iteration 28, loss = 0.31081298\n",
            "Iteration 29, loss = 0.31062075\n",
            "Iteration 30, loss = 0.31078830\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.832 total time= 1.6min\n",
            "Iteration 1, loss = 0.32615399\n",
            "Iteration 2, loss = 0.31577449\n",
            "Iteration 3, loss = 0.31484663\n",
            "Iteration 4, loss = 0.31430022\n",
            "Iteration 5, loss = 0.31380902\n",
            "Iteration 6, loss = 0.31333202\n",
            "Iteration 7, loss = 0.31329590\n",
            "Iteration 8, loss = 0.31292543\n",
            "Iteration 9, loss = 0.31257510\n",
            "Iteration 10, loss = 0.31241081\n",
            "Iteration 11, loss = 0.31245953\n",
            "Iteration 12, loss = 0.31213384\n",
            "Iteration 13, loss = 0.31208789\n",
            "Iteration 14, loss = 0.31201762\n",
            "Iteration 15, loss = 0.31193906\n",
            "Iteration 16, loss = 0.31168456\n",
            "Iteration 17, loss = 0.31168746\n",
            "Iteration 18, loss = 0.31150716\n",
            "Iteration 19, loss = 0.31152674\n",
            "Iteration 20, loss = 0.31160234\n",
            "Iteration 21, loss = 0.31118446\n",
            "Iteration 22, loss = 0.31151121\n",
            "Iteration 23, loss = 0.31135951\n",
            "Iteration 24, loss = 0.31111664\n",
            "Iteration 25, loss = 0.31118760\n",
            "Iteration 26, loss = 0.31111860\n",
            "Iteration 27, loss = 0.31093539\n",
            "Iteration 28, loss = 0.31089170\n",
            "Iteration 29, loss = 0.31087627\n",
            "Iteration 30, loss = 0.31094811\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.833 total time= 1.5min\n",
            "Iteration 1, loss = 0.32673477\n",
            "Iteration 2, loss = 0.31637380\n",
            "Iteration 3, loss = 0.31541673\n",
            "Iteration 4, loss = 0.31477424\n",
            "Iteration 5, loss = 0.31448198\n",
            "Iteration 6, loss = 0.31395087\n",
            "Iteration 7, loss = 0.31393987\n",
            "Iteration 8, loss = 0.31344893\n",
            "Iteration 9, loss = 0.31301503\n",
            "Iteration 10, loss = 0.31288308\n",
            "Iteration 11, loss = 0.31289738\n",
            "Iteration 12, loss = 0.31271282\n",
            "Iteration 13, loss = 0.31255821\n",
            "Iteration 14, loss = 0.31238608\n",
            "Iteration 15, loss = 0.31222919\n",
            "Iteration 16, loss = 0.31214892\n",
            "Iteration 17, loss = 0.31214370\n",
            "Iteration 18, loss = 0.31188827\n",
            "Iteration 19, loss = 0.31206477\n",
            "Iteration 20, loss = 0.31183358\n",
            "Iteration 21, loss = 0.31161988\n",
            "Iteration 22, loss = 0.31185792\n",
            "Iteration 23, loss = 0.31160998\n",
            "Iteration 24, loss = 0.31152947\n",
            "Iteration 25, loss = 0.31161872\n",
            "Iteration 26, loss = 0.31128238\n",
            "Iteration 27, loss = 0.31128990\n",
            "Iteration 28, loss = 0.31128368\n",
            "Iteration 29, loss = 0.31123971\n",
            "Iteration 30, loss = 0.31135884\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.837 total time= 1.5min\n",
            "Iteration 1, loss = 0.32798183\n",
            "Iteration 2, loss = 0.31678677\n",
            "Iteration 3, loss = 0.31562970\n",
            "Iteration 4, loss = 0.31502791\n",
            "Iteration 5, loss = 0.31443939\n",
            "Iteration 6, loss = 0.31407720\n",
            "Iteration 7, loss = 0.31389794\n",
            "Iteration 8, loss = 0.31356617\n",
            "Iteration 9, loss = 0.31343755\n",
            "Iteration 10, loss = 0.31335855\n",
            "Iteration 11, loss = 0.31322417\n",
            "Iteration 12, loss = 0.31296343\n",
            "Iteration 13, loss = 0.31290682\n",
            "Iteration 14, loss = 0.31270867\n",
            "Iteration 15, loss = 0.31272348\n",
            "Iteration 16, loss = 0.31263040\n",
            "Iteration 17, loss = 0.31241870\n",
            "Iteration 18, loss = 0.31254470\n",
            "Iteration 19, loss = 0.31223948\n",
            "Iteration 20, loss = 0.31222194\n",
            "Iteration 21, loss = 0.31209110\n",
            "Iteration 22, loss = 0.31198601\n",
            "Iteration 23, loss = 0.31201145\n",
            "Iteration 24, loss = 0.31189007\n",
            "Iteration 25, loss = 0.31162335\n",
            "Iteration 26, loss = 0.31180779\n",
            "Iteration 27, loss = 0.31181426\n",
            "Iteration 28, loss = 0.31167214\n",
            "Iteration 29, loss = 0.31165514\n",
            "Iteration 30, loss = 0.31141455\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.834 total time= 1.5min\n",
            "Iteration 1, loss = 0.33210227\n",
            "Iteration 2, loss = 0.31668962\n",
            "Iteration 3, loss = 0.31547848\n",
            "Iteration 4, loss = 0.31472076\n",
            "Iteration 5, loss = 0.31460916\n",
            "Iteration 6, loss = 0.31417697\n",
            "Iteration 7, loss = 0.31391150\n",
            "Iteration 8, loss = 0.31356820\n",
            "Iteration 9, loss = 0.31357476\n",
            "Iteration 10, loss = 0.31336259\n",
            "Iteration 11, loss = 0.31309024\n",
            "Iteration 12, loss = 0.31308946\n",
            "Iteration 13, loss = 0.31308153\n",
            "Iteration 14, loss = 0.31279798\n",
            "Iteration 15, loss = 0.31278523\n",
            "Iteration 16, loss = 0.31276150\n",
            "Iteration 17, loss = 0.31256714\n",
            "Iteration 18, loss = 0.31240939\n",
            "Iteration 19, loss = 0.31247560\n",
            "Iteration 20, loss = 0.31226055\n",
            "Iteration 21, loss = 0.31215862\n",
            "Iteration 22, loss = 0.31226737\n",
            "Iteration 23, loss = 0.31204424\n",
            "Iteration 24, loss = 0.31205833\n",
            "Iteration 25, loss = 0.31191359\n",
            "Iteration 26, loss = 0.31194138\n",
            "Iteration 27, loss = 0.31170739\n",
            "Iteration 28, loss = 0.31182891\n",
            "Iteration 29, loss = 0.31172300\n",
            "Iteration 30, loss = 0.31180790\n",
            "[CV 1/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.834 total time=  31.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.33097532\n",
            "Iteration 2, loss = 0.31618853\n",
            "Iteration 3, loss = 0.31482008\n",
            "Iteration 4, loss = 0.31433996\n",
            "Iteration 5, loss = 0.31405929\n",
            "Iteration 6, loss = 0.31363830\n",
            "Iteration 7, loss = 0.31335888\n",
            "Iteration 8, loss = 0.31312641\n",
            "Iteration 9, loss = 0.31305161\n",
            "Iteration 10, loss = 0.31299853\n",
            "Iteration 11, loss = 0.31261335\n",
            "Iteration 12, loss = 0.31251110\n",
            "Iteration 13, loss = 0.31251371\n",
            "Iteration 14, loss = 0.31226851\n",
            "Iteration 15, loss = 0.31216820\n",
            "Iteration 16, loss = 0.31222300\n",
            "Iteration 17, loss = 0.31192010\n",
            "Iteration 18, loss = 0.31187556\n",
            "Iteration 19, loss = 0.31191270\n",
            "Iteration 20, loss = 0.31178797\n",
            "Iteration 21, loss = 0.31161848\n",
            "Iteration 22, loss = 0.31167564\n",
            "Iteration 23, loss = 0.31160720\n",
            "Iteration 24, loss = 0.31148271\n",
            "Iteration 25, loss = 0.31135606\n",
            "Iteration 26, loss = 0.31132517\n",
            "Iteration 27, loss = 0.31137040\n",
            "Iteration 28, loss = 0.31130890\n",
            "Iteration 29, loss = 0.31133666\n",
            "Iteration 30, loss = 0.31125994\n",
            "[CV 2/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.831 total time=  32.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.33080342\n",
            "Iteration 2, loss = 0.31596242\n",
            "Iteration 3, loss = 0.31459344\n",
            "Iteration 4, loss = 0.31391547\n",
            "Iteration 5, loss = 0.31363260\n",
            "Iteration 6, loss = 0.31326043\n",
            "Iteration 7, loss = 0.31295478\n",
            "Iteration 8, loss = 0.31271479\n",
            "Iteration 9, loss = 0.31266492\n",
            "Iteration 10, loss = 0.31236700\n",
            "Iteration 11, loss = 0.31231746\n",
            "Iteration 12, loss = 0.31225360\n",
            "Iteration 13, loss = 0.31219042\n",
            "Iteration 14, loss = 0.31208996\n",
            "Iteration 15, loss = 0.31194974\n",
            "Iteration 16, loss = 0.31205864\n",
            "Iteration 17, loss = 0.31164866\n",
            "Iteration 18, loss = 0.31180542\n",
            "Iteration 19, loss = 0.31162986\n",
            "Iteration 20, loss = 0.31156380\n",
            "Iteration 21, loss = 0.31141710\n",
            "Iteration 22, loss = 0.31152797\n",
            "Iteration 23, loss = 0.31152333\n",
            "Iteration 24, loss = 0.31131271\n",
            "Iteration 25, loss = 0.31129789\n",
            "Iteration 26, loss = 0.31126771\n",
            "Iteration 27, loss = 0.31130371\n",
            "Iteration 28, loss = 0.31118623\n",
            "Iteration 29, loss = 0.31136670\n",
            "Iteration 30, loss = 0.31105014\n",
            "[CV 3/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.827 total time=  31.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.33193373\n",
            "Iteration 2, loss = 0.31647073\n",
            "Iteration 3, loss = 0.31506346\n",
            "Iteration 4, loss = 0.31471564\n",
            "Iteration 5, loss = 0.31425722\n",
            "Iteration 6, loss = 0.31403015\n",
            "Iteration 7, loss = 0.31354452\n",
            "Iteration 8, loss = 0.31346998\n",
            "Iteration 9, loss = 0.31313315\n",
            "Iteration 10, loss = 0.31299958\n",
            "Iteration 11, loss = 0.31289099\n",
            "Iteration 12, loss = 0.31295396\n",
            "Iteration 13, loss = 0.31268823\n",
            "Iteration 14, loss = 0.31262222\n",
            "Iteration 15, loss = 0.31256348\n",
            "Iteration 16, loss = 0.31240477\n",
            "Iteration 17, loss = 0.31218939\n",
            "Iteration 18, loss = 0.31229835\n",
            "Iteration 19, loss = 0.31212012\n",
            "Iteration 20, loss = 0.31204707\n",
            "Iteration 21, loss = 0.31188987\n",
            "Iteration 22, loss = 0.31187397\n",
            "Iteration 23, loss = 0.31192905\n",
            "Iteration 24, loss = 0.31164608\n",
            "Iteration 25, loss = 0.31171574\n",
            "Iteration 26, loss = 0.31176022\n",
            "Iteration 27, loss = 0.31171220\n",
            "Iteration 28, loss = 0.31147922\n",
            "Iteration 29, loss = 0.31155720\n",
            "Iteration 30, loss = 0.31132404\n",
            "[CV 4/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.832 total time=  32.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.33210872\n",
            "Iteration 2, loss = 0.31668750\n",
            "Iteration 3, loss = 0.31554338\n",
            "Iteration 4, loss = 0.31503108\n",
            "Iteration 5, loss = 0.31445261\n",
            "Iteration 6, loss = 0.31422657\n",
            "Iteration 7, loss = 0.31387342\n",
            "Iteration 8, loss = 0.31360911\n",
            "Iteration 9, loss = 0.31358547\n",
            "Iteration 10, loss = 0.31330161\n",
            "Iteration 11, loss = 0.31346711\n",
            "Iteration 12, loss = 0.31317469\n",
            "Iteration 13, loss = 0.31301344\n",
            "Iteration 14, loss = 0.31303696\n",
            "Iteration 15, loss = 0.31287115\n",
            "Iteration 16, loss = 0.31282960\n",
            "Iteration 17, loss = 0.31263009\n",
            "Iteration 18, loss = 0.31253624\n",
            "Iteration 19, loss = 0.31254968\n",
            "Iteration 20, loss = 0.31244197\n",
            "Iteration 21, loss = 0.31219292\n",
            "Iteration 22, loss = 0.31238295\n",
            "Iteration 23, loss = 0.31242066\n",
            "Iteration 24, loss = 0.31214033\n",
            "Iteration 25, loss = 0.31212233\n",
            "Iteration 26, loss = 0.31218485\n",
            "Iteration 27, loss = 0.31191172\n",
            "Iteration 28, loss = 0.31193419\n",
            "Iteration 29, loss = 0.31183221\n",
            "Iteration 30, loss = 0.31187182\n",
            "[CV 5/5] END activation=relu, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.840 total time=  29.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.32468312\n",
            "Iteration 2, loss = 0.31474529\n",
            "Iteration 3, loss = 0.31396591\n",
            "Iteration 4, loss = 0.31320810\n",
            "Iteration 5, loss = 0.31267368\n",
            "Iteration 6, loss = 0.31241003\n",
            "Iteration 7, loss = 0.31201693\n",
            "Iteration 8, loss = 0.31192038\n",
            "Iteration 9, loss = 0.31156974\n",
            "Iteration 10, loss = 0.31132449\n",
            "Iteration 11, loss = 0.31113948\n",
            "Iteration 12, loss = 0.31087554\n",
            "Iteration 13, loss = 0.31069985\n",
            "Iteration 14, loss = 0.31047395\n",
            "Iteration 15, loss = 0.31018263\n",
            "Iteration 16, loss = 0.31038724\n",
            "Iteration 17, loss = 0.30994946\n",
            "Iteration 18, loss = 0.30988406\n",
            "Iteration 19, loss = 0.30955312\n",
            "Iteration 20, loss = 0.30946055\n",
            "Iteration 21, loss = 0.30898497\n",
            "Iteration 22, loss = 0.30900389\n",
            "Iteration 23, loss = 0.30862718\n",
            "Iteration 24, loss = 0.30847725\n",
            "Iteration 25, loss = 0.30825226\n",
            "Iteration 26, loss = 0.30808062\n",
            "Iteration 27, loss = 0.30816245\n",
            "Iteration 28, loss = 0.30777298\n",
            "Iteration 29, loss = 0.30747802\n",
            "Iteration 30, loss = 0.30722148\n",
            "[CV 1/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.831 total time= 1.5min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.32419328\n",
            "Iteration 2, loss = 0.31449637\n",
            "Iteration 3, loss = 0.31330632\n",
            "Iteration 4, loss = 0.31294295\n",
            "Iteration 5, loss = 0.31222912\n",
            "Iteration 6, loss = 0.31181007\n",
            "Iteration 7, loss = 0.31146090\n",
            "Iteration 8, loss = 0.31129700\n",
            "Iteration 9, loss = 0.31094584\n",
            "Iteration 10, loss = 0.31068515\n",
            "Iteration 11, loss = 0.31038831\n",
            "Iteration 12, loss = 0.31013965\n",
            "Iteration 13, loss = 0.30987392\n",
            "Iteration 14, loss = 0.30965522\n",
            "Iteration 15, loss = 0.30969811\n",
            "Iteration 16, loss = 0.30931100\n",
            "Iteration 17, loss = 0.30912480\n",
            "Iteration 18, loss = 0.30896925\n",
            "Iteration 19, loss = 0.30868255\n",
            "Iteration 20, loss = 0.30852263\n",
            "Iteration 21, loss = 0.30826954\n",
            "Iteration 22, loss = 0.30815403\n",
            "Iteration 23, loss = 0.30795712\n",
            "Iteration 24, loss = 0.30762692\n",
            "Iteration 25, loss = 0.30763404\n",
            "Iteration 26, loss = 0.30752823\n",
            "Iteration 27, loss = 0.30709694\n",
            "Iteration 28, loss = 0.30689751\n",
            "Iteration 29, loss = 0.30673291\n",
            "Iteration 30, loss = 0.30654573\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.833 total time= 1.3min\n",
            "Iteration 1, loss = 0.32390593\n",
            "Iteration 2, loss = 0.31372172\n",
            "Iteration 3, loss = 0.31287169\n",
            "Iteration 4, loss = 0.31251843\n",
            "Iteration 5, loss = 0.31207169\n",
            "Iteration 6, loss = 0.31167963\n",
            "Iteration 7, loss = 0.31158912\n",
            "Iteration 8, loss = 0.31117458\n",
            "Iteration 9, loss = 0.31082788\n",
            "Iteration 10, loss = 0.31062216\n",
            "Iteration 11, loss = 0.31061194\n",
            "Iteration 12, loss = 0.31022115\n",
            "Iteration 13, loss = 0.31005433\n",
            "Iteration 14, loss = 0.30990635\n",
            "Iteration 15, loss = 0.30979433\n",
            "Iteration 16, loss = 0.30938969\n",
            "Iteration 17, loss = 0.30928735\n",
            "Iteration 18, loss = 0.30902814\n",
            "Iteration 19, loss = 0.30897433\n",
            "Iteration 20, loss = 0.30885675\n",
            "Iteration 21, loss = 0.30835044\n",
            "Iteration 22, loss = 0.30852030\n",
            "Iteration 23, loss = 0.30828988\n",
            "Iteration 24, loss = 0.30786842\n",
            "Iteration 25, loss = 0.30777156\n",
            "Iteration 26, loss = 0.30750701\n",
            "Iteration 27, loss = 0.30710302\n",
            "Iteration 28, loss = 0.30697121\n",
            "Iteration 29, loss = 0.30678560\n",
            "Iteration 30, loss = 0.30676086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.832 total time= 1.4min\n",
            "Iteration 1, loss = 0.32447081\n",
            "Iteration 2, loss = 0.31442008\n",
            "Iteration 3, loss = 0.31357599\n",
            "Iteration 4, loss = 0.31302358\n",
            "Iteration 5, loss = 0.31274987\n",
            "Iteration 6, loss = 0.31224773\n",
            "Iteration 7, loss = 0.31229639\n",
            "Iteration 8, loss = 0.31179240\n",
            "Iteration 9, loss = 0.31130426\n",
            "Iteration 10, loss = 0.31116762\n",
            "Iteration 11, loss = 0.31116225\n",
            "Iteration 12, loss = 0.31090174\n",
            "Iteration 13, loss = 0.31070378\n",
            "Iteration 14, loss = 0.31039513\n",
            "Iteration 15, loss = 0.31006337\n",
            "Iteration 16, loss = 0.31000466\n",
            "Iteration 17, loss = 0.30989943\n",
            "Iteration 18, loss = 0.30952531\n",
            "Iteration 19, loss = 0.30947678\n",
            "Iteration 20, loss = 0.30916148\n",
            "Iteration 21, loss = 0.30886531\n",
            "Iteration 22, loss = 0.30889853\n",
            "Iteration 23, loss = 0.30862963\n",
            "Iteration 24, loss = 0.30836906\n",
            "Iteration 25, loss = 0.30838470\n",
            "Iteration 26, loss = 0.30790629\n",
            "Iteration 27, loss = 0.30768267\n",
            "Iteration 28, loss = 0.30754793\n",
            "Iteration 29, loss = 0.30746425\n",
            "Iteration 30, loss = 0.30740160\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.834 total time= 1.3min\n",
            "Iteration 1, loss = 0.32579291\n",
            "Iteration 2, loss = 0.31481863\n",
            "Iteration 3, loss = 0.31381036\n",
            "Iteration 4, loss = 0.31328290\n",
            "Iteration 5, loss = 0.31279211\n",
            "Iteration 6, loss = 0.31240089\n",
            "Iteration 7, loss = 0.31221943\n",
            "Iteration 8, loss = 0.31177685\n",
            "Iteration 9, loss = 0.31160420\n",
            "Iteration 10, loss = 0.31141659\n",
            "Iteration 11, loss = 0.31132264\n",
            "Iteration 12, loss = 0.31091090\n",
            "Iteration 13, loss = 0.31076716\n",
            "Iteration 14, loss = 0.31049598\n",
            "Iteration 15, loss = 0.31045529\n",
            "Iteration 16, loss = 0.31017747\n",
            "Iteration 17, loss = 0.30986638\n",
            "Iteration 18, loss = 0.30983406\n",
            "Iteration 19, loss = 0.30951307\n",
            "Iteration 20, loss = 0.30944145\n",
            "Iteration 21, loss = 0.30914198\n",
            "Iteration 22, loss = 0.30891303\n",
            "Iteration 23, loss = 0.30889397\n",
            "Iteration 24, loss = 0.30863976\n",
            "Iteration 25, loss = 0.30838805\n",
            "Iteration 26, loss = 0.30839525\n",
            "Iteration 27, loss = 0.30827460\n",
            "Iteration 28, loss = 0.30800039\n",
            "Iteration 29, loss = 0.30785365\n",
            "Iteration 30, loss = 0.30752595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.837 total time= 1.2min\n",
            "Iteration 1, loss = 0.33076632\n",
            "Iteration 2, loss = 0.31536328\n",
            "Iteration 3, loss = 0.31416670\n",
            "Iteration 4, loss = 0.31340444\n",
            "Iteration 5, loss = 0.31327833\n",
            "Iteration 6, loss = 0.31292094\n",
            "Iteration 7, loss = 0.31265325\n",
            "Iteration 8, loss = 0.31231588\n",
            "Iteration 9, loss = 0.31223358\n",
            "Iteration 10, loss = 0.31209174\n",
            "Iteration 11, loss = 0.31175821\n",
            "Iteration 12, loss = 0.31170313\n",
            "Iteration 13, loss = 0.31172889\n",
            "Iteration 14, loss = 0.31143942\n",
            "Iteration 15, loss = 0.31132699\n",
            "Iteration 16, loss = 0.31130869\n",
            "Iteration 17, loss = 0.31104027\n",
            "Iteration 18, loss = 0.31091464\n",
            "Iteration 19, loss = 0.31101159\n",
            "Iteration 20, loss = 0.31077715\n",
            "Iteration 21, loss = 0.31064202\n",
            "Iteration 22, loss = 0.31067840\n",
            "Iteration 23, loss = 0.31048534\n",
            "Iteration 24, loss = 0.31044576\n",
            "Iteration 25, loss = 0.31015465\n",
            "Iteration 26, loss = 0.31028313\n",
            "Iteration 27, loss = 0.30991238\n",
            "Iteration 28, loss = 0.31007730\n",
            "Iteration 29, loss = 0.30990521\n",
            "Iteration 30, loss = 0.30991698\n",
            "[CV 1/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.834 total time=  31.7s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.32960817\n",
            "Iteration 2, loss = 0.31485647\n",
            "Iteration 3, loss = 0.31348535\n",
            "Iteration 4, loss = 0.31303948\n",
            "Iteration 5, loss = 0.31270691\n",
            "Iteration 6, loss = 0.31235062\n",
            "Iteration 7, loss = 0.31211483\n",
            "Iteration 8, loss = 0.31187910\n",
            "Iteration 9, loss = 0.31179770\n",
            "Iteration 10, loss = 0.31169348\n",
            "Iteration 11, loss = 0.31134192\n",
            "Iteration 12, loss = 0.31114228\n",
            "Iteration 13, loss = 0.31112109\n",
            "Iteration 14, loss = 0.31087703\n",
            "Iteration 15, loss = 0.31073515\n",
            "Iteration 16, loss = 0.31075892\n",
            "Iteration 17, loss = 0.31037228\n",
            "Iteration 18, loss = 0.31035048\n",
            "Iteration 19, loss = 0.31037343\n",
            "Iteration 20, loss = 0.31018839\n",
            "Iteration 21, loss = 0.30985912\n",
            "Iteration 22, loss = 0.30988551\n",
            "Iteration 23, loss = 0.30980909\n",
            "Iteration 24, loss = 0.30963739\n",
            "Iteration 25, loss = 0.30943886\n",
            "Iteration 26, loss = 0.30937953\n",
            "Iteration 27, loss = 0.30940998\n",
            "Iteration 28, loss = 0.30934528\n",
            "Iteration 29, loss = 0.30921229\n",
            "Iteration 30, loss = 0.30918599\n",
            "[CV 2/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.831 total time=  30.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.32960582\n",
            "Iteration 2, loss = 0.31473310\n",
            "Iteration 3, loss = 0.31338583\n",
            "Iteration 4, loss = 0.31266879\n",
            "Iteration 5, loss = 0.31246582\n",
            "Iteration 6, loss = 0.31208905\n",
            "Iteration 7, loss = 0.31176658\n",
            "Iteration 8, loss = 0.31156459\n",
            "Iteration 9, loss = 0.31148276\n",
            "Iteration 10, loss = 0.31118552\n",
            "Iteration 11, loss = 0.31107160\n",
            "Iteration 12, loss = 0.31098210\n",
            "Iteration 13, loss = 0.31093110\n",
            "Iteration 14, loss = 0.31079223\n",
            "Iteration 15, loss = 0.31056022\n",
            "Iteration 16, loss = 0.31068179\n",
            "Iteration 17, loss = 0.31022530\n",
            "Iteration 18, loss = 0.31033379\n",
            "Iteration 19, loss = 0.31016051\n",
            "Iteration 20, loss = 0.31011723\n",
            "Iteration 21, loss = 0.30995887\n",
            "Iteration 22, loss = 0.30991840\n",
            "Iteration 23, loss = 0.30993624\n",
            "Iteration 24, loss = 0.30969560\n",
            "Iteration 25, loss = 0.30962150\n",
            "Iteration 26, loss = 0.30965079\n",
            "Iteration 27, loss = 0.30951692\n",
            "Iteration 28, loss = 0.30939819\n",
            "Iteration 29, loss = 0.30951557\n",
            "Iteration 30, loss = 0.30919421\n",
            "[CV 3/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.829 total time=  30.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.33063722\n",
            "Iteration 2, loss = 0.31502121\n",
            "Iteration 3, loss = 0.31373571\n",
            "Iteration 4, loss = 0.31335762\n",
            "Iteration 5, loss = 0.31297162\n",
            "Iteration 6, loss = 0.31275836\n",
            "Iteration 7, loss = 0.31231260\n",
            "Iteration 8, loss = 0.31222123\n",
            "Iteration 9, loss = 0.31192867\n",
            "Iteration 10, loss = 0.31178204\n",
            "Iteration 11, loss = 0.31165449\n",
            "Iteration 12, loss = 0.31168406\n",
            "Iteration 13, loss = 0.31146680\n",
            "Iteration 14, loss = 0.31132748\n",
            "Iteration 15, loss = 0.31123251\n",
            "Iteration 16, loss = 0.31111362\n",
            "Iteration 17, loss = 0.31083615\n",
            "Iteration 18, loss = 0.31090807\n",
            "Iteration 19, loss = 0.31075469\n",
            "Iteration 20, loss = 0.31063623\n",
            "Iteration 21, loss = 0.31050865\n",
            "Iteration 22, loss = 0.31045903\n",
            "Iteration 23, loss = 0.31044754\n",
            "Iteration 24, loss = 0.31017745\n",
            "Iteration 25, loss = 0.31016190\n",
            "Iteration 26, loss = 0.31022952\n",
            "Iteration 27, loss = 0.31005101\n",
            "Iteration 28, loss = 0.30985014\n",
            "Iteration 29, loss = 0.30993234\n",
            "Iteration 30, loss = 0.30956991\n",
            "[CV 4/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.831 total time=  31.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.33057514\n",
            "Iteration 2, loss = 0.31530283\n",
            "Iteration 3, loss = 0.31418417\n",
            "Iteration 4, loss = 0.31370794\n",
            "Iteration 5, loss = 0.31312188\n",
            "Iteration 6, loss = 0.31287294\n",
            "Iteration 7, loss = 0.31247010\n",
            "Iteration 8, loss = 0.31228691\n",
            "Iteration 9, loss = 0.31218514\n",
            "Iteration 10, loss = 0.31193523\n",
            "Iteration 11, loss = 0.31208357\n",
            "Iteration 12, loss = 0.31178198\n",
            "Iteration 13, loss = 0.31163993\n",
            "Iteration 14, loss = 0.31164774\n",
            "Iteration 15, loss = 0.31141744\n",
            "Iteration 16, loss = 0.31137301\n",
            "Iteration 17, loss = 0.31117463\n",
            "Iteration 18, loss = 0.31110900\n",
            "Iteration 19, loss = 0.31103679\n",
            "Iteration 20, loss = 0.31102579\n",
            "Iteration 21, loss = 0.31071626\n",
            "Iteration 22, loss = 0.31084655\n",
            "Iteration 23, loss = 0.31086691\n",
            "Iteration 24, loss = 0.31052302\n",
            "Iteration 25, loss = 0.31048608\n",
            "Iteration 26, loss = 0.31053617\n",
            "Iteration 27, loss = 0.31022488\n",
            "Iteration 28, loss = 0.31022199\n",
            "Iteration 29, loss = 0.31014176\n",
            "Iteration 30, loss = 0.30998549\n",
            "[CV 5/5] END activation=relu, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.837 total time=  28.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.32697092\n",
            "Iteration 2, loss = 0.31867415\n",
            "Iteration 3, loss = 0.31765238\n",
            "Iteration 4, loss = 0.31672777\n",
            "Iteration 5, loss = 0.31601616\n",
            "Iteration 6, loss = 0.31571740\n",
            "Iteration 7, loss = 0.31537233\n",
            "Iteration 8, loss = 0.31532670\n",
            "Iteration 9, loss = 0.31489249\n",
            "Iteration 10, loss = 0.31479445\n",
            "Iteration 11, loss = 0.31465926\n",
            "Iteration 12, loss = 0.31445386\n",
            "Iteration 13, loss = 0.31427951\n",
            "Iteration 14, loss = 0.31424833\n",
            "Iteration 15, loss = 0.31408712\n",
            "Iteration 16, loss = 0.31428313\n",
            "Iteration 17, loss = 0.31400375\n",
            "Iteration 18, loss = 0.31402303\n",
            "Iteration 19, loss = 0.31375510\n",
            "Iteration 20, loss = 0.31399254\n",
            "Iteration 21, loss = 0.31351729\n",
            "Iteration 22, loss = 0.31365978\n",
            "Iteration 23, loss = 0.31348167\n",
            "Iteration 24, loss = 0.31349637\n",
            "Iteration 25, loss = 0.31340323\n",
            "Iteration 26, loss = 0.31336679\n",
            "Iteration 27, loss = 0.31352153\n",
            "Iteration 28, loss = 0.31331948\n",
            "Iteration 29, loss = 0.31326630\n",
            "Iteration 30, loss = 0.31311361\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.830 total time= 2.2min\n",
            "Iteration 1, loss = 0.32631894\n",
            "Iteration 2, loss = 0.31843235\n",
            "Iteration 3, loss = 0.31698223\n",
            "Iteration 4, loss = 0.31651724\n",
            "Iteration 5, loss = 0.31563430\n",
            "Iteration 6, loss = 0.31533209\n",
            "Iteration 7, loss = 0.31497097\n",
            "Iteration 8, loss = 0.31482604\n",
            "Iteration 9, loss = 0.31445327\n",
            "Iteration 10, loss = 0.31441315\n",
            "Iteration 11, loss = 0.31413759\n",
            "Iteration 12, loss = 0.31399892\n",
            "Iteration 13, loss = 0.31383232\n",
            "Iteration 14, loss = 0.31363436\n",
            "Iteration 15, loss = 0.31388675\n",
            "Iteration 16, loss = 0.31352716\n",
            "Iteration 17, loss = 0.31351801\n",
            "Iteration 18, loss = 0.31351702\n",
            "Iteration 19, loss = 0.31322169\n",
            "Iteration 20, loss = 0.31341882\n",
            "Iteration 21, loss = 0.31308501\n",
            "Iteration 22, loss = 0.31322057\n",
            "Iteration 23, loss = 0.31316455\n",
            "Iteration 24, loss = 0.31304326\n",
            "Iteration 25, loss = 0.31308604\n",
            "Iteration 26, loss = 0.31309272\n",
            "Iteration 27, loss = 0.31283763\n",
            "Iteration 28, loss = 0.31284156\n",
            "Iteration 29, loss = 0.31274580\n",
            "Iteration 30, loss = 0.31279087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.832 total time= 2.2min\n",
            "Iteration 1, loss = 0.32613086\n",
            "Iteration 2, loss = 0.31796219\n",
            "Iteration 3, loss = 0.31653109\n",
            "Iteration 4, loss = 0.31603607\n",
            "Iteration 5, loss = 0.31551488\n",
            "Iteration 6, loss = 0.31479727\n",
            "Iteration 7, loss = 0.31485651\n",
            "Iteration 8, loss = 0.31457460\n",
            "Iteration 9, loss = 0.31408682\n",
            "Iteration 10, loss = 0.31397232\n",
            "Iteration 11, loss = 0.31400913\n",
            "Iteration 12, loss = 0.31367757\n",
            "Iteration 13, loss = 0.31363502\n",
            "Iteration 14, loss = 0.31357709\n",
            "Iteration 15, loss = 0.31346225\n",
            "Iteration 16, loss = 0.31310923\n",
            "Iteration 17, loss = 0.31311496\n",
            "Iteration 18, loss = 0.31310577\n",
            "Iteration 19, loss = 0.31305254\n",
            "Iteration 20, loss = 0.31315261\n",
            "Iteration 21, loss = 0.31276538\n",
            "Iteration 22, loss = 0.31311627\n",
            "Iteration 23, loss = 0.31308295\n",
            "Iteration 24, loss = 0.31280085\n",
            "Iteration 25, loss = 0.31280517\n",
            "Iteration 26, loss = 0.31269985\n",
            "Iteration 27, loss = 0.31257014\n",
            "Iteration 28, loss = 0.31256350\n",
            "Iteration 29, loss = 0.31262304\n",
            "Iteration 30, loss = 0.31278896\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.827 total time= 2.2min\n",
            "Iteration 1, loss = 0.32674358\n",
            "Iteration 2, loss = 0.31858971\n",
            "Iteration 3, loss = 0.31724529\n",
            "Iteration 4, loss = 0.31635296\n",
            "Iteration 5, loss = 0.31605475\n",
            "Iteration 6, loss = 0.31551852\n",
            "Iteration 7, loss = 0.31555659\n",
            "Iteration 8, loss = 0.31512878\n",
            "Iteration 9, loss = 0.31458250\n",
            "Iteration 10, loss = 0.31437566\n",
            "Iteration 11, loss = 0.31451213\n",
            "Iteration 12, loss = 0.31426131\n",
            "Iteration 13, loss = 0.31419211\n",
            "Iteration 14, loss = 0.31392860\n",
            "Iteration 15, loss = 0.31379791\n",
            "Iteration 16, loss = 0.31368648\n",
            "Iteration 17, loss = 0.31368162\n",
            "Iteration 18, loss = 0.31343072\n",
            "Iteration 19, loss = 0.31369632\n",
            "Iteration 20, loss = 0.31350787\n",
            "Iteration 21, loss = 0.31321674\n",
            "Iteration 22, loss = 0.31344577\n",
            "Iteration 23, loss = 0.31337301\n",
            "Iteration 24, loss = 0.31313453\n",
            "Iteration 25, loss = 0.31329239\n",
            "Iteration 26, loss = 0.31302779\n",
            "Iteration 27, loss = 0.31299865\n",
            "Iteration 28, loss = 0.31289503\n",
            "Iteration 29, loss = 0.31305324\n",
            "Iteration 30, loss = 0.31318729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.830 total time= 2.1min\n",
            "Iteration 1, loss = 0.32767086\n",
            "Iteration 2, loss = 0.31914096\n",
            "Iteration 3, loss = 0.31742553\n",
            "Iteration 4, loss = 0.31669321\n",
            "Iteration 5, loss = 0.31608088\n",
            "Iteration 6, loss = 0.31571887\n",
            "Iteration 7, loss = 0.31543823\n",
            "Iteration 8, loss = 0.31510046\n",
            "Iteration 9, loss = 0.31513527\n",
            "Iteration 10, loss = 0.31497305\n",
            "Iteration 11, loss = 0.31477104\n",
            "Iteration 12, loss = 0.31450975\n",
            "Iteration 13, loss = 0.31442705\n",
            "Iteration 14, loss = 0.31427933\n",
            "Iteration 15, loss = 0.31432745\n",
            "Iteration 16, loss = 0.31413880\n",
            "Iteration 17, loss = 0.31399153\n",
            "Iteration 18, loss = 0.31411406\n",
            "Iteration 19, loss = 0.31381474\n",
            "Iteration 20, loss = 0.31384598\n",
            "Iteration 21, loss = 0.31385880\n",
            "Iteration 22, loss = 0.31366634\n",
            "Iteration 23, loss = 0.31374795\n",
            "Iteration 24, loss = 0.31360099\n",
            "Iteration 25, loss = 0.31334309\n",
            "Iteration 26, loss = 0.31362858\n",
            "Iteration 27, loss = 0.31361749\n",
            "Iteration 28, loss = 0.31341108\n",
            "Iteration 29, loss = 0.31340117\n",
            "Iteration 30, loss = 0.31327524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.838 total time= 2.1min\n",
            "Iteration 1, loss = 0.33015896\n",
            "Iteration 2, loss = 0.31761710\n",
            "Iteration 3, loss = 0.31642520\n",
            "Iteration 4, loss = 0.31574259\n",
            "Iteration 5, loss = 0.31567986\n",
            "Iteration 6, loss = 0.31521517\n",
            "Iteration 7, loss = 0.31489024\n",
            "Iteration 8, loss = 0.31465535\n",
            "Iteration 9, loss = 0.31468644\n",
            "Iteration 10, loss = 0.31447936\n",
            "Iteration 11, loss = 0.31411933\n",
            "Iteration 12, loss = 0.31417762\n",
            "Iteration 13, loss = 0.31409334\n",
            "Iteration 14, loss = 0.31375161\n",
            "Iteration 15, loss = 0.31380610\n",
            "Iteration 16, loss = 0.31378127\n",
            "Iteration 17, loss = 0.31362753\n",
            "Iteration 18, loss = 0.31346758\n",
            "Iteration 19, loss = 0.31360355\n",
            "Iteration 20, loss = 0.31337507\n",
            "Iteration 21, loss = 0.31327785\n",
            "Iteration 22, loss = 0.31342886\n",
            "Iteration 23, loss = 0.31320788\n",
            "Iteration 24, loss = 0.31322864\n",
            "Iteration 25, loss = 0.31305343\n",
            "Iteration 26, loss = 0.31309221\n",
            "Iteration 27, loss = 0.31294546\n",
            "Iteration 28, loss = 0.31300633\n",
            "Iteration 29, loss = 0.31293430\n",
            "Iteration 30, loss = 0.31302954\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.832 total time=  47.1s\n",
            "Iteration 1, loss = 0.32964453\n",
            "Iteration 2, loss = 0.31720867\n",
            "Iteration 3, loss = 0.31574510\n",
            "Iteration 4, loss = 0.31541741\n",
            "Iteration 5, loss = 0.31509249\n",
            "Iteration 6, loss = 0.31472131\n",
            "Iteration 7, loss = 0.31438619\n",
            "Iteration 8, loss = 0.31415945\n",
            "Iteration 9, loss = 0.31418215\n",
            "Iteration 10, loss = 0.31406095\n",
            "Iteration 11, loss = 0.31361340\n",
            "Iteration 12, loss = 0.31355809\n",
            "Iteration 13, loss = 0.31354232\n",
            "Iteration 14, loss = 0.31325271\n",
            "Iteration 15, loss = 0.31326997\n",
            "Iteration 16, loss = 0.31330359\n",
            "Iteration 17, loss = 0.31298984\n",
            "Iteration 18, loss = 0.31299556\n",
            "Iteration 19, loss = 0.31297194\n",
            "Iteration 20, loss = 0.31297894\n",
            "Iteration 21, loss = 0.31271833\n",
            "Iteration 22, loss = 0.31274243\n",
            "Iteration 23, loss = 0.31267820\n",
            "Iteration 24, loss = 0.31256450\n",
            "Iteration 25, loss = 0.31249442\n",
            "Iteration 26, loss = 0.31241002\n",
            "Iteration 27, loss = 0.31246968\n",
            "Iteration 28, loss = 0.31240026\n",
            "Iteration 29, loss = 0.31245718\n",
            "Iteration 30, loss = 0.31242195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.826 total time=  47.4s\n",
            "Iteration 1, loss = 0.32935194\n",
            "Iteration 2, loss = 0.31685954\n",
            "Iteration 3, loss = 0.31550931\n",
            "Iteration 4, loss = 0.31498341\n",
            "Iteration 5, loss = 0.31475988\n",
            "Iteration 6, loss = 0.31444252\n",
            "Iteration 7, loss = 0.31414301\n",
            "Iteration 8, loss = 0.31385703\n",
            "Iteration 9, loss = 0.31379133\n",
            "Iteration 10, loss = 0.31356296\n",
            "Iteration 11, loss = 0.31335486\n",
            "Iteration 12, loss = 0.31337963\n",
            "Iteration 13, loss = 0.31322554\n",
            "Iteration 14, loss = 0.31318993\n",
            "Iteration 15, loss = 0.31296703\n",
            "Iteration 16, loss = 0.31315571\n",
            "Iteration 17, loss = 0.31273234\n",
            "Iteration 18, loss = 0.31291283\n",
            "Iteration 19, loss = 0.31272727\n",
            "Iteration 20, loss = 0.31267133\n",
            "Iteration 21, loss = 0.31252813\n",
            "Iteration 22, loss = 0.31250711\n",
            "Iteration 23, loss = 0.31260642\n",
            "Iteration 24, loss = 0.31243522\n",
            "Iteration 25, loss = 0.31234024\n",
            "Iteration 26, loss = 0.31236511\n",
            "Iteration 27, loss = 0.31235106\n",
            "Iteration 28, loss = 0.31232014\n",
            "Iteration 29, loss = 0.31242032\n",
            "Iteration 30, loss = 0.31223871\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.824 total time=  48.0s\n",
            "Iteration 1, loss = 0.33004604\n",
            "Iteration 2, loss = 0.31730563\n",
            "Iteration 3, loss = 0.31600449\n",
            "Iteration 4, loss = 0.31566527\n",
            "Iteration 5, loss = 0.31522077\n",
            "Iteration 6, loss = 0.31511524\n",
            "Iteration 7, loss = 0.31459728\n",
            "Iteration 8, loss = 0.31448405\n",
            "Iteration 9, loss = 0.31419189\n",
            "Iteration 10, loss = 0.31412642\n",
            "Iteration 11, loss = 0.31401776\n",
            "Iteration 12, loss = 0.31403969\n",
            "Iteration 13, loss = 0.31373724\n",
            "Iteration 14, loss = 0.31368703\n",
            "Iteration 15, loss = 0.31365270\n",
            "Iteration 16, loss = 0.31350185\n",
            "Iteration 17, loss = 0.31327723\n",
            "Iteration 18, loss = 0.31334812\n",
            "Iteration 19, loss = 0.31317476\n",
            "Iteration 20, loss = 0.31320034\n",
            "Iteration 21, loss = 0.31299134\n",
            "Iteration 22, loss = 0.31305530\n",
            "Iteration 23, loss = 0.31314672\n",
            "Iteration 24, loss = 0.31290446\n",
            "Iteration 25, loss = 0.31294468\n",
            "Iteration 26, loss = 0.31304082\n",
            "Iteration 27, loss = 0.31288564\n",
            "Iteration 28, loss = 0.31270689\n",
            "Iteration 29, loss = 0.31277564\n",
            "Iteration 30, loss = 0.31261647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.829 total time=  48.3s\n",
            "Iteration 1, loss = 0.33036233\n",
            "Iteration 2, loss = 0.31764507\n",
            "Iteration 3, loss = 0.31650887\n",
            "Iteration 4, loss = 0.31607263\n",
            "Iteration 5, loss = 0.31543932\n",
            "Iteration 6, loss = 0.31522696\n",
            "Iteration 7, loss = 0.31484108\n",
            "Iteration 8, loss = 0.31459901\n",
            "Iteration 9, loss = 0.31458781\n",
            "Iteration 10, loss = 0.31423871\n",
            "Iteration 11, loss = 0.31438303\n",
            "Iteration 12, loss = 0.31407979\n",
            "Iteration 13, loss = 0.31391823\n",
            "Iteration 14, loss = 0.31390886\n",
            "Iteration 15, loss = 0.31378004\n",
            "Iteration 16, loss = 0.31373658\n",
            "Iteration 17, loss = 0.31354890\n",
            "Iteration 18, loss = 0.31351031\n",
            "Iteration 19, loss = 0.31343292\n",
            "Iteration 20, loss = 0.31342365\n",
            "Iteration 21, loss = 0.31324918\n",
            "Iteration 22, loss = 0.31337493\n",
            "Iteration 23, loss = 0.31346497\n",
            "Iteration 24, loss = 0.31312167\n",
            "Iteration 25, loss = 0.31318175\n",
            "Iteration 26, loss = 0.31315384\n",
            "Iteration 27, loss = 0.31294776\n",
            "Iteration 28, loss = 0.31300564\n",
            "Iteration 29, loss = 0.31297225\n",
            "Iteration 30, loss = 0.31290046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5] END activation=tanh, alpha=0.01, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.838 total time=  47.2s\n",
            "Iteration 1, loss = 0.32441017\n",
            "Iteration 2, loss = 0.31614651\n",
            "Iteration 3, loss = 0.31517321\n",
            "Iteration 4, loss = 0.31428349\n",
            "Iteration 5, loss = 0.31364032\n",
            "Iteration 6, loss = 0.31340877\n",
            "Iteration 7, loss = 0.31308248\n",
            "Iteration 8, loss = 0.31307155\n",
            "Iteration 9, loss = 0.31263797\n",
            "Iteration 10, loss = 0.31252811\n",
            "Iteration 11, loss = 0.31239545\n",
            "Iteration 12, loss = 0.31220603\n",
            "Iteration 13, loss = 0.31200995\n",
            "Iteration 14, loss = 0.31193997\n",
            "Iteration 15, loss = 0.31176248\n",
            "Iteration 16, loss = 0.31193090\n",
            "Iteration 17, loss = 0.31163703\n",
            "Iteration 18, loss = 0.31158430\n",
            "Iteration 19, loss = 0.31134104\n",
            "Iteration 20, loss = 0.31145162\n",
            "Iteration 21, loss = 0.31095263\n",
            "Iteration 22, loss = 0.31103770\n",
            "Iteration 23, loss = 0.31082514\n",
            "Iteration 24, loss = 0.31074703\n",
            "Iteration 25, loss = 0.31063243\n",
            "Iteration 26, loss = 0.31055551\n",
            "Iteration 27, loss = 0.31069527\n",
            "Iteration 28, loss = 0.31040568\n",
            "Iteration 29, loss = 0.31028206\n",
            "Iteration 30, loss = 0.31009592\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.830 total time= 2.1min\n",
            "Iteration 1, loss = 0.32376358\n",
            "Iteration 2, loss = 0.31591961\n",
            "Iteration 3, loss = 0.31452201\n",
            "Iteration 4, loss = 0.31411405\n",
            "Iteration 5, loss = 0.31329660\n",
            "Iteration 6, loss = 0.31303370\n",
            "Iteration 7, loss = 0.31272027\n",
            "Iteration 8, loss = 0.31258840\n",
            "Iteration 9, loss = 0.31223069\n",
            "Iteration 10, loss = 0.31216963\n",
            "Iteration 11, loss = 0.31190326\n",
            "Iteration 12, loss = 0.31176128\n",
            "Iteration 13, loss = 0.31157037\n",
            "Iteration 14, loss = 0.31137635\n",
            "Iteration 15, loss = 0.31157724\n",
            "Iteration 16, loss = 0.31121235\n",
            "Iteration 17, loss = 0.31117683\n",
            "Iteration 18, loss = 0.31110787\n",
            "Iteration 19, loss = 0.31081755\n",
            "Iteration 20, loss = 0.31094425\n",
            "Iteration 21, loss = 0.31058491\n",
            "Iteration 22, loss = 0.31064140\n",
            "Iteration 23, loss = 0.31048946\n",
            "Iteration 24, loss = 0.31034250\n",
            "Iteration 25, loss = 0.31032431\n",
            "Iteration 26, loss = 0.31033091\n",
            "Iteration 27, loss = 0.31004734\n",
            "Iteration 28, loss = 0.30993757\n",
            "Iteration 29, loss = 0.30977166\n",
            "Iteration 30, loss = 0.30982094\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.833 total time= 2.2min\n",
            "Iteration 1, loss = 0.32357085\n",
            "Iteration 2, loss = 0.31542821\n",
            "Iteration 3, loss = 0.31405191\n",
            "Iteration 4, loss = 0.31362004\n",
            "Iteration 5, loss = 0.31314567\n",
            "Iteration 6, loss = 0.31250652\n",
            "Iteration 7, loss = 0.31259068\n",
            "Iteration 8, loss = 0.31234984\n",
            "Iteration 9, loss = 0.31189169\n",
            "Iteration 10, loss = 0.31180351\n",
            "Iteration 11, loss = 0.31185910\n",
            "Iteration 12, loss = 0.31153596\n",
            "Iteration 13, loss = 0.31148590\n",
            "Iteration 14, loss = 0.31141102\n",
            "Iteration 15, loss = 0.31125245\n",
            "Iteration 16, loss = 0.31091276\n",
            "Iteration 17, loss = 0.31091084\n",
            "Iteration 18, loss = 0.31084325\n",
            "Iteration 19, loss = 0.31076876\n",
            "Iteration 20, loss = 0.31077669\n",
            "Iteration 21, loss = 0.31034307\n",
            "Iteration 22, loss = 0.31063815\n",
            "Iteration 23, loss = 0.31051510\n",
            "Iteration 24, loss = 0.31023503\n",
            "Iteration 25, loss = 0.31017850\n",
            "Iteration 26, loss = 0.31005112\n",
            "Iteration 27, loss = 0.30989619\n",
            "Iteration 28, loss = 0.30981571\n",
            "Iteration 29, loss = 0.30977394\n",
            "Iteration 30, loss = 0.30985403\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.830 total time= 2.1min\n",
            "Iteration 1, loss = 0.32418465\n",
            "Iteration 2, loss = 0.31605600\n",
            "Iteration 3, loss = 0.31476836\n",
            "Iteration 4, loss = 0.31394660\n",
            "Iteration 5, loss = 0.31369605\n",
            "Iteration 6, loss = 0.31320863\n",
            "Iteration 7, loss = 0.31328405\n",
            "Iteration 8, loss = 0.31286378\n",
            "Iteration 9, loss = 0.31232966\n",
            "Iteration 10, loss = 0.31216436\n",
            "Iteration 11, loss = 0.31230003\n",
            "Iteration 12, loss = 0.31205610\n",
            "Iteration 13, loss = 0.31198717\n",
            "Iteration 14, loss = 0.31165645\n",
            "Iteration 15, loss = 0.31151789\n",
            "Iteration 16, loss = 0.31139051\n",
            "Iteration 17, loss = 0.31138886\n",
            "Iteration 18, loss = 0.31109765\n",
            "Iteration 19, loss = 0.31130049\n",
            "Iteration 20, loss = 0.31101651\n",
            "Iteration 21, loss = 0.31075209\n",
            "Iteration 22, loss = 0.31086817\n",
            "Iteration 23, loss = 0.31075598\n",
            "Iteration 24, loss = 0.31053156\n",
            "Iteration 25, loss = 0.31062367\n",
            "Iteration 26, loss = 0.31025074\n",
            "Iteration 27, loss = 0.31016260\n",
            "Iteration 28, loss = 0.31006254\n",
            "Iteration 29, loss = 0.31010546\n",
            "Iteration 30, loss = 0.31012553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.833 total time= 2.1min\n",
            "Iteration 1, loss = 0.32511366\n",
            "Iteration 2, loss = 0.31661006\n",
            "Iteration 3, loss = 0.31496021\n",
            "Iteration 4, loss = 0.31429116\n",
            "Iteration 5, loss = 0.31372937\n",
            "Iteration 6, loss = 0.31341587\n",
            "Iteration 7, loss = 0.31317124\n",
            "Iteration 8, loss = 0.31284402\n",
            "Iteration 9, loss = 0.31288603\n",
            "Iteration 10, loss = 0.31272862\n",
            "Iteration 11, loss = 0.31257186\n",
            "Iteration 12, loss = 0.31226015\n",
            "Iteration 13, loss = 0.31218506\n",
            "Iteration 14, loss = 0.31201687\n",
            "Iteration 15, loss = 0.31202845\n",
            "Iteration 16, loss = 0.31181619\n",
            "Iteration 17, loss = 0.31162736\n",
            "Iteration 18, loss = 0.31169539\n",
            "Iteration 19, loss = 0.31136543\n",
            "Iteration 20, loss = 0.31131055\n",
            "Iteration 21, loss = 0.31130976\n",
            "Iteration 22, loss = 0.31107317\n",
            "Iteration 23, loss = 0.31105554\n",
            "Iteration 24, loss = 0.31089608\n",
            "Iteration 25, loss = 0.31059257\n",
            "Iteration 26, loss = 0.31077746\n",
            "Iteration 27, loss = 0.31076453\n",
            "Iteration 28, loss = 0.31046941\n",
            "Iteration 29, loss = 0.31039550\n",
            "Iteration 30, loss = 0.31019646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.838 total time= 2.2min\n",
            "Iteration 1, loss = 0.32854969\n",
            "Iteration 2, loss = 0.31597579\n",
            "Iteration 3, loss = 0.31479158\n",
            "Iteration 4, loss = 0.31411389\n",
            "Iteration 5, loss = 0.31405318\n",
            "Iteration 6, loss = 0.31361216\n",
            "Iteration 7, loss = 0.31328865\n",
            "Iteration 8, loss = 0.31303239\n",
            "Iteration 9, loss = 0.31305584\n",
            "Iteration 10, loss = 0.31284584\n",
            "Iteration 11, loss = 0.31249426\n",
            "Iteration 12, loss = 0.31248773\n",
            "Iteration 13, loss = 0.31240082\n",
            "Iteration 14, loss = 0.31204388\n",
            "Iteration 15, loss = 0.31206499\n",
            "Iteration 16, loss = 0.31201548\n",
            "Iteration 17, loss = 0.31183524\n",
            "Iteration 18, loss = 0.31167224\n",
            "Iteration 19, loss = 0.31177343\n",
            "Iteration 20, loss = 0.31153338\n",
            "Iteration 21, loss = 0.31138962\n",
            "Iteration 22, loss = 0.31152370\n",
            "Iteration 23, loss = 0.31129775\n",
            "Iteration 24, loss = 0.31128328\n",
            "Iteration 25, loss = 0.31107094\n",
            "Iteration 26, loss = 0.31112353\n",
            "Iteration 27, loss = 0.31090160\n",
            "Iteration 28, loss = 0.31095820\n",
            "Iteration 29, loss = 0.31085769\n",
            "Iteration 30, loss = 0.31093133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 1/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.833 total time=  48.1s\n",
            "Iteration 1, loss = 0.32803511\n",
            "Iteration 2, loss = 0.31556760\n",
            "Iteration 3, loss = 0.31410957\n",
            "Iteration 4, loss = 0.31377816\n",
            "Iteration 5, loss = 0.31345153\n",
            "Iteration 6, loss = 0.31309616\n",
            "Iteration 7, loss = 0.31276735\n",
            "Iteration 8, loss = 0.31253139\n",
            "Iteration 9, loss = 0.31253083\n",
            "Iteration 10, loss = 0.31242551\n",
            "Iteration 11, loss = 0.31197249\n",
            "Iteration 12, loss = 0.31185579\n",
            "Iteration 13, loss = 0.31183646\n",
            "Iteration 14, loss = 0.31152678\n",
            "Iteration 15, loss = 0.31151832\n",
            "Iteration 16, loss = 0.31152159\n",
            "Iteration 17, loss = 0.31119172\n",
            "Iteration 18, loss = 0.31116025\n",
            "Iteration 19, loss = 0.31110903\n",
            "Iteration 20, loss = 0.31107638\n",
            "Iteration 21, loss = 0.31077040\n",
            "Iteration 22, loss = 0.31079824\n",
            "Iteration 23, loss = 0.31070215\n",
            "Iteration 24, loss = 0.31057446\n",
            "Iteration 25, loss = 0.31044748\n",
            "Iteration 26, loss = 0.31039802\n",
            "Iteration 27, loss = 0.31037172\n",
            "Iteration 28, loss = 0.31029116\n",
            "Iteration 29, loss = 0.31032815\n",
            "Iteration 30, loss = 0.31028619\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 2/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.826 total time=  47.2s\n",
            "Iteration 1, loss = 0.32774328\n",
            "Iteration 2, loss = 0.31522823\n",
            "Iteration 3, loss = 0.31388740\n",
            "Iteration 4, loss = 0.31336729\n",
            "Iteration 5, loss = 0.31314554\n",
            "Iteration 6, loss = 0.31284071\n",
            "Iteration 7, loss = 0.31255181\n",
            "Iteration 8, loss = 0.31226173\n",
            "Iteration 9, loss = 0.31220305\n",
            "Iteration 10, loss = 0.31197787\n",
            "Iteration 11, loss = 0.31176918\n",
            "Iteration 12, loss = 0.31175406\n",
            "Iteration 13, loss = 0.31160748\n",
            "Iteration 14, loss = 0.31153437\n",
            "Iteration 15, loss = 0.31131448\n",
            "Iteration 16, loss = 0.31146790\n",
            "Iteration 17, loss = 0.31103376\n",
            "Iteration 18, loss = 0.31116085\n",
            "Iteration 19, loss = 0.31096751\n",
            "Iteration 20, loss = 0.31088657\n",
            "Iteration 21, loss = 0.31072199\n",
            "Iteration 22, loss = 0.31069592\n",
            "Iteration 23, loss = 0.31074484\n",
            "Iteration 24, loss = 0.31056957\n",
            "Iteration 25, loss = 0.31043567\n",
            "Iteration 26, loss = 0.31046447\n",
            "Iteration 27, loss = 0.31042443\n",
            "Iteration 28, loss = 0.31035206\n",
            "Iteration 29, loss = 0.31040021\n",
            "Iteration 30, loss = 0.31020829\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 3/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.826 total time=  47.5s\n",
            "Iteration 1, loss = 0.32843729\n",
            "Iteration 2, loss = 0.31566838\n",
            "Iteration 3, loss = 0.31437247\n",
            "Iteration 4, loss = 0.31403910\n",
            "Iteration 5, loss = 0.31359182\n",
            "Iteration 6, loss = 0.31349055\n",
            "Iteration 7, loss = 0.31297905\n",
            "Iteration 8, loss = 0.31286271\n",
            "Iteration 9, loss = 0.31258452\n",
            "Iteration 10, loss = 0.31251114\n",
            "Iteration 11, loss = 0.31240214\n",
            "Iteration 12, loss = 0.31239686\n",
            "Iteration 13, loss = 0.31210169\n",
            "Iteration 14, loss = 0.31202881\n",
            "Iteration 15, loss = 0.31197936\n",
            "Iteration 16, loss = 0.31181555\n",
            "Iteration 17, loss = 0.31158163\n",
            "Iteration 18, loss = 0.31158643\n",
            "Iteration 19, loss = 0.31143107\n",
            "Iteration 20, loss = 0.31140431\n",
            "Iteration 21, loss = 0.31120692\n",
            "Iteration 22, loss = 0.31122907\n",
            "Iteration 23, loss = 0.31128358\n",
            "Iteration 24, loss = 0.31107692\n",
            "Iteration 25, loss = 0.31101265\n",
            "Iteration 26, loss = 0.31114776\n",
            "Iteration 27, loss = 0.31100229\n",
            "Iteration 28, loss = 0.31080404\n",
            "Iteration 29, loss = 0.31086190\n",
            "Iteration 30, loss = 0.31064637\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 4/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.829 total time=  47.8s\n",
            "Iteration 1, loss = 0.32875443\n",
            "Iteration 2, loss = 0.31600880\n",
            "Iteration 3, loss = 0.31487274\n",
            "Iteration 4, loss = 0.31443616\n",
            "Iteration 5, loss = 0.31380228\n",
            "Iteration 6, loss = 0.31358582\n",
            "Iteration 7, loss = 0.31321686\n",
            "Iteration 8, loss = 0.31297043\n",
            "Iteration 9, loss = 0.31294687\n",
            "Iteration 10, loss = 0.31259892\n",
            "Iteration 11, loss = 0.31272486\n",
            "Iteration 12, loss = 0.31241779\n",
            "Iteration 13, loss = 0.31225520\n",
            "Iteration 14, loss = 0.31222419\n",
            "Iteration 15, loss = 0.31206560\n",
            "Iteration 16, loss = 0.31199515\n",
            "Iteration 17, loss = 0.31176759\n",
            "Iteration 18, loss = 0.31169529\n",
            "Iteration 19, loss = 0.31162537\n",
            "Iteration 20, loss = 0.31159154\n",
            "Iteration 21, loss = 0.31136759\n",
            "Iteration 22, loss = 0.31145805\n",
            "Iteration 23, loss = 0.31152476\n",
            "Iteration 24, loss = 0.31118741\n",
            "Iteration 25, loss = 0.31121164\n",
            "Iteration 26, loss = 0.31116261\n",
            "Iteration 27, loss = 0.31091837\n",
            "Iteration 28, loss = 0.31094318\n",
            "Iteration 29, loss = 0.31089576\n",
            "Iteration 30, loss = 0.31080807\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV 5/5] END activation=tanh, alpha=0.001, hidden_layer_sizes=(32, 32), max_iter=30, random_state=42, solver=adam, verbose=True;, score=0.838 total time=  48.4s\n",
            "Iteration 1, loss = 0.32243545\n",
            "Iteration 2, loss = 0.31401857\n",
            "Iteration 3, loss = 0.31342956\n",
            "Iteration 4, loss = 0.31292801\n",
            "Iteration 5, loss = 0.31263717\n",
            "Iteration 6, loss = 0.31204934\n",
            "Iteration 7, loss = 0.31190843\n",
            "Iteration 8, loss = 0.31158385\n",
            "Iteration 9, loss = 0.31153677\n",
            "Iteration 10, loss = 0.31121097\n",
            "Iteration 11, loss = 0.31115420\n",
            "Iteration 12, loss = 0.31091826\n",
            "Iteration 13, loss = 0.31073057\n",
            "Iteration 14, loss = 0.31030715\n",
            "Iteration 15, loss = 0.31020129\n",
            "Iteration 16, loss = 0.31026134\n",
            "Iteration 17, loss = 0.30990042\n",
            "Iteration 18, loss = 0.30977066\n",
            "Iteration 19, loss = 0.30955742\n",
            "Iteration 20, loss = 0.30931004\n",
            "Iteration 21, loss = 0.30912879\n",
            "Iteration 22, loss = 0.30897950\n",
            "Iteration 23, loss = 0.30876590\n",
            "Iteration 24, loss = 0.30848927\n",
            "Iteration 25, loss = 0.30869754\n",
            "Iteration 26, loss = 0.30823685\n",
            "Iteration 27, loss = 0.30806291\n",
            "Iteration 28, loss = 0.30788930\n",
            "Iteration 29, loss = 0.30776255\n",
            "Iteration 30, loss = 0.30760079\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=MLPClassifier(),\n",
              "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;], &#x27;alpha&#x27;: [0.01, 0.001],\n",
              "                         &#x27;hidden_layer_sizes&#x27;: [(64, 64), (32, 32)],\n",
              "                         &#x27;max_iter&#x27;: [30], &#x27;random_state&#x27;: [42],\n",
              "                         &#x27;solver&#x27;: [&#x27;adam&#x27;], &#x27;verbose&#x27;: [True]},\n",
              "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=MLPClassifier(),\n",
              "             param_grid={&#x27;activation&#x27;: [&#x27;relu&#x27;, &#x27;tanh&#x27;], &#x27;alpha&#x27;: [0.01, 0.001],\n",
              "                         &#x27;hidden_layer_sizes&#x27;: [(64, 64), (32, 32)],\n",
              "                         &#x27;max_iter&#x27;: [30], &#x27;random_state&#x27;: [42],\n",
              "                         &#x27;solver&#x27;: [&#x27;adam&#x27;], &#x27;verbose&#x27;: [True]},\n",
              "             scoring=&#x27;f1_weighted&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=5, estimator=MLPClassifier(),\n",
              "             param_grid={'activation': ['relu', 'tanh'], 'alpha': [0.01, 0.001],\n",
              "                         'hidden_layer_sizes': [(64, 64), (32, 32)],\n",
              "                         'max_iter': [30], 'random_state': [42],\n",
              "                         'solver': ['adam'], 'verbose': [True]},\n",
              "             scoring='f1_weighted', verbose=3)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_grid_search_clf = GridSearchCV(estimator=mlp_classifer, param_grid=mlp_param_grid, scoring='f1_weighted', cv=5, verbose=3)\n",
        "mlp_grid_search_clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elF1CrueEgs8",
        "outputId": "59f3fcb8-f34d-4cd3-ab74-e2e84c84ca79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'activation': 'relu', 'alpha': 0.001, 'hidden_layer_sizes': (64, 64), 'max_iter': 30, 'random_state': 42, 'solver': 'adam', 'verbose': True}\n"
          ]
        }
      ],
      "source": [
        "print(mlp_grid_search_clf.best_params_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "ntLehcv-XIh3",
        "outputId": "8ac34ae9-77e7-4ab8-dd58-72df4bae48fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 1, loss = 0.32243545\n",
            "Iteration 2, loss = 0.31401857\n",
            "Iteration 3, loss = 0.31342956\n",
            "Iteration 4, loss = 0.31292801\n",
            "Iteration 5, loss = 0.31263717\n",
            "Iteration 6, loss = 0.31204934\n",
            "Iteration 7, loss = 0.31190843\n",
            "Iteration 8, loss = 0.31158385\n",
            "Iteration 9, loss = 0.31153677\n",
            "Iteration 10, loss = 0.31121097\n",
            "Iteration 11, loss = 0.31115420\n",
            "Iteration 12, loss = 0.31091826\n",
            "Iteration 13, loss = 0.31073057\n",
            "Iteration 14, loss = 0.31030715\n",
            "Iteration 15, loss = 0.31020129\n",
            "Iteration 16, loss = 0.31026134\n",
            "Iteration 17, loss = 0.30990042\n",
            "Iteration 18, loss = 0.30977066\n",
            "Iteration 19, loss = 0.30955742\n",
            "Iteration 20, loss = 0.30931004\n",
            "Iteration 21, loss = 0.30912879\n",
            "Iteration 22, loss = 0.30897950\n",
            "Iteration 23, loss = 0.30876590\n",
            "Iteration 24, loss = 0.30848927\n",
            "Iteration 25, loss = 0.30869754\n",
            "Iteration 26, loss = 0.30823685\n",
            "Iteration 27, loss = 0.30806291\n",
            "Iteration 28, loss = 0.30788930\n",
            "Iteration 29, loss = 0.30776255\n",
            "Iteration 30, loss = 0.30760079\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30,\n",
              "              random_state=42, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30,\n",
              "              random_state=42, verbose=True)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "MLPClassifier(alpha=0.001, hidden_layer_sizes=(64, 64), max_iter=30,\n",
              "              random_state=42, verbose=True)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mlp_classifer_binary_imbalanced_split = MLPClassifier()\n",
        "mlp_classifer_binary_imbalanced_split.set_params(**mlp_grid_search_clf.best_params_)\n",
        "mlp_classifer_binary_imbalanced_split.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Biw6WkLbEgs8"
      },
      "outputs": [],
      "source": [
        "mlp_pickle_file_binary_imbalanced_split = '/content/drive/MyDrive/AML_Final_Project/mlp_classifer_binary_imbalanced_split.pkl'\n",
        "# with open(mlp_pickle_file_binary_imbalanced_split, 'wb') as file:\n",
        "#     pickle.dump(mlp_classifer_binary_imbalanced_split, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up2AFp8zEgs8"
      },
      "outputs": [],
      "source": [
        "with open(mlp_pickle_file_binary_imbalanced_split, 'rb') as file:\n",
        "    mlp_classifer_binary_imbalanced_split = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHHIPJ0aEgs8",
        "outputId": "7296f96c-fa42-4fae-ddd4-2b6fb6f7502a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.88      0.92     48512\n",
            "         1.0       0.16      0.52      0.25      2224\n",
            "\n",
            "    accuracy                           0.86     50736\n",
            "   macro avg       0.57      0.70      0.59     50736\n",
            "weighted avg       0.94      0.86      0.89     50736\n",
            "\n",
            "[[42607  5905]\n",
            " [ 1060  1164]]\n"
          ]
        }
      ],
      "source": [
        "y_pred = mlp_classifer_binary_imbalanced_split.predict(X_test)\n",
        "print(classification_report(y_pred, y_test))\n",
        "print(confusion_matrix(y_pred, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlbtHkcSOor4"
      },
      "source": [
        "### Training the MLP classifier using the best parameters obtained after grid search and cross validation using the PCA on training data to get the cumulative variance explained by different no. of components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9HPGbMPF2TO",
        "outputId": "c311e534-30ca-47a4-f1c5-848967c5453f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cumulative variance explained by 3 components is 0.4425854030123507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.87      0.93     49633\n",
            "         1.0       0.09      0.56      0.15      1103\n",
            "\n",
            "    accuracy                           0.86     50736\n",
            "   macro avg       0.54      0.71      0.54     50736\n",
            "weighted avg       0.97      0.86      0.91     50736\n",
            "\n",
            "\n",
            "Cumulative variance explained by 5 components is 0.6190931265213593\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.88      0.92     48685\n",
            "         1.0       0.15      0.53      0.24      2051\n",
            "\n",
            "    accuracy                           0.86     50736\n",
            "   macro avg       0.57      0.70      0.58     50736\n",
            "weighted avg       0.94      0.86      0.90     50736\n",
            "\n",
            "\n",
            "Cumulative variance explained by 10 components is 0.8618993073380475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.88      0.93     48793\n",
            "         1.0       0.15      0.54      0.23      1943\n",
            "\n",
            "    accuracy                           0.86     50736\n",
            "   macro avg       0.56      0.71      0.58     50736\n",
            "weighted avg       0.95      0.86      0.90     50736\n",
            "\n",
            "\n",
            "Cumulative variance explained by 15 components is 0.9475321175921767\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.88      0.93     48664\n",
            "         1.0       0.16      0.54      0.25      2072\n",
            "\n",
            "    accuracy                           0.86     50736\n",
            "   macro avg       0.57      0.71      0.59     50736\n",
            "weighted avg       0.94      0.86      0.90     50736\n",
            "\n",
            "\n",
            "Cumulative variance explained by 20 components is 0.9950711117337883\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 20\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.97      0.88      0.92     48203\n",
            "         1.0       0.19      0.52      0.28      2533\n",
            "\n",
            "    accuracy                           0.86     50736\n",
            "   macro avg       0.58      0.70      0.60     50736\n",
            "weighted avg       0.93      0.86      0.89     50736\n",
            "\n",
            "\n",
            "Cumulative variance explained by 25 components is 0.9999999999999996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (30) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report for total components: 25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.88      0.93     48924\n",
            "         1.0       0.14      0.56      0.23      1812\n",
            "\n",
            "    accuracy                           0.87     50736\n",
            "   macro avg       0.56      0.72      0.58     50736\n",
            "weighted avg       0.95      0.87      0.90     50736\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "num_components = [3, 5, 10, 15, 20, 25]\n",
        "variance = []\n",
        "\n",
        "for num in num_components:\n",
        "  # Initializing the PCA with defitive components\n",
        "  pca = PCA(n_components=num)\n",
        "\n",
        "  # Fit the PCA on the training data\n",
        "  pca.fit(X_train)\n",
        "\n",
        "  # Transform the train and test data as per the components of the PCA\n",
        "  X_train_pca = pca.transform(X_train)\n",
        "  X_test_pca = pca.transform(X_test)\n",
        "\n",
        "  # Recording the explained variance for each number of components\n",
        "  variance.append(np.sum(pca.explained_variance_ratio_))\n",
        "\n",
        "  print(\"Cumulative variance explained by {} components is {}\".format(num,variance[-1]))\n",
        "\n",
        "  mlp_classifer = MLPClassifier(activation = 'relu', alpha=0.001, hidden_layer_sizes=(64, 64), max_iter = 30, solver='adam', random_state= 42)\n",
        "  mlp_classifer.fit(X_train_pca, y_train)\n",
        "  y_pred = mlp_classifer.predict(X_test_pca)\n",
        "  print(f\"Classification Report for total components: {num}\")\n",
        "  print(classification_report(y_pred, y_test))\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "yUujHdydOsdO",
        "outputId": "2b41e540-a008-492a-97b1-e331845421a3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### START CODE ###\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.plot(num_components, variance)\n",
        "plt.title(\"PCA Explained Variance for Binary Imbalanced Split\")\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.grid(True)\n",
        "### END CODE ###\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwMsguHLQV5g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
