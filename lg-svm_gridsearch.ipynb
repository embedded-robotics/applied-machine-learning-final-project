{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B21q-bx4zWoZ"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "infile = \"archive/diabetes_binary_5050split_health_indicators_BRFSS2015.csv\"\n",
    "df = pd.read_csv(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "plE_OXorzWoa",
    "outputId": "ce5a4335-6fe8-45a9-e8cb-3d43faaf4b5e"
   },
   "outputs": [],
   "source": [
    "# Show you all the columns in this file\n",
    "df.columns\n",
    "# Show you the first 5 rows in this file\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.get_dummies(df, columns=['GenHlth'])\n",
    "\n",
    "columns_standard_scaling = ['Age','Education','Income']\n",
    "columns_minmax_scaling = ['BMI','MentHlth','PhysHlth']\n",
    "\n",
    "float_list = columns_minmax_scaling + columns_standard_scaling\n",
    "int_list = df2.columns.difference(float_list)\n",
    "\n",
    "df2[int_list] = df2[int_list].astype(int)\n",
    "\n",
    "minmax_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()\n",
    "\n",
    "\n",
    "df2[columns_standard_scaling] = standard_scaler.fit_transform(df2[columns_standard_scaling])\n",
    "df2[columns_minmax_scaling] = minmax_scaler.fit_transform(df2[columns_minmax_scaling])\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZ0QGMfLzWoa"
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "target = \"Diabetes_binary\"\n",
    "if \"012\" in infile:\n",
    "    target=\"Diabetes_012\"\n",
    "\n",
    "X = df2.drop(columns=[target])\n",
    "y = df2[target]\n",
    "\n",
    "# Write code to make train and test splits\n",
    "## START CODE ##\n",
    "oversampling = 0\n",
    "if oversampling==0:\n",
    "    traindf, testdf = train_test_split(df2, test_size=0.2, random_state=42, stratify=df2[target])\n",
    "    X_train = traindf.drop(columns=[target])\n",
    "    y_train = traindf[target]\n",
    "    X_test = testdf.drop(columns=[target])\n",
    "    y_test = testdf[target]\n",
    "else:\n",
    "    X_train_noresample, X_test, y_train_noresample, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train_noresample, y_train_noresample)\n",
    "\n",
    "## END CODE ##\n",
    "\n",
    "# # Write code to make train and validation splits\n",
    "\n",
    "# ## START CODE ##\n",
    "# traindf, valdf = train_test_split(traindf, test_size=0.2, random_state=15, stratify=traindf[target])\n",
    "# X_train = traindf.drop(columns=[target])\n",
    "# y_train = traindf[target]\n",
    "# X_val = valdf.drop(columns=[target])\n",
    "# y_val = valdf[target]\n",
    "# ## END CODE ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import (accuracy_score,roc_auc_score,precision_score,recall_score,f1_score,precision_recall_fscore_support)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def grid_search_for_classifier(model, param_grid, X_train, y_train):\n",
    "  # Grid search\n",
    "  grid_search = GridSearchCV(model, param_grid=param_grid, verbose=2, cv=5, n_jobs=-1)\n",
    "\n",
    "  # Conduct grid search using the training set (1 line of code only)\n",
    "  ### START CODE ###\n",
    "  grid_search.fit(X_train,y_train)\n",
    "  ### END CODE ###\n",
    "  print(grid_search.best_params_)\n",
    "\n",
    "  # Set the best paramters for your clf (1 line of code only)\n",
    "  ### START CODE ###\n",
    "  # model.set_params(**grid_search.best_params_)\n",
    "  ### END CODE ###\n",
    "  return grid_search.best_estimator_\n",
    "\n",
    "def evaluate_classifier(model, X_test, y_test):\n",
    "  # Fit your classifier on the training set\n",
    "  ### START CODE ###\n",
    "  # model.fit(X_train,y_train)\n",
    "  ### END CODE ###\n",
    "\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  print(\"Confusion matrix: \")\n",
    "  # Print the confusion matrix computed from the test set (1 line of code only)\n",
    "  ### START CODE ###\n",
    "  print(confusion_matrix(y_test, y_pred))\n",
    "  ### END CODE ###\n",
    "\n",
    "\n",
    "  ### START CODE ###\n",
    "  # y_pred_proba = model.predict_proba(X_test)\n",
    "  # y_test_binarized = label_binarize(y_test, classes=[0, 1, 2])\n",
    "  acc_score = accuracy_score(y_test, y_pred)\n",
    "  # auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "  # auc_score = roc_auc_score(y_test_binarized, y_pred_proba, average='macro')\n",
    "  # prec_score = precision_score(y_test, y_pred, average='macro')\n",
    "  # rec_score = recall_score(y_test, y_pred, average='macro')\n",
    "  # fone_score = f1_score(y_test, y_pred, average='macro')\n",
    "  precision_weighted, recall_weighted, f1_weighted, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "  ### END CODE ###\n",
    "\n",
    "  print(\"Accuracy: {}, F1_Weighted: {}, Precision: {}, Recall: {}\".format(acc_score, f1_weighted,  precision_weighted, recall_weighted))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10], \n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear','saga','sag'],\n",
    "    \"random_state\": [42]\n",
    "}\n",
    "\n",
    "# Initialize Logistic Regression model\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "best_model = grid_search_for_classifier(log_reg, param_grid, X_train, y_train)\n",
    "final_model = evaluate_classifier(best_model, X_test, y_test)\n",
    "\n",
    "# with open('logreg-binary_imbalanced.pkl', 'wb') as file:\n",
    "#     pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1,1], \n",
    "    'kernel': ['linear','rbf','poly'], \n",
    "    'gamma': ['scale','auto'],\n",
    "    \"random_state\": [42]\n",
    "}\n",
    "\n",
    "# Initialize SVM model\n",
    "svm = SVC()\n",
    "\n",
    "best_model = grid_search_for_classifier(svm, param_grid, X_train, y_train)\n",
    "final_model = evaluate_classifier(best_model, X_test, y_test)\n",
    "\n",
    "# with open('svm-012.pkl', 'wb') as file:\n",
    "#     pickle.dump(final_model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "def search_best_svm(kernel, C_search_space, gamma, random_state):\n",
    "    best_score = -np.inf\n",
    "    for C in C_search_space:\n",
    "        # Initialize an SVM classifier with the specified kernel type, C value, and random state\n",
    "        ### START CODE ###\n",
    "        svm = SVC(kernel=kernel,C=C, gamma=gamma, random_state=random_state)\n",
    "        ### END CODE ###\n",
    "\n",
    "        # Evaluate accuracy scores using 5-fold cross-validation scores\n",
    "        ### START CODE ###\n",
    "        scores = cross_val_score(svm, X_train, y_train, cv=5, n_jobs=-1)\n",
    "        ### END CODE ###\n",
    "\n",
    "        # Compute the average score and compare with the current best score to update the best C\n",
    "        ### START CODE ###\n",
    "        score = np.mean(scores)\n",
    "        if (score > best_score):\n",
    "          best_score = score\n",
    "          best_C = C\n",
    "        ### END CODE ###\n",
    "        print(f\"C: {C} Avg Cross Val Score: {np.round(score, 4)}\")\n",
    "\n",
    "    print(f\"Best C: {best_C}\")\n",
    "\n",
    "    # Initialize the model using the specified kernel type, best C, and random state;\n",
    "    # and then fit the model using training set\n",
    "    ### START CODE ###\n",
    "    model = SVC(kernel=kernel, C=best_C, random_state=random_state)\n",
    "    model.fit(X_train,y_train)\n",
    "    ### END CODE ###\n",
    "    return model, best_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_values = [0.1,1]\n",
    "kernel_types = ['linear','rbf','poly']\n",
    "gammas = ['scale', 'auto']\n",
    "\n",
    "for kernel_type in kernel_types:\n",
    "    best_Cs = []\n",
    "    accuracies = []\n",
    "    for gamma in gammas:\n",
    "        model, C = search_best_svm(kernel_type, C_values, gamma, 42)\n",
    "        best_Cs.append(C)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "    for i, gamma in enumerate(gammas):\n",
    "        # print(kernel_type)\n",
    "        # print(best_Cs)\n",
    "        # print(gamma)\n",
    "        # print(accuracies)\n",
    "        print(\"For %s, the best model had C_value of %f, gamma of %s, and accuracy of %f\" % (kernel_type, best_Cs[i], gamma, accuracies[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
